{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Berigny/AI-Entrainment-Protocol/blob/main/LENR_fixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Energy Nuclear (LENR) Cycles Model (Fixed)\n",
    "This notebook tests whether a minimal, topology-first model can simulate an\nd falsify a low-energy nuclear reaction (LENR) cycle driven by breath-like EM co\nherence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1.1 Config — Toggles & Seeds\n",
    "\n",
    "# CONFIG\n",
    "USE_STAR   = True          # S1 only if False; S1..S4 if True\n",
    "USE_PADIC  = False\n",
    "USE_QUAT   = True          # optional: quaternion state\n",
    "RNG_SEED   = 13\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1.2 Imports\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from mpmath import mpf, power\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geometry & Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2.1 Geometry — S1..S4 shells with role policy\n",
    "\n",
    "ROLE_BY_MOD = {0: \"Compression\", 1: \"Expression\", 2: \"Stabilisation\", 3: \"Emission\"}\n",
    "\n",
    "def build_geometry(use_star: bool = True):\n",
    "    \"\"\"Builds the STAR graph geometry before policy enforcement.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    nodes = ['C', 'S'] + [str(i) for i in range(16)]\n",
    "    G.add_nodes_from(nodes)\n",
    "    \n",
    "    roles = {n: ('Mediator' if n == 'C' else 'Sink' if n == 'S' else ROLE_BY_MOD[int(n) % 4]) for n in G.nodes()}\n",
    "    shells = {n: (f\"S{1 + int(int(n) / 4)}\" if n.isdigit() else '*') for n in G.nodes()}\n",
    "    \n",
    "    # Add intra-shell edges for all 4 shells\n",
    "    for i in range(4):\n",
    "        b = i * 4\n",
    "        s = [str(b + j) for j in range(4)]\n",
    "        G.add_edge('C', s[1], kind='activation')\n",
    "        G.add_edge(s[1], s[2], kind='work')\n",
    "        G.add_edge(s[2], 'C', kind='squeeze')\n",
    "        G.add_edge('C', s[3], kind='fusion')\n",
    "        G.add_edge(s[3], s[0], kind='heat')\n",
    "        G.add_edge(s[0], 'C', kind='reset')\n",
    "\n",
    "    # Add inter-shell (cubic) and sink edges\n",
    "    for a, b in [(0, 4), (8, 12)]: G.add_edge(str(a), str(b), kind='compression'); G.add_edge(str(b), str(a), kind='compression')\n",
    "    for a, b in [(3, 6), (11, 14)]: G.add_edge(str(a), str(b), kind='work_bridge')\n",
    "    for e_node in [3, 7, 11, 15]: G.add_edge(str(e_node), 'C', kind='heat_bridge')\n",
    "    for e_node in [3, 7, 11, 15]: G.add_edge(str(e_node), 'S', kind='sink')\n",
    "    \n",
    "    # Define the connection policy\n",
    "    policy = {\n",
    "        'Compression': {'out': {'Mediator', 'Compression'}, 'in': {'Emission', 'Compression', 'Mediator'}},\n",
    "        'Expression': {'out': {'Stabilisation', 'Mediator'}, 'in': {'Mediator'}},\n",
    "        'Stabilisation': {'out': {'Mediator'}, 'in': {'Expression', 'Emission'}},\n",
    "        'Emission': {'out': {'Compression', 'Stabilisation', 'Mediator', 'Sink'}, 'in': {'Stabilisation', 'Mediator'}},\n",
    "        'Mediator': {'out': {'Expression', 'Emission', 'Compression', 'Stabilisation', 'Mediator', 'Sink'}, 'in': {'*'}},\n",
    "        'Sink': {'in': {'*'}} \n",
    "    }\n",
    "    return G, roles, shells, policy\n",
    "\n",
    "def enforce_policy(G, roles, policy):\n",
    "    \"\"\"Filters the graph, keeping only edges that conform to the policy.\"\"\"\n",
    "    keep = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        ru, rv = roles.get(u, 'Mediator'), roles.get(v, 'Mediator')\n",
    "        allowed_out = policy.get(ru, {}).get('out', set())\n",
    "        allowed_in = policy.get(rv, {}).get('in', set())\n",
    "        if ('*' in allowed_in or ru in allowed_in) and (rv in allowed_out):\n",
    "            keep.append((u, v, data))\n",
    "    \n",
    "    H = nx.DiGraph()\n",
    "    H.add_nodes_from(G.nodes())\n",
    "    H.add_edges_from(keep)\n",
    "    return H\n",
    "\n",
    "# Build and enforce\n",
    "G_raw, roles, shells, policy = build_geometry(USE_STAR)\n",
    "G0 = enforce_policy(G_raw, roles, policy)\n",
    "nx.set_node_attributes(G0, roles, 'role')\n",
    "nx.set_node_attributes(G0, shells, 'shell')\n",
    "G0.graph.update({'roles': roles, 'shells': shells, 'policy': policy})\n",
    "\n",
    "print(f\"Raw graph edges: {G_raw.number_of_edges()}\")\n",
    "print(f\"Policy-enforced graph: |V|={G0.number_of_nodes()} |E|={G0.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2.2 DEC Backbone — ∂ Operators & Rectangular Hodge Stars\n",
    "\n",
    "def build_dec_backbone(G):\n",
    "    \"\"\"Builds the DEC backbone to match the provided graph G.\"\"\"\n",
    "    # Sort nodes for consistent ordering, handling non-digit nodes\n",
    "    V = sorted(list(G.nodes()), key=lambda x: (not x.isdigit(), int(x) if x.isdigit() else float('inf'), x))\n",
    "    node_id = {v: i for i, v in enumerate(V)}\n",
    "    \n",
    "    # Generate faces for all shells from the graph's shell structure\n",
    "    F_tuples = []\n",
    "    shells = nx.get_node_attributes(G, 'shell')\n",
    "    shell_nodes = defaultdict(list)\n",
    "    for node, shell in shells.items():\n",
    "        if shell.startswith('S'):\n",
    "            shell_nodes[shell].append(node)\n",
    "    \n",
    "    for shell, nodes in shell_nodes.items():\n",
    "        # Outer faces of the tetrahedron\n",
    "        F_tuples.extend([(nodes[0],nodes[1],nodes[2]), (nodes[0],nodes[1],nodes[3]), (nodes[0],nodes[2],nodes[3]), (nodes[1],nodes[2],nodes[3])])\n",
    "        # Centroid-facing faces\n",
    "        if 'C' in V:\n",
    "            F_tuples.extend([(nodes[0],nodes[1],'C'), (nodes[0],nodes[2],'C'), (nodes[0],nodes[3],'C'), (nodes[1],nodes[2],'C'), (nodes[1],nodes[3],'C'), (nodes[2],nodes[3],'C')])\n",
    "    F = [tuple(sorted(f)) for f in F_tuples]\n",
    "    \n",
    "    # Edges are derived from the faces to form the simplicial complex\n",
    "    edges_backbone = sorted({tuple(sorted((a, b))) for a, b, c in F for a,b in [(a, b), (b, c), (c, a)]})\n",
    "    edge_id = {e: i for i, e in enumerate(edges_backbone)}\n",
    "    face_id = {f: i for i, f in enumerate(F)}\n",
    "    n_edges = len(edges_backbone)\n",
    "    n_faces = len(F)\n",
    "    \n",
    "    # Boundary Maps\n",
    "    B1 = np.zeros((len(V), n_edges), dtype=float)\n",
    "    for (u,v), ei in edge_id.items():\n",
    "        if u in node_id and v in node_id:\n",
    "            B1[node_id[u], ei] = -1.0\n",
    "            B1[node_id[v], ei] = 1.0\n",
    "    B1 = csr_matrix(B1)\n",
    "    \n",
    "    B2 = np.zeros((n_edges, n_faces), dtype=float)\n",
    "    for fj, (v0, v1, v2) in enumerate(F_tuples):\n",
    "        face_edges = [(v0,v1), (v1,v2), (v2,v0)]\n",
    "        for u,v in face_edges:\n",
    "            e_sorted = tuple(sorted((u,v)))\n",
    "            if e_sorted in edge_id:\n",
    "                sign = 1 if (u,v) == e_sorted else -1\n",
    "                B2[edge_id[e_sorted], fj] = sign\n",
    "    B2 = csr_matrix(B2)\n",
    "    \n",
    "    # Rectangular Hodge Stars (via incidence averaging)\n",
    "    Inc_fe = np.zeros((n_faces, n_edges))\n",
    "    for f_idx, face in enumerate(F):\n",
    "        face_nodes = set(face)\n",
    "        for e_idx, edge in enumerate(edges_backbone):\n",
    "            if set(edge).issubset(face_nodes):\n",
    "                Inc_fe[f_idx, e_idx] = 1.0\n",
    "    \n",
    "    face_deg = Inc_fe.sum(axis=1, keepdims=True)\n",
    "    face_deg[face_deg == 0] = 1.0\n",
    "    Inc_fe_avg = Inc_fe / face_deg\n",
    "    Inc_ef_avg = Inc_fe_avg.T\n",
    "\n",
    "    star_eps = csr_matrix(Inc_fe_avg)      # Edges -> Faces\n",
    "    star_muinv = csr_matrix(Inc_ef_avg)    # Faces -> Edges\n",
    "\n",
    "    # SPD Energy Forms\n",
    "    Se = (star_eps.T @ star_eps)\n",
    "    Sb = (star_muinv.T @ star_muinv)\n",
    "\n",
    "    # Damping Matrix R\n",
    "    damping_rates = {e: 0.1 if 'S' in e else 0.0 for e in edges_backbone}\n",
    "    R = csr_matrix(np.diag([damping_rates.get(e, 0.0) for e in edges_backbone]))\n",
    "\n",
    "    # Audits\n",
    "    inf_norm = np.max(np.abs(B1 @ B2)) if (B1 @ B2).nnz > 0 else 0.0\n",
    "    print(f\"[DEC Dims] |V|={len(V)} |E|={n_edges} |F|={n_faces}\")\n",
    "    print(f\"||B1·B2||_∞ = {inf_norm:.3e} (expect 0)\")\n",
    "    \n",
    "    return V, F, node_id, edge_id, face_id, B1, B2, star_eps, star_muinv, Se, Sb, R\n",
    "\n",
    "V, F, node_id, edge_id, face_id, B1, B2, star_eps, star_muinv, Se, Sb, R = build_dec_backbone(G0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2.3 Energy Forms & Power Pairings\n",
    "\n",
    "# Map J (faces) to edges for power pairing with E\n",
    "J_faces_to_edges = star_muinv # This is equivalent to Inc_ef_avg\n",
    "\n",
    "def edge_damping_power(E_vec):\n",
    "    return float(E_vec @ (R @ E_vec))\n",
    "\n",
    "def stored_energy(E_vec, B_vec):\n",
    "    return 0.5 * (E_vec @ (Se @ E_vec) + B_vec @ (Sb @ B_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Markov Layer & Simulation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3.1 Markov Layer & Breath Modulation\n",
    "\n",
    "def build_markov(G):\n",
    "    \"\"\"Adds 'rate' and 'kind' attributes to graph edges based on a base dictionary.\"\"\"\n",
    "    base = {\n",
    "        'activation': 0.5, 'work': 0.8, 'squeeze': 0.9, 'fusion': 0.7,\n",
    "        'heat': 1.0, 'reset': 0.3, 'compression': 0.3,\n",
    "        'work_bridge': 0.4, 'heat_bridge': 0.5, 'sink': 0.2\n",
    "    }\n",
    "    rates = {e: base.get(d.get('kind', 'work'), 0.5) for e, d in G.edges.items()}\n",
    "    kinds = {e: d.get('kind', 'work') for e, d in G.edges.items()}\n",
    "    nx.set_edge_attributes(G, rates, 'rate')\n",
    "    nx.set_edge_attributes(G, kinds, 'kind')\n",
    "    return rates, kinds\n",
    "\n",
    "EDGE_RATES, EDGE_KINDS = build_markov(G0)\n",
    "\n",
    "def apply_breath(G_base, step, inhale_gain=1.15, exhale_gain=1.10):\n",
    "    \"\"\"Applies breath-like modulation to edge rates.\"\"\"\n",
    "    phase = 'in' if (step % 2) == 0 else 'out'\n",
    "    G = G_base.copy()\n",
    "    roles = G.graph['roles']\n",
    "    sinks = {n for n, r in roles.items() if r == 'Compression'}\n",
    "    sources = {'C'}\n",
    "    pumps = {n for n, r in roles.items() if r in {'Expression', 'Emission'}}\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        rate = data['rate'] # Start with the base rate\n",
    "        if phase == 'in' and (v in sinks or v in sources): rate *= inhale_gain\n",
    "        elif phase == 'out' and (u in sources and v in pumps): rate *= exhale_gain\n",
    "        data['rate'] = rate # Update the rate for the current step\n",
    "    return G, phase\n",
    "\n",
    "print(f\"Markov layer: {len(EDGE_RATES)} edges across kinds {sorted(set(EDGE_KINDS.values()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3.2 Quaternion State & Coupling (Optional)\n",
    "\n",
    "def init_quaternion_state(G, roles):\n",
    "    Q = {n: np.zeros(4) for n in G.nodes()}\n",
    "    for n, r in roles.items():\n",
    "        if r == 'Compression': Q[n] = np.array([1.0, 0.0, 0.2, 0.0])\n",
    "        elif r == 'Expression': Q[n] = np.array([0.1, 1.0, 0.0, 0.0])\n",
    "        elif r == 'Stabilisation': Q[n] = np.array([0.0, 0.0, 1.0, 0.1])\n",
    "        elif r == 'Emission': Q[n] = np.array([0.0, 0.1, 0.0, 1.0])\n",
    "    return Q\n",
    "\n",
    "def project(flow_kind, vec):\n",
    "    arr = np.asarray(vec, dtype=float)\n",
    "    if flow_kind in ('work', 'activation'): return float(arr[1])\n",
    "    if flow_kind in ('squeeze', 'reset'): return float(arr[0] + arr[2])\n",
    "    if flow_kind in ('fusion', 'work_bridge'): return float(arr[3] + arr[1])\n",
    "    if flow_kind in ('heat', 'heat_bridge'): return float(arr[3])\n",
    "    if flow_kind == 'compression': return float(arr[0])\n",
    "    if flow_kind == 'sink': return float(arr.sum())\n",
    "    return 0.0\n",
    "\n",
    "QUAT_STATE = init_quaternion_state(G0, roles) if USE_QUAT else {}\n",
    "\n",
    "def _edge_sign_index(u, v, edge_id):\n",
    "    e_sorted = tuple(sorted((u,v)))\n",
    "    if e_sorted in edge_id:\n",
    "        sign = 1.0 if (u,v) == e_sorted else -1.0\n",
    "        return sign, edge_id[e_sorted]\n",
    "    return 0.0, None\n",
    "\n",
    "def markov_to_currents(Gk, edge_id, coherence_gain=0.1, state=None):\n",
    "    J = np.zeros(len(edge_id), dtype=float)\n",
    "    active_kinds = set(EDGE_KINDS.values()) - {'heat', 'heat_bridge', 'sink'}\n",
    "    state = QUAT_STATE if state is None and USE_QUAT else state\n",
    "    for u, v, data in Gk.edges(data=True):\n",
    "        kind, rate = data.get('kind'), data.get('rate', 0.0)\n",
    "        if kind not in active_kinds or rate <= 0.0: continue\n",
    "        sgn, ei = _edge_sign_index(u, v, edge_id)\n",
    "        if ei is None: continue\n",
    "        amp = project(kind, state.get(u, np.zeros(4))) if state else 1.0\n",
    "        J[ei] += sgn * coherence_gain * rate * amp\n",
    "    return J\n",
    "\n",
    "def accumulate_heat(Gk, dt, state):\n",
    "    \"\"\"Heat export coupled to live quaternion state.\"\"\"\n",
    "    total = 0.0\n",
    "    heat_kinds = {'heat', 'heat_bridge', 'sink'}\n",
    "    for u, v, d in Gk.edges(data=True):\n",
    "        if d.get('kind') not in heat_kinds: continue\n",
    "        rate = float(d.get('rate', 0.0))\n",
    "        vec  = state.get(u, np.zeros(4))\n",
    "        # Using k-component (inductive/emission) for heat coupling\n",
    "        kamp = float(vec[3])\n",
    "        total += rate * kamp\n",
    "    return total * dt\n",
    "\n",
    "if USE_QUAT: print(\"Quaternion state initialised.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3.3 Phase Linter\n",
    "\n",
    "def build_phase_linter(G, S1_nodes, S2_nodes):\n",
    "    \"\"\"Builds and returns the linter function.\"\"\"\n",
    "    node_list = sorted(list(G.nodes()), key=lambda x: (not x.isdigit(), int(x) if x.isdigit() else x))\n",
    "    idx = {k: i for i, k in enumerate(node_list)}\n",
    "    n_nodes = len(node_list)\n",
    "    kap = np.zeros((n_nodes, n_nodes))\n",
    "    theta = np.zeros_like(kap)\n",
    "\n",
    "    def _set_k(a, b, val): \n",
    "        if a in idx and b in idx: i, j = idx[a], idx[b]; kap[i,j]=val; kap[j,i]=val\n",
    "    def _set_th(a, b, rad): \n",
    "        if a in idx and b in idx: i, j = idx[a], idx[b]; theta[i,j]=rad; theta[j,i]=-rad\n",
    "\n",
    "    # Define couplings\n",
    "    for U in (S1_nodes, S2_nodes):\n",
    "        for i, u in enumerate(U): \n",
    "            for v in U[i+1:]: _set_k(u, v, 0.02)\n",
    "    _set_k('1', '2', 0.12); _set_th('1', '2', np.pi/2)\n",
    "    if USE_STAR:\n",
    "        _set_k('5', '6', 0.12); _set_th('5', '6', np.pi/2)\n",
    "        _set_k('3', '6', 0.08); _set_th('3', '6', np.pi/2)\n",
    "        for p in [('7','4'), ('7','2'), ('5','0')]: _set_k(*p, 0.05); _set_th(*p, np.pi)\n",
    "\n",
    "    gamma_C = 0.05\n",
    "    phi_state = np.zeros(n_nodes)\n",
    "\n",
    "    def linter_fn(step, dt=0.05, relax_steps=5):\n",
    "        nonlocal phi_state\n",
    "        for _ in range(relax_steps):\n",
    "            d_phi = np.zeros_like(phi_state)\n",
    "            for i, u in enumerate(node_list):\n",
    "                if u == 'C': continue\n",
    "                acc = sum(kap[i,j] * np.sin(phi_state[j] - phi_state[i] - theta[i,j]) for j in range(n_nodes) if i != j)\n",
    "                if 'C' in idx: acc -= gamma_C * np.sin(phi_state[i] - phi_state[idx['C']])\n",
    "                d_phi[i] = acc\n",
    "            phi_state += dt * d_phi\n",
    "            phi_state = (phi_state + np.pi) % (2 * np.pi) - np.pi\n",
    "        \n",
    "        errors = []\n",
    "        def err(a,b,trg): \n",
    "            if a in idx and b in idx: return np.degrees(np.abs(_wrap_pi((phi_state[idx[a]]-phi_state[idx[b]])-trg)))\n",
    "            return np.nan\n",
    "        errors.append(err('1','2',np.pi/2))\n",
    "        if USE_STAR: errors.extend([err('5','6',np.pi/2), err('3','6',np.pi/2)])\n",
    "        return np.nanmean([e for e in errors if np.isfinite(e)])\n",
    "\n",
    "    def _wrap_pi(x): return (x + np.pi) % (2 * np.pi) - np.pi\n",
    "    return linter_fn\n",
    "\n",
    "linter_fn = build_phase_linter(G0, [str(i) for i in range(4)], [str(i) for i in range(4,8)])\n",
    "print(\"Phase linter function 'linter_fn' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3.4 Core Engine — Leapfrog DEC Loop\n",
    "\n",
    "def run_lenr_core(\n",
    "    G_base, steps: int = 400, dt: float = 1e-3, coherence_gain: float = 0.1, \n",
    "    report_every: int = 20, state: dict = None):\n",
    "    \"\"\"Runs the main DEC simulation loop.\"\"\"\n",
    "    \n",
    "    B2t = B2.T.toarray()\n",
    "    \n",
    "    E = np.zeros(n_edges, dtype=float)\n",
    "    B = np.zeros(n_faces, dtype=float)\n",
    "    \n",
    "    # Initial condition: small pump on C->1 if it exists on the backbone\n",
    "    s, C1_idx = _edge_sign_index('C', '1', edge_id)\n",
    "    if C1_idx is not None: E[C1_idx] = 1e-4 * s\n",
    "    \n",
    "    U = stored_energy(E, B)\n",
    "    Q = 0.0\n",
    "    \n",
    "    hist = {k: [] for k in [\"heat\", \"energy\", \"residual\", \"phase_error\", \"samples\", \"Rc_in\", \"Rc_out\", \"sink_throughput\"]}\n",
    "    hist['dt'] = dt\n",
    "    \n",
    "    def _centroid_reliance_local(Gk):\n",
    "        total = sum(d.get('rate', 0.0) for u,v,d in Gk.edges(data=True))\n",
    "        via_c = sum(d.get('rate', 0.0) for u,v,d in Gk.edges(data=True) if u == 'C' or v == 'C')\n",
    "        return via_c / total if total > 0.0 else 0.0\n",
    "    \n",
    "    for n in range(steps):\n",
    "        Gk, phase = apply_breath(G_base, n)\n",
    "        J_work = markov_to_currents(Gk, edge_id, coherence_gain, state)\n",
    "        \n",
    "        # Faraday: dB/dt = - curl E\n",
    "        B -= dt * (B2.T @ E)\n",
    "\n",
    "        # Ampere: dE/dt = curl(H) - J_cond\n",
    "        H = star_muinv @ B\n",
    "        dE = (B2 @ H) - J_work\n",
    "        E += dt * dE - dt * (R @ E)\n",
    "        \n",
    "        # Accounting & Diagnostics\n",
    "        dQ = accumulate_heat(Gk, dt, QUAT_STATE) + edge_damping_power(E) * dt\n",
    "        Q_new = Q + dQ\n",
    "\n",
    "        U_new = stored_energy(E, B)\n",
    "        dU = U_new - U\n",
    "        # The injected work is implicitly handled by the J_work term in Ampere's law.\n",
    "        # The residual checks if the change in stored energy is balanced by dissipated heat.\n",
    "        residual = dU + dQ\n",
    "        \n",
    "        if n % report_every == 0 or n == steps - 1:\n",
    "            hist[\"heat\"].append(Q_new)\n",
    "            hist[\"energy\"].append(U_new)\n",
    "            hist[\"residual\"].append(residual)\n",
    "            hist[\"samples\"].append(n)\n",
    "            hist[\"phase_error\"].append(linter_fn(n))\n",
    "            hist[\"sink_throughput\"].append(dQ / dt)\n",
    "            rc = _centroid_reliance_local(Gk)\n",
    "            hist[f\"Rc_{phase}\"].append(rc)\n",
    "            \n",
    "        U, Q = U_new, Q_new\n",
    "            \n",
    "    return hist\n",
    "\n",
    "print(\"Core engine 'run_lenr_core' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Thermodynamic Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4.1 Markov Thermodynamics — Zeroth/Second/Third-Law Analogues\n",
    "\n",
    "def get_stationary_distribution(P, max_iter=1000, tol=1e-9):\n",
    "    \"\"\"Computes the stationary distribution of a Markov transition matrix P.\"\"\"\n",
    "    n = P.shape[0]\n",
    "    pi = np.ones(n) / n\n",
    "    for _ in range(max_iter):\n",
    "        pi_new = pi @ P\n",
    "        if np.allclose(pi, pi_new, atol=tol):\n",
    "            return pi_new\n",
    "        pi = pi_new\n",
    "    return pi\n",
    "\n",
    "def compute_epr(Pm, stationary):\n",
    "    \"\"\"Computes the entropy production rate (EPR) for a Markov process.\"\"\"\n",
    "    epr = 0.0\n",
    "    n_nodes = Pm.shape[0]\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(n_nodes):\n",
    "            if Pm[i, j] > 0 and stationary[i] > 0:\n",
    "                # Add a small epsilon to prevent log(0)\n",
    "                flux = stationary[i] * Pm[i, j]\n",
    "                ratio = Pm[i, j] / (Pm[j, i] + 1e-12)\n",
    "                if ratio > 0:\n",
    "                    epr += flux * np.log(ratio)\n",
    "    return epr\n",
    "\n",
    "# --- Normal Scenario ---\n",
    "n_nodes = len(V)\n",
    "P_normal = np.zeros((n_nodes, n_nodes))\n",
    "for u, v, data in G0.edges(data=True):\n",
    "    if u in node_id and v in node_id:\n",
    "        P_normal[node_id[u], node_id[v]] = data['rate']\n",
    "row_sums = P_normal.sum(axis=1, keepdims=True)\n",
    "P_normal = np.divide(P_normal, row_sums, where=row_sums!=0)\n",
    "pi_normal = get_stationary_distribution(P_normal)\n",
    "epr_normal = compute_epr(P_normal, pi_normal)\n",
    "\n",
    "# --- Counterfactual Scenario (2->1 like shortcut) ---\n",
    "# Find a policy-violating edge to add. E.g., Expression -> Expression is not allowed.\n",
    "# Let's add an edge from node '1' to '5' (both Expression).\n",
    "G_counter = G0.copy()\n",
    "G_counter.add_edge('1', '5', rate=0.5) # Arbitrary rate for the forbidden edge\n",
    "P_counter = np.zeros((n_nodes, n_nodes))\n",
    "for u, v, data in G_counter.edges(data=True):\n",
    "    if u in node_id and v in node_id:\n",
    "        P_counter[node_id[u], node_id[v]] = data['rate']\n",
    "row_sums_c = P_counter.sum(axis=1, keepdims=True)\n",
    "P_counter = np.divide(P_counter, row_sums_c, where=row_sums_c!=0)\n",
    "pi_counter = get_stationary_distribution(P_counter)\n",
    "epr_counter = compute_epr(P_counter, pi_counter)\n",
    "\n",
    "# --- Low-Theta Scenario ---\n",
    "theta = 0.1\n",
    "P_low_T = np.zeros((n_nodes, n_nodes))\n",
    "for u, v, data in G0.edges(data=True):\n",
    "    rate = data['rate']\n",
    "    if u in ['C', 'S'] or v in ['C', 'S']:\n",
    "        rate *= theta\n",
    "    if u in node_id and v in node_id:\n",
    "        P_low_T[node_id[u], node_id[v]] = rate\n",
    "row_sums_lt = P_low_T.sum(axis=1, keepdims=True)\n",
    "P_low_T = np.divide(P_low_T, row_sums_lt, where=row_sums_lt!=0)\n",
    "pi_low_T = get_stationary_distribution(P_low_T)\n",
    "epr_low_T = compute_epr(P_low_T, pi_low_T)\n",
    "\n",
    "print(f\"EPR (Normal): {epr_normal:.4f}\")\n",
    "print(f\"EPR (Counterfactual): {epr_counter:.4f}\")\n",
    "print(f\"EPR (Low-Theta): {epr_low_T:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simulation & Analysis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
