{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Berigny/AI-Entrainment-Protocol/blob/main/LENR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Low Energy Nuclear (LENR) Cycles Model\n",
    "This notebook tests whether a minimal, topology-first model can simulate and falsify a low-energy nuclear reaction (LENR) cycle driven by breath-like EM coherence. Using Discrete Exterior Calculus (DEC) on a star-tetrahedral complex with a shared centroid, we evolve fields, enforce first-law energy accounting, monitor entropy production and phase relations, and—optionally—add an adelic (ℝ × ℚ_p) layer to represent hierarchical memory at the fusion node. If quantised heat bursts do not emerge with lawful topology, pre-burst EM signatures, rising EPR, and correct energy balance, the hypothesis is weakened. If they do, we proceed to richer modelling and lab validation. The prize is significant: a path to low-cost, high-yield, sustainable energy in an energy-hungry world.\n",
    "\n",
    "## Falsification criteria\n",
    "\n",
    "We consider the LENR cycle unsupported if any lawful configuration fails to produce:\n",
    "(i) pre-burst EM coherence with ~90° E–M phase and centroid mediation,\n",
    "(ii) quantised heat steps at the sink,\n",
    "(iii) a non-negative EPR that rises prior to bursts, and\n",
    "(iv) first-law integrity (residual ≈ 0).\n",
    "Controls must behave as expected: illegal shortcuts reduce irreversibility or break energy accounting; removing C→3 or 1→2 kills bursts; random primes revert to baseline.\n",
    "\n",
    "## Notebook Overview & Research Aim\n",
    "### Goal\n",
    "- Simulate and *attempt to falsify* LENR-like cycles on a tetrahedral (and star-tetrahedral) topology.\n",
    "- If not falsified, motivate deeper modelling and lab tests for low-cost, high-yield, sustainable energy.\n",
    "### Key Ideas\n",
    "- DEC on simplicial complexes; mediation via centroid **C**; breath-driven, asymmetric flows; adelic (ℝ×ℚ_p) layer."
   ],
   "metadata": {
    "id": "qKR1ogm8760g"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pyright-config"
   },
   "source": [
    "# pyright: reportMissingImports=false, reportMissingModuleSource=false, reportUndefinedVariable=false\n",
    "# Static-analysis stubs; real values are set later during execution.\n",
    "try:\n",
    "    import mpmath  # type: ignore\n",
    "    import sympy  # type: ignore\n",
    "except Exception:\n",
    "    pass\n",
    "globals().setdefault('global_dt', 0.0)\n",
    "globals().setdefault('global_epsilon', 1.0)\n",
    "globals().setdefault('global_mu', 1.0)\n",
    "globals().setdefault('global_sigma', 0.0)\n",
    "globals().setdefault('n_edges', 0)\n",
    "globals().setdefault('n_faces', 0)\n",
    "globals().setdefault('edge_idx', {})\n",
    "globals().setdefault('phi_star', None)\n",
    "globals().setdefault('linter_fn', None)\n",
    "globals().setdefault('pe', None)\n",
    "globals().setdefault('n', None)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c3c07b46"
   },
   "source": [
    "\n",
    "# @title 1. **Config — toggles & seeds** { display-mode: \"form\" }\n",
    "# @markdown Core switches used by downstream cells.\n",
    "# 1. CONFIG\n",
    "USE_STAR   = True          # S1 only if False; S1..S4 if True\n",
    "USE_PADIC  = False\n",
    "USE_QUAT   = True          # optional: quaternion state\n",
    "RNG_SEED   = 13\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Geometry (simplices, orientations, dual volumes)"
   ],
   "metadata": {
    "id": "rWI-4DAHO92i"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "provenance": [],
     "authorship_tag": "ABX9TyOUOdgZOa632FOlGnwASH5Y",
     "include_colab_link": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb7ea8f2",
    "outputId": "23e99b22-1465-4e8b-d413-cbc88ceaab82"
   },
   "source": [
    "\n",
    "# @title 2. **Geometry — S1..S4 shells with role policy** { display-mode: \"form\" }\n",
    "# @markdown Builds the mediated star geometry with cubic bridges and enforces role guards.\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "ROLE_BY_MOD = {0: \"Compression\", 1: \"Expression\", 2: \"Stabilisation\", 3: \"Emission\"}\n",
    "\n",
    "def make_shell(base: int):\n",
    "    \"\"\"Return node ids for one shell S = {b,b+1,b+2,b+3,'C'}\"\"\"\n",
    "    return [str(base + i) for i in range(4)] + ['C']\n",
    "\n",
    "def build_geometry(use_star: bool = True):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      G         : DiGraph with nodes, intra-shell edges only\n",
    "      roles     : dict node->role ('Compression'/'Expression'/'Stabilisation'/'Emission'/'Mediator'/'Sink')\n",
    "      shells    : dict node->shell label ('S1'..'S4' or 'S1')\n",
    "      policy    : role-level bridge policy (for enforcement)\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    nodes = ['C'] + [str(i) for i in (range(4) if not use_star else range(16))]\n",
    "    shells = {}\n",
    "    roles = {n: ('Mediator' if n == 'C' else ROLE_BY_MOD[int(n) % 4]) for n in nodes}\n",
    "    for n in nodes:\n",
    "        if n == 'C' or not n.isdigit():\n",
    "            shells[n] = 'S1'\n",
    "        else:\n",
    "            shells[n] = f\"S{1 + int(int(n) / 4)}\" if use_star else 'S1'\n",
    "    G.add_nodes_from(nodes)\n",
    "\n",
    "    def add_shell_edges(b):\n",
    "        s = [str(b + i) for i in range(4)]\n",
    "        G.add_edge('C', s[1], kind='activation')\n",
    "        G.add_edge(s[1], s[2], kind='work')\n",
    "        G.add_edge(s[2], 'C', kind='squeeze')\n",
    "        G.add_edge('C', s[3], kind='fusion')\n",
    "        G.add_edge(s[3], s[0], kind='heat')\n",
    "        G.add_edge(s[0], 'C', kind='reset')\n",
    "\n",
    "    add_shell_edges(0)\n",
    "    if use_star:\n",
    "        for b in (4, 8, 12):\n",
    "            add_shell_edges(b)\n",
    "\n",
    "        for a, b in [(0, 4), (8, 12)]:\n",
    "            G.add_edge(str(a), str(b), kind='compression')\n",
    "            G.add_edge(str(b), str(a), kind='compression')\n",
    "\n",
    "        for a, b in [(3, 6), (11, 14)]:\n",
    "            G.add_edge(str(a), str(b), kind='work_bridge')\n",
    "\n",
    "        for e in [3, 7, 11, 15]:\n",
    "            G.add_edge(str(e), 'C', kind='heat_bridge')\n",
    "\n",
    "        G.add_node('S')\n",
    "        roles['S'] = 'Sink'\n",
    "        shells['S'] = '*'\n",
    "        for e in [3, 7, 11, 15]:\n",
    "            G.add_edge(str(e), 'S', kind='sink')\n",
    "\n",
    "    policy = {\n",
    "        'Compression': {'out': {'Mediator', 'Compression'}, 'in': {'Emission', 'Compression', 'Mediator'}},\n",
    "        'Expression': {'out': {'Stabilisation', 'Mediator'}, 'in': {'Mediator'}},\n",
    "        'Stabilisation': {'out': {'Mediator'}, 'in': {'Expression'}},\n",
    "        'Emission': {'out': {'Compression', 'Stabilisation', 'Mediator', 'Sink'}, 'in': {'Stabilisation', 'Mediator'}},\n",
    "        'Mediator': {'out': {'Expression', 'Emission', 'Compression', 'Stabilisation', 'Mediator', 'Sink'}, 'in': {'*'}}\n",
    "    }\n",
    "    return G, roles, shells, policy\n",
    "\n",
    "def enforce_policy(G, roles, policy):\n",
    "    keep = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        ru, rv = roles.get(u, 'Mediator'), roles.get(v, 'Mediator')\n",
    "        allowed_out = policy.get(ru, {}).get('out', set())\n",
    "        allowed_in = policy.get(rv, {}).get('in', set())\n",
    "        if ('*' in allowed_in or ru in allowed_in) and (rv in allowed_out):\n",
    "            if ru == 'Stabilisation' and rv == 'Expression':\n",
    "                continue\n",
    "            if ru == 'Emission' and rv == 'Emission':\n",
    "                continue\n",
    "            keep.append((u, v, data))\n",
    "    H = nx.DiGraph()\n",
    "    H.add_nodes_from(G.nodes())\n",
    "    H.add_edges_from(keep)\n",
    "    return H\n",
    "\n",
    "G0, roles, shells, policy = build_geometry(USE_STAR)\n",
    "G0 = enforce_policy(G0, roles, policy)\n",
    "\n",
    "nx.set_node_attributes(G0, roles, 'role')\n",
    "nx.set_node_attributes(G0, shells, 'shell')\n",
    "G0.graph['roles'] = roles\n",
    "G0.graph['shells'] = shells\n",
    "G0.graph['policy'] = policy\n",
    "\n",
    "role_counts = defaultdict(int)\n",
    "for r in roles.values():\n",
    "    role_counts[r] += 1\n",
    "\n",
    "print(f\"Geometry built (USE_STAR={USE_STAR}): |V|={G0.number_of_nodes()} |E|={G0.number_of_edges()}\")\n",
    "print(\"Roles:\", dict(role_counts))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8eb7eb44"
   },
   "source": [
    "# @title 0. **Notebook Overview & Research Aim** { display-mode: \"form\" }\n",
    "# @markdown **Goal**\n",
    "# @markdown - Simulate and *attempt to falsify* LENR-like cycles on a tetrahedral (and star-tetrahedral) topology.\n",
    "# @markdown - If not falsified, motivate deeper modelling and lab tests for low-cost, high-yield, sustainable energy.\n",
    "# @markdown **Key Ideas**\n",
    "# @markdown - DEC on simplicial complexes; mediation via centroid **C**; breath-driven, asymmetric flows; adelic (ℝ×ℚ_p) layer."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c3c07b46"
   },
   "source": [
    "# @title 1. **Imports & Global Config** { display-mode: \"form\" }\n",
    "# @markdown **What this sets**\n",
    "# @markdown - Imports, numeric precision/warnings, plotting defaults, reproducibility seeds.\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from mpmath import mpf, power\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7f7f6517"
   },
   "source": [
    "# @title 2. **Geometry — Single Tetra (S1): Nodes, Edges, Breath Rules** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Defines S1 vertices {0,1,2,3,C}, allowed directed edges, self-loops, and “breath” semantics (work vs heat).\n",
    "\n",
    "\n",
    "# Nodes: two tetrahedra share a single centroid C\n",
    "S1 = ['0','1','2','3']          # sinks even / branches odd\n",
    "S2 = ['4','5','6','7']\n",
    "ALL = S1 + S2 + ['C']\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(ALL)\n",
    "\n",
    "# Baseline rates (mpf for clean high-precision arithmetic)\n",
    "r = lambda x: mpf(str(x))\n",
    "\n",
    "# Core single-shell flows (work/heat + mediation)\n",
    "core_edges_S1 = [\n",
    "    ('C','1', {'rate': r(0.5)}),   # pump\n",
    "    ('1','2', {'rate': r(0.8)}),   # E→M (work)\n",
    "    ('2','C', {'rate': r(0.9)}),   # return to mediator\n",
    "    ('C','3', {'rate': r(0.7)}),   # squeeze/fusion path\n",
    "    ('3','0', {'rate': r(1.0)}),   # heat dump\n",
    "    ('0','C', {'rate': r(0.3)}),   # reset\n",
    "]\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "662659ce",
    "outputId": "c1a519d0-fc64-4ea6-ffae-c04099d35355"
   },
   "source": [
    "# @title 3. **Geometry — Star Tetra (S1 + S2) with Cubic Bridges** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Adds S2 vertices {4,5,6,7} and inter-tetra “cubic” bridges; encodes the cross-tetra flow sequence you specified.\n",
    "\n",
    "core_edges_S2 = [\n",
    "    ('C','5', {'rate': r(0.5)}),\n",
    "    ('5','6', {'rate': r(0.8)}),\n",
    "    ('6','C', {'rate': r(0.9)}),\n",
    "    ('C','7', {'rate': r(0.7)}),\n",
    "    ('7','4', {'rate': r(1.0)}),\n",
    "    ('4','C', {'rate': r(0.3)}),\n",
    "]\n",
    "\n",
    "# Cubic cross-edges (work bridge + heat dumps)\n",
    "cross_edges = [\n",
    "    ('3','6', {'rate': r(0.35)}),  # work bridge (coherent transfer S1→S2)\n",
    "    ('7','2', {'rate': r(0.25)}),  # heat-biased back to S1 magnetic\n",
    "    ('5','0', {'rate': r(0.20)}),  # heat dump assist into S1 sink\n",
    "    ('1','6', {'rate': r(0.20)}),  # optional assist E→M across shells\n",
    "]\n",
    "\n",
    "# Self-loops (stability/linger)\n",
    "self_loops = [(n, n, {'rate': r(0.4)}) for n in S1+S2]\n",
    "\n",
    "G.add_edges_from(core_edges_S1 + core_edges_S2 + cross_edges + self_loops)\n",
    "print(\"Graph ready. |V|=\", len(G.nodes), \"|E|=\", len(G.edges))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title 4. **DEC Operators — B₁, B₂ and Incidence-based Hodge Stars** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Builds boundary maps (nodes→edges, faces→edges) and rectangular Hodge stand-ins; checks shapes and orientations.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sympy import prime, factorint\n",
    "from mpmath import mpf, power\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# --- DEC BACKBONE (independent of Markov edges) ---\n",
    "# Use a fixed vertex set and face list; include centroid faces if you want C-curl.\n",
    "V = ['0','1','2','3','C']  # adjust if you’re in star mode\n",
    "F = [\n",
    "    ('0','1','2'), ('0','1','3'), ('0','2','3'), ('1','2','3'),        # outer tetra\n",
    "    ('0','1','C'), ('0','2','C'), ('0','3','C'), ('1','2','C'), ('1','3','C'), ('2','3','C')  # C faces\n",
    "]\n",
    "\n",
    "# Build an oriented edge set from faces (backbone edges)\n",
    "edges_backbone = sorted({(a,b) for (a,b,c) in F for (a,b) in ((a,b),(b,c),(c,a))})\n",
    "# Index maps for backbone\n",
    "node_id = {v:i for i,v in enumerate(V)}\n",
    "edge_id = {e:i for i,e in enumerate(edges_backbone)}\n",
    "face_id = {f:i for i,f in enumerate(F)}\n",
    "\n",
    "# B1_backbone: nodes×edges (∂1)\n",
    "B1 = np.zeros((len(V), len(edges_backbone)))\n",
    "for (u,v), ei in edge_id.items():\n",
    "    B1[node_id[u], ei] = -1.0\n",
    "    B1[node_id[v], ei] = +1.0\n",
    "B1 = csr_matrix(B1)\n",
    "\n",
    "# B2_backbone: edges×faces (∂2)\n",
    "B2 = np.zeros((len(edges_backbone), len(F)))\n",
    "for fj,(v0,v1,v2) in enumerate(F):\n",
    "    for (a,b) in ((v0,v1),(v1,v2),(v2,v0)):\n",
    "        sign = +1.0\n",
    "        e = (a,b)\n",
    "        if e not in edge_id:\n",
    "            # use reversed orientation if needed\n",
    "            e = (b,a); sign = -1.0\n",
    "        B2[edge_id[e], fj] += sign\n",
    "B2 = csr_matrix(B2)\n",
    "\n",
    "# Simple incidence-averaged rectangular Hodge stars on this backbone\n",
    "Inc_fe = np.zeros((len(F), len(edges_backbone)))\n",
    "for fj,(v0,v1,v2) in enumerate(F):\n",
    "    for (a,b) in ((v0,v1),(v1,v2),(v2,v0),(v1,v0),(v2,v1),(v0,v2)):\n",
    "        if (a,b) in edge_id:\n",
    "            Inc_fe[fj, edge_id[(a,b)]] = 1.0\n",
    "deg = Inc_fe.sum(axis=1, keepdims=True); deg[deg==0] = 1.0\n",
    "Inc_fe_avg = Inc_fe / deg\n",
    "star_eps   = csr_matrix(Inc_fe_avg)      # faces×edges\n",
    "star_muinv = csr_matrix(Inc_fe_avg.T)    # edges×faces\n",
    "\n",
    "# Energy forms\n",
    "Se = (star_eps.T @ star_eps).astype(float).toarray()\n",
    "Sb = (star_muinv.T @ star_muinv).astype(float).toarray()\n",
    "\n",
    "# Sanity: boundary of boundary\n",
    "bdb = (B1 @ B2).toarray()\n",
    "print(\"||B1·B2||_∞ =\", np.max(np.abs(bdb)))  # should be 0.0\n",
    "\n",
    "# Export edge index/counts for downstream cells\n",
    "edge_idx = dict(edge_id)\n",
    "n_edges = len(edge_idx)\n",
    "n_faces = len(face_id)\n",
    "print(f\"Backbone sizes: |E|={n_edges} |F|={n_faces}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1pqe2HQ_n5m",
    "outputId": "00f0c716-93d9-4c86-b94d-290e521882c3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Prep — Map Graph Sinks → DEC-Backbone Damping R { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Builds the sparse diagonal damping matrix **R** on the **DEC backbone** (edge index space),\n",
    "# @markdown   using your **directed Markov graph** `G`.\n",
    "# @markdown - For every graph edge that **ends at a sink** (default: `\"0\"`), assigns a small loss to the\n",
    "# @markdown   corresponding **backbone edge index**.\n",
    "# @markdown - If the exact orientation `(u,v)` is not present on the backbone, it will **fall back to `(v,u)`**\n",
    "# @markdown   (orientation doesn’t matter for scalar loss).\n",
    "# @markdown - Prints a short summary and lists any **graph sink-edges not found** on the backbone\n",
    "# @markdown   (e.g., cross-tetra “cubic” edges you didn’t include in the DEC face set).\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "def build_R_from_graph(\n",
    "    G,\n",
    "    edge_id,\n",
    "    sinks=(\"0\",),\n",
    "    loss=1e-2,\n",
    "    allow_reverse=True,\n",
    "    scale_by_attr=None,   # e.g. \"rate\" or \"loss_weight\" if you want per-edge scaling\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.DiGraph\n",
    "        Your transport/Markov graph (with attrs like 'rate', etc.)\n",
    "    edge_id : dict[(u,v)->int]\n",
    "        DEC backbone edge indexing (from your B2/backbone builder).\n",
    "    sinks : tuple[str]\n",
    "        Node labels considered as sinks (default (\"0\",)).\n",
    "    loss : float\n",
    "        Base damping to add for each sink-directed edge.\n",
    "    allow_reverse : bool\n",
    "        If (u,v) not found in backbone, try (v,u).\n",
    "    scale_by_attr : str | None\n",
    "        Optional graph edge attribute name to scale damping, e.g., scale by 'rate'.\n",
    "    verbose : bool\n",
    "        Print mapping summary and first few unmapped edges.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    R : scipy.sparse.csr_matrix (m×m)\n",
    "        Diagonal damping in backbone edge space (m = len(edge_id)).\n",
    "    \"\"\"\n",
    "    m = len(edge_id)\n",
    "    r = np.zeros(m, dtype=float)\n",
    "    mapped = 0\n",
    "    missing = []\n",
    "\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if str(v) not in sinks:\n",
    "            continue\n",
    "\n",
    "        # base loss, optionally scaled by an attribute (e.g., 'rate')\n",
    "        w = float(loss)\n",
    "        if scale_by_attr is not None and scale_by_attr in data:\n",
    "            try:\n",
    "                w *= float(data[scale_by_attr])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        ei = edge_id.get((str(u), str(v)))\n",
    "        if ei is None and allow_reverse:\n",
    "            ei = edge_id.get((str(v), str(u)))\n",
    "\n",
    "        if ei is not None:\n",
    "            r[ei] += w\n",
    "            mapped += 1\n",
    "        else:\n",
    "            missing.append((str(u), str(v)))\n",
    "\n",
    "    R = csr_matrix(np.diag(r))\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"R built from sinks {sinks}: mapped {mapped} graph edges → \"\n",
    "            f\"loss={loss:g} (nnz={R.nnz}/{m}).\"\n",
    "        )\n",
    "        if missing:\n",
    "            preview = \", \".join([f\"{e[0]}→{e[1]}\" for e in missing[:10]])\n",
    "            print(\n",
    "                f\"Unmapped sink-edges not on backbone (showing up to 10): {preview}\"\n",
    "                + (\" ...\" if len(missing) > 10 else \"\")\n",
    "            )\n",
    "            print(\n",
    "                \"Hint: If these are legitimate transport edges (e.g., cross-tetra/cubic), \"\n",
    "                \"consider adding their undirected versions to the DEC backbone face/edge set, \"\n",
    "                \"or accept that damping only applies on the backbone.\"\n",
    "            )\n",
    "\n",
    "    return R\n",
    "\n",
    "# --- Usage ---\n",
    "# Requires: G (graph), edge_id (from your DEC backbone), and optionally custom sinks.\n",
    "# Example: damp only edges that flow into '0' (heat sink)\n",
    "R = build_R_from_graph(G, edge_id, sinks=(\"0\",), loss=1e-2, allow_reverse=True, scale_by_attr=\"rate\", verbose=True)\n",
    "\n",
    "# If you already had an R and want to *augment* it (not replace), do e.g.:\n",
    "# R = R + build_R_from_graph(G, edge_id, sinks=(\"0\",), loss=1e-2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqI9gXCq9HoJ",
    "outputId": "b700e6ca-3066-4004-d5b5-383fd8cf7a2c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Prep — Cast DEC operators & globals to float (fix object dtypes) { display-mode: \"form\" }\n",
    "\n",
    "# Cast all scalar globals to plain floats\n",
    "global_dt = float(global_dt)\n",
    "global_epsilon = float(global_epsilon)\n",
    "global_mu = float(global_mu)\n",
    "global_sigma = float(global_sigma)\n",
    "\n",
    "# Cast sparse operators to float64\n",
    "B2         = B2.astype(float)\n",
    "star_eps   = star_eps.astype(float)\n",
    "star_muinv = star_muinv.astype(float)\n",
    "R          = R.astype(float)\n",
    "\n",
    "# If Se/Sb were built earlier, rebuild/cast them to float now\n",
    "Se = (star_eps.T @ star_eps).astype(float).toarray()\n",
    "Sb = (star_muinv.T @ star_muinv).astype(float).toarray()\n",
    "\n",
    "print(\"Dtypes:\",\n",
    "      \"\\n  B2:\", B2.dtype,\n",
    "      \"\\n  star_eps:\", star_eps.dtype,\n",
    "      \"\\n  star_muinv:\", star_muinv.dtype,\n",
    "      \"\\n  R:\", R.dtype,\n",
    "      \"\\n  Se:\", Se.dtype, \"Sb:\", Sb.dtype,\n",
    "      \"\\nScalars: dt, ε, μ, σ =\", global_dt, global_epsilon, global_mu, global_sigma)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBO8tCYN9irG",
    "outputId": "7302e6e1-1057-4584-a517-cfc42bbc9996"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a2db0ea",
    "outputId": "0d49dbc8-7475-41d3-e93c-3d96f5cc8155"
   },
   "source": [
    "# @title 6. **Baseline DEC Stepper (S1) — Energy & Frequency** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Uses your DEC operators (**B₂**, rectangular Hodge stars) to step **E (edges)** and **B (faces)**.\n",
    "# @markdown - Logs total energy via SPD forms (**Se, Sb**) and an “EEG-like” average-frequency proxy.\n",
    "# @markdown - Assumes Cells 4–5 have defined: `B2, star_eps, star_muinv, Se, Sb, R, edge_idx, n_edges, n_faces`.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ---- guards: require prior cells ----\n",
    "required = ['B2','star_eps','star_muinv','Se','Sb','R','edge_idx','n_edges','n_faces',\n",
    "            'global_dt', 'global_epsilon', 'global_mu', 'global_sigma']\n",
    "missing = [k for k in required if k not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Run DEC operator cells first; missing: {missing}\")\n",
    "\n",
    "# time step (use something small and stable; or reuse your CFL dt if available)\n",
    "dt = float(global_dt)\n",
    "ε  = float(global_epsilon)\n",
    "μ  = float(global_mu)\n",
    "σ  = float(global_sigma)\n",
    "\n",
    "\n",
    "# ---- fields on correct carriers ----\n",
    "E = np.zeros(n_edges, dtype=float)   # edges (1-form)\n",
    "B = np.zeros(n_faces, dtype=float)   # faces (2-form)\n",
    "\n",
    "# Initial condition: small pump on C→1 if present\n",
    "# (re)seed ICs as float\n",
    "idx = edge_idx.get(('C','1'))\n",
    "if idx is not None:\n",
    "    E[idx] = 1e-4\n",
    "else:\n",
    "    print(\"Note: edge ('C','1') not found; skipping pump init.\")\n",
    "\n",
    "\n",
    "def dec_step(E, B, dt):\n",
    "    \"\"\"One explicit DEC step: Faraday (faces) then Ampère (edges) with edge damping R.\"\"\"\n",
    "    # ensure float arrays (guards against stray mpf/object)\n",
    "    E = np.asarray(E, dtype=float)\n",
    "    B = np.asarray(B, dtype=float)\n",
    "\n",
    "    # Faraday: dB/dt = - curl(E)   with curl(E) = B2.T @ E  (faces)\n",
    "    curl_E = (B2.T @ E)                 # shape: (n_faces,)\n",
    "    B_new  = B - dt * curl_E            # faces\n",
    "\n",
    "    # Ampère (explicit, schematic): dE/dt = (1/ε) * (faces→edges) - (σ/ε)E - R E\n",
    "    # faces→edges is B2 @ B_new (edges)\n",
    "    drive  = (B2 @ B_new)               # shape: (n_edges,)\n",
    "    damping = (R @ E)                   # shape: (n_edges,)\n",
    "    E_new  = E + (dt/ε) * drive - (dt*σ/ε) * E - dt * damping\n",
    "\n",
    "    return E_new, B_new\n",
    "\n",
    "\n",
    "def energy_total(E, B):\n",
    "    # SPD quadratic energy (consistent with your rectangular stars)\n",
    "    return 0.5 * (E @ (Se @ E) + B @ (Sb @ B))\n",
    "\n",
    "def eeg_like_freq(history, E, B, dt):\n",
    "    # simple global-oscillation proxy from mean |E|, |B| slopes\n",
    "    Em = float(np.mean(np.abs(E)))\n",
    "    Bm = float(np.mean(np.abs(B)))\n",
    "    if len(history['E_mean']) >= 1:\n",
    "        dEm = (Em - history['E_mean'][-1]) / dt\n",
    "        dBm = (Bm - history['B_mean'][-1]) / dt\n",
    "        return float(np.hypot(dEm, dBm)), Em, Bm\n",
    "    return 0.0, Em, Bm\n",
    "\n",
    "# quick shape asserts (run once after defining B2, E, B)\n",
    "assert B2.shape == (n_edges, n_faces)\n",
    "assert (B2.T @ E).shape == (n_faces,)\n",
    "assert (B2 @ B).shape   == (n_edges,)\n",
    "\n",
    "\n",
    "# ---- run ----\n",
    "steps = 200\n",
    "t = 0.0\n",
    "# Initialize history outside the loop to accumulate data\n",
    "history = {\n",
    "    't': [],\n",
    "    'energy': [],\n",
    "    'freq': [],\n",
    "    'E_mean': [],\n",
    "    'B_mean': [],\n",
    "    'E_field': [],\n",
    "    'B_field': []\n",
    "}\n",
    "\n",
    "for k in range(steps):\n",
    "    # step\n",
    "    E, B = dec_step(E, B, dt)\n",
    "\n",
    "    # logs\n",
    "    U   = energy_total(E, B)\n",
    "    f, Em, Bm = eeg_like_freq(history, E, B, dt)\n",
    "\n",
    "    history['t'].append(t)\n",
    "    history['energy'].append(U)\n",
    "    history['freq'].append(f)\n",
    "    history['E_mean'].append(Em)\n",
    "    history['B_mean'].append(Bm)\n",
    "    history['E_field'].append(E.copy())\n",
    "    history['B_field'].append(B.copy())\n",
    "\n",
    "    if k % 50 == 0:\n",
    "        print(f\"Step {k:3d}  t={t:7.4f}  Energy={U:.3e}  ⟨|E|⟩={Em:.3e}  ⟨|B|⟩={Bm:.3e}  freq*={f:.2e}\")\n",
    "\n",
    "    t += dt\n",
    "\n",
    "# export for later\n",
    "baseline_history = history\n",
    "print(\"\\nDEC stepper complete → `baseline_history` with keys:\", list(baseline_history.keys()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "898ec073",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "outputId": "4c9c0f48-cb62-4097-9226-9056a3e6431c"
   },
   "source": [
    "# @title 7. **Markov Diagnostics — Mediation, Entropy, Mixing** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Builds discrete transition chains from your graph **G** (uses `data['rate']` on edges).\n",
    "# @markdown - Reports: Centroid reliance **R_C**, discrete **ΔE** (early Electric rise), entropy production **Σ** (Schnakenberg), spectral gap, **Kemeny** constant, and mean hitting times to sinks **{0, C}** (auto-pruned if missing).\n",
    "#\n",
    "# @markdown **Counterfactual**\n",
    "# @markdown - Optionally adds forbidden **2→1** (or **6→5** if S2 present) to test loss of mediation and lowered dissipation (EPR).\n",
    "import numpy as np\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def build_P_from_graph(G, node_idx, rate_attr='rate'):\n",
    "    n = len(node_idx)\n",
    "    P = np.zeros((n, n))\n",
    "    # Use node_idx to map original node labels to matrix indices\n",
    "    for u_orig, v_orig, data in G.edges(data=True):\n",
    "        u_str, v_str = str(u_orig), str(v_orig)\n",
    "        if u_str in node_idx and v_str in node_idx:\n",
    "            i, j = node_idx[u_str], node_idx[v_str]\n",
    "            P[i, j] = float(data.get(rate_attr, 0.0))\n",
    "    # row-normalise\n",
    "    for i in range(n):\n",
    "        s = P[i].sum()\n",
    "        if s > 0:\n",
    "            P[i] /= s\n",
    "    return P\n",
    "\n",
    "def roll_states(P, start_idx, steps=20):\n",
    "    n = P.shape[0]\n",
    "    x = np.zeros(n); x[start_idx] = 1.0\n",
    "    traj = [x.copy()]\n",
    "    for _ in range(steps):\n",
    "        x = x @ P\n",
    "        traj.append(x.copy())\n",
    "    return np.stack(traj)\n",
    "\n",
    "def centroid_reliance(states, node_idx, horizon=10):\n",
    "    if 'C' not in node_idx: return np.nan\n",
    "    c = node_idx['C']\n",
    "    T = min(horizon, states.shape[0])\n",
    "    return float(states[:T, c].mean())\n",
    "\n",
    "def electric_acceleration(states, node_idx, t1=1, t2=2):\n",
    "    # Prefer '1' (S1 electric); fall back to '5' (S2 electric) if needed\n",
    "    e_key = '1' if '1' in node_idx else ('5' if '5' in node_idx else None)\n",
    "    if e_key is None: return np.nan\n",
    "    e = node_idx[e_key]\n",
    "    if max(t1, t2) >= states.shape[0]: return np.nan\n",
    "    return float(states[t2, e] - states[t1, e])\n",
    "\n",
    "def absorbing_hitting_time(P, targets, node_idx):\n",
    "    # Make copy with targets absorbing\n",
    "    tgt_idx = [node_idx[t] for t in targets if t in node_idx]\n",
    "    if not tgt_idx:\n",
    "        return np.full(P.shape[0], np.nan)\n",
    "    Q_idx = [i for i in range(P.shape[0]) if i not in tgt_idx]\n",
    "    if not Q_idx:\n",
    "        # If all nodes are targets, hitting time from any node is 0\n",
    "        return np.zeros(P.shape[0])\n",
    "    Q = P[np.ix_(Q_idx, Q_idx)]\n",
    "    I = np.eye(Q.shape[0])\n",
    "    try:\n",
    "        N = np.linalg.inv(I - Q)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # Handle singular matrix (e.g., disconnected graph)\n",
    "        # Using pinv can give a result but interpret with caution\n",
    "        N = np.linalg.pinv(I - Q)\n",
    "    t_mean = N.sum(axis=1)  # expected steps to absorption from each transient\n",
    "    out = np.zeros(P.shape[0])\n",
    "    # Map results back to original full node indexing\n",
    "    # Ensure Q_idx length matches t_mean length\n",
    "    if len(Q_idx) == len(t_mean):\n",
    "        for k_q, i_orig in enumerate(Q_idx):\n",
    "            out[i_orig] = t_mean[k_q]\n",
    "    else:\n",
    "        # This case indicates a potential issue in Q/N calculation\n",
    "        print(\"Warning: Mismatch in transient node indices and hitting time results length.\")\n",
    "        # Fallback: fill with NaNs for safety\n",
    "        out.fill(np.nan)\n",
    "\n",
    "    return out\n",
    "\n",
    "def stationary_dist(P):\n",
    "    n = P.shape[0]\n",
    "    A = P.T - np.eye(n)\n",
    "    A[-1, :] = 1.0  # Add constraint that distribution sums to 1\n",
    "    b = np.zeros(n)\n",
    "    b[-1] = 1.0\n",
    "    try:\n",
    "        # Use pinv for potentially non-ergodic chains\n",
    "        pi = np.linalg.pinv(A) @ b\n",
    "        pi = np.real(pi)\n",
    "        pi = np.maximum(pi, 0)\n",
    "        s = pi.sum()\n",
    "        return (pi / s) if s > 0 else np.ones(n) / n\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Warning: Could not compute stationary distribution.\")\n",
    "        return np.ones(n) / n # Fallback to uniform distribution\n",
    "\n",
    "def entropy_production(P, eps=1e-12):\n",
    "    pi = stationary_dist(P)\n",
    "    n = P.shape[0]\n",
    "    Sigma = 0.0\n",
    "    for i in range(n):\n",
    "        for j in range(n): # Iterate over all pairs for detailed balance check\n",
    "            if i == j: continue\n",
    "            Jij = pi[i] * P[i, j]\n",
    "            Jji = pi[j] * P[j, i]\n",
    "            # Use absolute values for log argument to avoid issues with small negative numbers\n",
    "            # Add eps for numerical stability\n",
    "            if abs(Jij) > eps or abs(Jji) > eps:\n",
    "                Sigma += (Jij - Jji) * np.log((abs(Jij) + eps) / (abs(Jji) + eps))\n",
    "\n",
    "    # For Schnakenberg, sum over *distinct* pairs i != j only once, e.g., j > i.\n",
    "    # The formula is Sigma = 0.5 * Sum_{i!=j} (Jij - Jji) * log(Jij/Jji)\n",
    "    # The previous loop sums each pair twice (i,j) and (j,i), so divide by 2.\n",
    "    return float(Sigma * 0.5) # Divide by 2 for correct Schnakenberg formula\n",
    "\n",
    "def spectral_gap_and_kemeny(P):\n",
    "    n = P.shape[0]\n",
    "    vals = np.linalg.eigvals(P)\n",
    "    vals = np.real_if_close(vals)\n",
    "    # Sort eigenvalues by magnitude in descending order\n",
    "    sorted_indices = np.argsort(np.abs(vals))[::-1]\n",
    "    sorted_vals = vals[sorted_indices]\n",
    "\n",
    "    # Find the eigenvalue closest to 1 (should be 1 for ergodic chains)\n",
    "    idx_one = np.argmin(np.abs(sorted_vals - 1.0))\n",
    "    l1 = sorted_vals[idx_one]\n",
    "\n",
    "    # The second largest eigenvalue magnitude\n",
    "    if len(sorted_vals) > 1:\n",
    "       # Find the second largest eigenvalue by magnitude, excluding the one at 1\n",
    "       # Ensure there are eigenvalues other than 1 before accessing index 0 of the deleted array\n",
    "       non_one_vals = np.delete(sorted_vals, idx_one)\n",
    "       l2 = np.abs(non_one_vals)[0] if non_one_vals.size > 0 else 0.0\n",
    "    else:\n",
    "        l2 = 0.0\n",
    "\n",
    "    gap = float(1.0 - l2)\n",
    "\n",
    "    K = 0.0\n",
    "    # Kemeny constant formula sum_{k=2}^n 1/(1-lambda_k)\n",
    "    # Sum over all eigenvalues except the one at 1\n",
    "    for k in range(n):\n",
    "        # Use a tolerance when comparing to 1 to handle floating point inaccuracies\n",
    "        if abs(sorted_vals[k] - 1.0) < 1e-9:\n",
    "             continue\n",
    "        denom = 1.0 - sorted_vals[k]\n",
    "        if abs(denom) > 1e-9:\n",
    "            K += (1.0 / denom)\n",
    "        # else: if denominator is zero (another eigenvalue at 1), Kemeny is infinite. Handle with large number.\n",
    "        else:\n",
    "            K += 1e9 # Represent infinite Kemeny constant with a large number\n",
    "    return gap, float(K)\n",
    "\n",
    "def pick_start_index(node_idx):\n",
    "    # Prefer magnetic-like start: '2' in S1, else '6' in S2, else first node\n",
    "    for k in ('2', '6'):\n",
    "        if k in node_idx: return node_idx[k]\n",
    "    # Fallback to 'C' if available, otherwise first node\n",
    "    if 'C' in node_idx: return node_idx['C']\n",
    "    return 0 if node_idx else None # Return 0 if node_idx is not empty, otherwise None\n",
    "\n",
    "# ---------- build base chain ----------\n",
    "# Expect G in scope; if node_idx not present, build it.\n",
    "# Use the global G defined in cell 3, which includes all nodes\n",
    "if 'G' not in globals():\n",
    "    raise ValueError(\"Graph G not found. Run Cell 3 (Geometry — Star Tetra) first.\")\n",
    "\n",
    "# Re-build node_idx based on the current G to ensure consistency\n",
    "node_idx = {str(n): i for i, n in enumerate(G.nodes())}\n",
    "ALL_nodes_present = all(n in node_idx for n in ALL) # Check if all original nodes are in the current G\n",
    "\n",
    "if not node_idx:\n",
    "    print(\"Error: No nodes found in graph G.\")\n",
    "    P_norm = None\n",
    "else:\n",
    "    P_norm = build_P_from_graph(G, node_idx)\n",
    "    start_idx = pick_start_index(node_idx)\n",
    "    if start_idx is None:\n",
    "        print(\"Error: Could not determine a valid starting node.\")\n",
    "        traj_norm = None\n",
    "    else:\n",
    "        traj_norm = roll_states(P_norm, start_idx=start_idx, steps=20)\n",
    "\n",
    "    if traj_norm is not None:\n",
    "        Rc_norm   = centroid_reliance(traj_norm, node_idx, horizon=10)\n",
    "        dE_norm   = electric_acceleration(traj_norm, node_idx, t1=1, t2=2)\n",
    "    else:\n",
    "        Rc_norm, dE_norm = np.nan, np.nan\n",
    "\n",
    "    Sigma_norm = entropy_production(P_norm) if P_norm is not None else np.nan\n",
    "    gap_norm, K_norm = spectral_gap_and_kemeny(P_norm) if P_norm is not None else (np.nan, np.nan)\n",
    "    HT_norm = absorbing_hitting_time(P_norm, targets=['0', 'C'], node_idx=node_idx) if P_norm is not None else np.full(len(node_idx), np.nan)\n",
    "\n",
    "# ---------- counterfactual (optional 2→1 or 6→5) ----------\n",
    "add_counterfactual = True # This can be controlled by a form field later\n",
    "w_forbidden = 0.10 # This can be controlled by a form field later\n",
    "\n",
    "def add_forbidden_edge(Gin, node_idx, w):\n",
    "    Gx = Gin.copy()\n",
    "    tag = None\n",
    "    # Check if nodes exist before adding the edge\n",
    "    if '2' in node_idx and '1' in node_idx:\n",
    "        # Check if the edge already exists before adding to avoid errors in some graph types\n",
    "        if not Gx.has_edge('2', '1'):\n",
    "            Gx.add_edge('2', '1', rate=w)\n",
    "            tag = '2→1'\n",
    "        elif Gx['2']['1'].get('rate', 0.0) != w:\n",
    "            # Update rate if edge exists but rate is different\n",
    "            Gx['2']['1']['rate'] = w\n",
    "            tag = f'2→1 (rate updated to {w})'\n",
    "        else:\n",
    "            tag = '2→1 (edge already exists with same rate)'\n",
    "\n",
    "    elif '6' in node_idx and '5' in node_idx:\n",
    "        if not Gx.has_edge('6', '5'):\n",
    "            Gx.add_edge('6', '5', rate=w)\n",
    "            tag = '6→5'\n",
    "        elif Gx['6']['5'].get('rate', 0.0) != w:\n",
    "            Gx['6']['5']['rate'] = w\n",
    "            tag = f'6→5 (rate updated to {w})'\n",
    "        else:\n",
    "            tag = '6→5 (edge already exists with same rate)'\n",
    "\n",
    "    return Gx, tag\n",
    "\n",
    "if add_counterfactual:\n",
    "    # Use the original G to create the counterfactual graph\n",
    "    G_ctf, tag = add_forbidden_edge(G, node_idx, w_forbidden)\n",
    "    if tag is None or P_norm is None: # Also skip if normal P could not be built\n",
    "        print(\"Counterfactual skipped (no suitable nodes for forbidden edge or graph issues).\")\n",
    "        P_ctf = None\n",
    "    else:\n",
    "        # Re-build node_idx for the counterfactual graph to ensure consistency\n",
    "        node_idx_ctf = {str(n): i for i, n in enumerate(G_ctf.nodes())}\n",
    "        P_ctf = build_P_from_graph(G_ctf, node_idx_ctf)\n",
    "else:\n",
    "    P_ctf = None\n",
    "    tag = None\n",
    "\n",
    "# Ensure node_idx_ctf is defined if P_ctf is calculated\n",
    "if P_ctf is not None:\n",
    "    node_idx_ctf = {str(n): i for i, n in enumerate(G_ctf.nodes())}\n",
    "    # Use node_idx_ctf for counterfactual calculations\n",
    "    traj_ctf = roll_states(P_ctf, start_idx=pick_start_index(node_idx_ctf), steps=20)\n",
    "    if traj_ctf is not None:\n",
    "        Rc_ctf   = centroid_reliance(traj_ctf, node_idx_ctf, horizon=10)\n",
    "        dE_ctf   = electric_acceleration(traj_ctf, node_idx_ctf, t1=1, t2=2)\n",
    "    else:\n",
    "        Rc_ctf, dE_ctf = np.nan, np.nan\n",
    "\n",
    "    Sigma_ctf = entropy_production(P_ctf)\n",
    "    gap_ctf, K_ctf = spectral_gap_and_kemeny(P_ctf)\n",
    "    HT_ctf = absorbing_hitting_time(P_ctf, targets=['0', 'C'], node_idx=node_idx_ctf) # Use node_idx_ctf\n",
    "else:\n",
    "    Rc_ctf, dE_ctf, Sigma_ctf, gap_ctf, K_ctf = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    HT_ctf = np.full(len(node_idx), np.nan)\n",
    "\n",
    "\n",
    "# ---------- report ----------\n",
    "def fmt(v):\n",
    "    # Handle various NaN/None cases, format floats\n",
    "    if v is None or (isinstance(v, (float, np.float64)) and not np.isfinite(v)):\n",
    "        return \"nan\"\n",
    "    # Check if v is an array and format elements\n",
    "    if isinstance(v, np.ndarray):\n",
    "        return \"[\" + \", \".join(fmt(x) for x in v) + \"]\"\n",
    "    return f\"{v:.3f}\" # Default formatting for floats\n",
    "\n",
    "print(\"=== Markov Metrics ===\")\n",
    "print(f\"Centroid reliance R_C     : normal={fmt(Rc_norm)}\" + (f\" | counterfactual={fmt(Rc_ctf)}\" if P_ctf is not None else \"\"))\n",
    "print(f\"Electric acceleration ΔE   : normal={fmt(dE_norm)}\" + (f\" | counterfactual={fmt(dE_ctf)}\" if P_ctf is not None else \"\"))\n",
    "print(f\"Entropy production Σ       : normal={fmt(Sigma_norm)}\" + (f\" | counterfactual={fmt(Sigma_ctf)}\" if P_ctf is not None else \"\"))\n",
    "print(f\"Spectral gap (1-|λ2|)      : normal={fmt(gap_norm)}\" + (f\" | counterfactual={fmt(gap_ctf)}\" if P_ctf is not None else \"\"))\n",
    "print(f\"Kemeny constant            : normal={fmt(K_norm)}\" + (f\" | counterfactual={fmt(K_ctf)}\" if P_ctf is not None else \"\"))\n",
    "\n",
    "# Hitting times table\n",
    "def print_ht(label, HT, node_idx_for_ht, G_for_ht):\n",
    "    print(f\"Mean hitting time to {{0,C}} from each node ({label}):\")\n",
    "    # Iterate over the nodes actually present in the graph being reported on\n",
    "    # Sort nodes for consistent output order\n",
    "    sorted_nodes = sorted(G_for_ht.nodes(), key=str) # Simple string sort\n",
    "\n",
    "    # Check if node_idx_for_ht and HT have compatible sizes\n",
    "    if HT is not None and len(node_idx_for_ht) != len(HT):\n",
    "        print(f\"Warning: Node index size ({len(node_idx_for_ht)}) mismatch with HT array size ({len(HT)}) for {label} report.\")\n",
    "\n",
    "    for node_key_orig in sorted_nodes:\n",
    "        k = str(node_key_orig) # Ensure key is string for consistent lookup\n",
    "\n",
    "        # Safely get the node label, falling back to the key if node access fails\n",
    "        try:\n",
    "            node_label = G_for_ht.nodes[node_key_orig].get('label', k)\n",
    "        except KeyError:\n",
    "            # If direct access fails, use the string key as the label\n",
    "            node_label = k\n",
    "            print(f\"Warning: Could not access node attributes for key '{k}' in graph '{label}'. Using key as label.\")\n",
    "\n",
    "\n",
    "        # Get the hitting time value\n",
    "        v = np.nan # Default to NaN\n",
    "\n",
    "        if k in node_idx_for_ht:\n",
    "            idx = node_idx_for_ht[k]\n",
    "            if HT is not None and idx < len(HT): # Check index is within bounds of HT array\n",
    "                v = HT[idx]\n",
    "                 # Handle potential NaN/Inf from hitting time calculation\n",
    "                if not np.isfinite(v):\n",
    "                    v = 0.0 if k in ('0','C') else np.nan\n",
    "            elif k in ('0', 'C'):\n",
    "                 # If target node index is not valid for HT but is a target, report 0\n",
    "                v = 0.0\n",
    "            # else: If node is in node_idx but not a target and index is invalid/HT is None, v remains nan\n",
    "\n",
    "        elif k in ('0', 'C'):\n",
    "             # If target node is not in node_idx but is a target, report 0\n",
    "             v = 0.0\n",
    "        # else: If node exists in G_for_ht but not in node_idx_for_ht (unexpected), v remains nan\n",
    "\n",
    "\n",
    "        print(f\"  {node_label:>22s}: {fmt(v)}\")\n",
    "\n",
    "\n",
    "print_ht(\"normal\", HT_norm, node_idx, G) # Pass node_idx and G for normal report\n",
    "if P_ctf is not None and G_ctf is not None:\n",
    "    print_ht(f\"counterfactual ({tag})\", HT_ctf, node_idx_ctf, G_ctf) # Pass node_idx_ctf and G_ctf\n",
    "\n",
    "# Export for later cells\n",
    "markov_report = {\n",
    "    \"normal\": {\n",
    "        \"Rc\": Rc_norm, \"dE\": dE_norm, \"Sigma\": Sigma_norm,\n",
    "        \"gap\": gap_norm, \"Kemeny\": K_norm, \"HT\": HT_norm\n",
    "    }\n",
    "}\n",
    "if P_ctf is not None and G_ctf is not None:\n",
    "    markov_report[\"counterfactual\"] = {\n",
    "        \"tag\": tag, \"Rc\": Rc_ctf, \"dE\": dE_ctf, \"Sigma\": Sigma_ctf,\n",
    "        \"gap\": gap_ctf, \"Kemeny\": K_ctf, \"HT\": HT_ctf\n",
    "    }"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ace3d1f9"
   },
   "source": [
    "# @title 8. **Energy Balance Audit — Stored Energy vs Power Flows** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Defines SPD energy forms; compares dU/dt with (input − dissipation); residual should hover near zero.\n",
    "\n",
    "import numpy as np\n",
    "from mpmath import mpf\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Setup (Assumes Cell 6: baseline_history with 'energy', 'E_field', 'B_field') ---\n",
    "# Ensure globals exist from DEC Stepper\n",
    "try:\n",
    "    history = baseline_history # Corrected from global_history\n",
    "    dt = global_dt\n",
    "    ε = global_epsilon\n",
    "    μ = global_mu\n",
    "    σ = global_sigma\n",
    "except NameError:\n",
    "    raise ValueError(\"Run Cell 6 (DEC Stepper) first to set baseline_history, dt, ε, μ, σ\")\n",
    "\n",
    "# Graph (reuse from Cell 6 if available; mock for audit)\n",
    "if 'G' not in globals():\n",
    "    nodes = ['C', '0', '1', '2', '3']\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from([('C','1'), ('1','2'), ('2','C'), ('C','3'), ('3','0'), ('0','C')])\n",
    "\n",
    "# --- Power Flow Calculation ---\n",
    "def compute_power_flows(E, B, G, σ, ε):\n",
    "    \"\"\"Input power (proxy: pump at (C,1)) minus dissipation (Joule: σ |E|^2).\"\"\"\n",
    "    input_power = 0.0\n",
    "    if ('C', '1') in edge_idx:\n",
    "        input_power = abs(E[edge_idx[('C', '1')]]) * 1.0  # Source term (W/m)\n",
    "\n",
    "    # Dissipation: Integrated Joule heating σ |E|^2 over edges\n",
    "    dissipation = σ * np.sum(E**2)\n",
    "\n",
    "    return input_power - dissipation\n",
    "\n",
    "# --- Audit Loop (Over History) ---\n",
    "residuals = []\n",
    "dU_dt_vals = []\n",
    "power_net_vals = []\n",
    "n_steps = len(history['energy'])\n",
    "epsilon = 1e-18 # a small number to avoid division by zero\n",
    "\n",
    "if n_steps > 1:\n",
    "    for i in range(1, n_steps):\n",
    "        # Retrieve E/B from history\n",
    "        E = history['E_field'][i-1]  # Use previous for dU/dt consistency\n",
    "        B = history['B_field'][i-1]\n",
    "\n",
    "        # dU/dt (central finite difference approximation)\n",
    "        U_prev = history['energy'][i-1]\n",
    "        U_curr = history['energy'][i]\n",
    "        dU_dt = (U_curr - U_prev) / (dt + epsilon)\n",
    "\n",
    "        # Power net\n",
    "        power_net = compute_power_flows(E, B, G, σ, ε)\n",
    "\n",
    "        # Residual: |dU/dt - (input - dissipation)|\n",
    "        res = abs(float(dU_dt - power_net))\n",
    "        residuals.append(res)\n",
    "        dU_dt_vals.append(float(dU_dt))\n",
    "        power_net_vals.append(float(power_net))\n",
    "\n",
    "        # Early report\n",
    "        if i > 0 and i % 50 == 0:\n",
    "            print(f\"Step {i}: dU/dt={dU_dt:.2e}, Power Net={power_net:.2e}, Res={res:.2e}\")\n",
    "\n",
    "# --- Summary Stats ---\n",
    "if residuals:\n",
    "    mean_residual = np.mean(residuals)\n",
    "    max_residual = np.max(residuals)\n",
    "    std_residual = np.std(residuals)\n",
    "else:\n",
    "    mean_residual, max_residual, std_residual = np.nan, np.nan, np.nan\n",
    "\n",
    "U_final = history['energy'][-1] if history['energy'] else np.nan\n",
    "\n",
    "print(f\"\\n--- Energy Balance Audit Summary ---\")\n",
    "print(f\"Steps Audited: {len(residuals)}\")\n",
    "print(f\"Mean Residual: {mean_residual:.2e} (should hover ~0)\")\n",
    "print(f\"Max Residual: {max_residual:.2e}\")\n",
    "print(f\"Std Residual: {std_residual:.2e}\")\n",
    "print(f\"Final Stored Energy U: {float(U_final):.2e} J\")\n",
    "print(f\"Audit Status: {'PASS' if not np.isnan(mean_residual) and mean_residual < 1e-10 else 'FAIL'} (residual near zero)\")\n",
    "\n",
    "# --- Plot Residuals vs Time ---\n",
    "if residuals:\n",
    "    steps_plot = np.arange(1, len(residuals) + 1)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(steps_plot, dU_dt_vals, label='dU/dt', alpha=0.7)\n",
    "    ax1.plot(steps_plot, power_net_vals, label='Input - Dissipation', alpha=0.7)\n",
    "    ax1.set_title('Energy Rate vs Power Flows')\n",
    "    ax1.set_ylabel('Rate (J/s)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(steps_plot, residuals)\n",
    "    ax2.set_title('Residual |dU/dt - (Input - Dissipation)|')\n",
    "    ax2.set_ylabel('Residual')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Store for Later (e.g., Cell 15 plots) ---\n",
    "global_residuals = residuals\n",
    "global_dU_dt = dU_dt_vals\n",
    "global_power_net = power_net_vals\n",
    "\n",
    "print(\"\\nAudit complete. Residuals stored in global_residuals for visualizations.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bb2ece69"
   },
   "source": [
    "# @title 9. **Phase Linter — 90° E–M Lag & Anchor to C (S1 & Star)** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Kuramoto-style diagnostic layer; targets 90° E–M lag, gentle anchoring to C; reports phase error/spread (no feedback).\n",
    "import numpy as np\n",
    "\n",
    "# Assumes S1, S2, and a node_idx map are in the global scope.\n",
    "# If not, this cell will fail. Ensure geometry cells (2, 3) and an operator cell (e.g., 4) have run.\n",
    "\n",
    "# Define node_list based on detected S1/S2 to be robust\n",
    "node_list = []\n",
    "if 'S1' in globals(): node_list.extend(S1)\n",
    "if 'S2' in globals(): node_list.extend(S2)\n",
    "if 'C' in globals() and 'C' not in node_list: node_list.append('C')\n",
    "\n",
    "# Re-create index map based on the actual node list\n",
    "idx = {k: i for i, k in enumerate(node_list)}\n",
    "n_nodes_phase = len(node_list)\n",
    "\n",
    "# Initialize phase array if not present\n",
    "if 'phi_star' not in globals() or len(phi_star) != n_nodes_phase:\n",
    "    phi_star = np.zeros(n_nodes_phase)\n",
    "\n",
    "def _wrap_pi(x):\n",
    "    return (x + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "# --- Define Couplings and Target Lags ---\n",
    "kap = np.zeros((n_nodes_phase, n_nodes_phase))\n",
    "theta = np.zeros_like(kap)\n",
    "\n",
    "def set_kap(a, b, val):\n",
    "    if a in idx and b in idx:\n",
    "        i, j = idx[a], idx[b]\n",
    "        kap[i, j] = val\n",
    "        kap[j, i] = val\n",
    "\n",
    "def set_theta(a, b, rad):\n",
    "    if a in idx and b in idx:\n",
    "        i, j = idx[a], idx[b]\n",
    "        theta[i, j] = rad\n",
    "        theta[j, i] = -rad # Anti-symmetric for phi_j - phi_i\n",
    "\n",
    "# Baseline weak coupling for all nodes within each shell\n",
    "if 'S1' in globals():\n",
    "    for i, u in enumerate(S1):\n",
    "        for v in S1[i+1:]:\n",
    "            set_kap(u, v, 0.02)\n",
    "if 'S2' in globals():\n",
    "    for i, u in enumerate(S2):\n",
    "        for v in S2[i+1:]:\n",
    "            set_kap(u, v, 0.02)\n",
    "\n",
    "# Stronger E-M couplings within each shell\n",
    "set_kap('1', '2', 0.12)\n",
    "set_kap('5', '6', 0.12)\n",
    "set_theta('1', '2', np.pi / 2)\n",
    "set_theta('5', '6', np.pi / 2)\n",
    "\n",
    "# Work and heat bridge couplings\n",
    "set_kap('3', '6', 0.08); set_theta('3', '6', np.pi / 2) # Work\n",
    "set_kap('7', '4', 0.05); set_theta('7', '4', np.pi)     # Heat\n",
    "set_kap('7', '2', 0.05); set_theta('7', '2', np.pi)     # Heat\n",
    "set_kap('5', '0', 0.05); set_theta('5', '0', np.pi)     # Heat\n",
    "\n",
    "# Anchor to Centroid\n",
    "γC = 0.05\n",
    "\n",
    "def phase_step(phi, dt):\n",
    "    d_phi = np.zeros_like(phi)\n",
    "    # Iterate over all nodes that have a defined index\n",
    "    for u, i in idx.items():\n",
    "        if u == 'C': continue # Centroid is the anchor, does not update\n",
    "\n",
    "        acc = 0.0\n",
    "        # Interaction with other nodes\n",
    "        for v, j in idx.items():\n",
    "            if i == j: continue\n",
    "            acc += kap[i, j] * np.sin(phi[j] - phi[i] - theta[i, j])\n",
    "\n",
    "        # Anchor to Centroid (phi[idx['C']] is assumed to be 0)\n",
    "        if 'C' in idx:\n",
    "            acc -= γC * np.sin(phi[i] - phi[idx['C']])\n",
    "\n",
    "        d_phi[i] = acc\n",
    "\n",
    "    # Update phases (excluding the Centroid)\n",
    "    phi += dt * d_phi\n",
    "    # Keep centroid phase at 0\n",
    "    if 'C' in idx:\n",
    "        phi[idx['C']] = 0\n",
    "\n",
    "    return _wrap_pi(phi)\n",
    "\n",
    "def phase_report(phi):\n",
    "    report_data = {}\n",
    "    def err(a, b, trg):\n",
    "        if a in idx and b in idx:\n",
    "            i, j = idx[a], idx[b]\n",
    "            return float(np.degrees(_wrap_pi((phi[i] - phi[j]) - trg)))\n",
    "        return np.nan\n",
    "\n",
    "    report_data['EM_S1_deg'] = err('1', '2', np.pi/2)\n",
    "    report_data['EM_S2_deg'] = err('5', '6', np.pi/2)\n",
    "    report_data['work_3_6_deg'] = err('3', '6', np.pi/2)\n",
    "    report_data['heat_7_4_deg'] = err('7', '4', np.pi)\n",
    "    report_data['heat_7_2_deg'] = err('7', '2', np.pi)\n",
    "    report_data['heat_5_0_deg'] = err('5', '0', np.pi)\n",
    "    if 'C' in idx:\n",
    "        report_data['C_phase_deg'] = float(np.degrees(phi[idx['C']]))\n",
    "\n",
    "    return report_data\n",
    "\n",
    "# Example of running the phase linter for a few steps to let it settle\n",
    "# This part is for demonstration; the main simulation will call phase_step repeatedly\n",
    "print(\"Phase linter loaded. Running a few settling steps...\")\n",
    "for _ in range(50):\n",
    "    phi_star = phase_step(phi_star, dt=0.1)\n",
    "\n",
    "print(\"Settling complete. Current phase errors:\")\n",
    "print(phase_report(phi_star))\n",
    "\n",
    "# The linter functions (phase_step, phase_report) are now available for other cells."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ee8a0508"
   },
   "source": [
    "# @title 10. **Centroid Angle Probe — 109.471221° Mediation Test** { display-mode: \"form\" }\n",
    "\n",
    "# @markdown **What this does**\n",
    "\n",
    "# @markdown - Reweights edges to/from C by the tetrahedral bond angle; measures impact on mediation (R_C), hitting times, EPR."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "main-switch-cell"
   },
   "source": [
    "# @title Main — Select Pipeline and Geometry { display-mode: \"form\" }\n",
    "PIPELINE = \"fast\"   # \"fast\" (Cell 6 dec_step) or \"si\" (Cell 14 leapfrog_step)\n",
    "GEOMETRY = \"S1\"     # \"S1\" or \"STAR\"\n",
    "\n",
    "if PIPELINE == \"fast\":\n",
    "    print(\"Running baseline DEC stepper (dimensionless).\")\n",
    "    # call your run_cycle or the loop built in Cell 6, with GEOMETRY flag if supported\n",
    "    # e.g., baseline_history = run_cycle(..., geometry=GEOMETRY)\n",
    "elif PIPELINE == \"si\":\n",
    "    print(\"Running stable SI leapfrog stepper.\")\n",
    "    # e.g., si_history = run_star_tetra_cycle(..., geometry=GEOMETRY)\n",
    "else:\n",
    "    raise ValueError(\"Unknown PIPELINE.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8cdd9aab"
   },
   "source": [
    "# @title 11. **Adelic Layer — ℚ_p Utilities & Prime Sweep** { display-mode: \"form\" }\n",
    "\n",
    "# @markdown **What this does**\n",
    "\n",
    "# @markdown - Implements p-adic valuation/norm; builds composite “adelic balance”; sweeps primes (e.g., 2,3,5,7,11,…,137) for robustness."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# @title 3. **Markov layer & breath modulation** { display-mode: \"form\" }\n",
    "# @markdown Builds rate dictionaries, optional quaternion states, and breath modulation on enforced geometry.\n",
    "import numpy as np\n",
    "\n",
    "def build_markov(G):\n",
    "    \"\"\"Return edge list with rates by kind, no DEC coupling yet.\"\"\"\n",
    "    base = {\n",
    "        'activation': 0.5, 'work': 0.8, 'squeeze': 0.9, 'fusion': 0.7,\n",
    "        'heat': 1.0, 'reset': 0.3, 'compression': 0.3,\n",
    "        'work_bridge': 0.4, 'heat_bridge': 0.5, 'sink': 0.2\n",
    "    }\n",
    "    rates = {(u, v): base.get(data.get('kind', 'work'), 0.5) for u, v, data in G.edges(data=True)}\n",
    "    kinds = {(u, v): data.get('kind', 'work') for u, v, data in G.edges(data=True)}\n",
    "    return rates, kinds\n",
    "\n",
    "EDGE_RATES, EDGE_KINDS = build_markov(G0)\n",
    "G0.graph['edge_rates'] = EDGE_RATES\n",
    "G0.graph['edge_kinds'] = EDGE_KINDS\n",
    "\n",
    "def init_quaternion_state(G, roles):\n",
    "    \"\"\"Ψ_n = (e,h,d,b) initialised by role; scale as you like.\"\"\"\n",
    "    Q = {}\n",
    "    for n in G.nodes():\n",
    "        r = roles.get(n, 'Mediator')\n",
    "        if r == 'Compression':\n",
    "            Q[n] = np.array([1.0, 0.0, 0.2, 0.0])\n",
    "        elif r == 'Expression':\n",
    "            Q[n] = np.array([0.1, 1.0, 0.0, 0.0])\n",
    "        elif r == 'Stabilisation':\n",
    "            Q[n] = np.array([0.0, 0.0, 1.0, 0.1])\n",
    "        elif r == 'Emission':\n",
    "            Q[n] = np.array([0.0, 0.1, 0.0, 1.0])\n",
    "        else:\n",
    "            Q[n] = np.zeros(4)\n",
    "    return Q\n",
    "\n",
    "def project(flow_kind, vec):\n",
    "    \"\"\"Return scalar amplitude for a quaternion state by flow kind.\"\"\"\n",
    "    arr = np.asarray(vec, dtype=float).reshape(-1)\n",
    "    if arr.shape[0] < 4:\n",
    "        arr = np.pad(arr, (0, 4 - arr.shape[0]), constant_values=0.0)\n",
    "    if flow_kind in ('work', 'activation'):\n",
    "        return float(arr[1])\n",
    "    if flow_kind in ('squeeze', 'reset'):\n",
    "        return float(arr[0] + arr[2])\n",
    "    if flow_kind in ('fusion', 'work_bridge'):\n",
    "        return float(arr[3] + arr[1])\n",
    "    if flow_kind in ('heat', 'heat_bridge'):\n",
    "        return float(arr[3])\n",
    "    if flow_kind == 'compression':\n",
    "        return float(arr[0])\n",
    "    if flow_kind == 'sink':\n",
    "        return float(arr.sum())\n",
    "    return 0.0\n",
    "\n",
    "QUAT_STATE = init_quaternion_state(G0, G0.graph.get('roles', {})) if USE_QUAT else {}\n",
    "\n",
    "def apply_breath(\n",
    "    G_base,\n",
    "    step,\n",
    "    edge_rates=None,\n",
    "    inhale_gain=1.15,\n",
    "    exhale_gain=1.10,\n",
    "    sinks=None,\n",
    "    sources=None,\n",
    "    pumps=None,\n",
    "):\n",
    "    \"\"\"Scale edge rates by breath phase using role-aware defaults.\"\"\"\n",
    "    phase = 'in' if (step % 2) == 0 else 'out'\n",
    "    G = G_base.copy()\n",
    "    edge_rates = EDGE_RATES if edge_rates is None else edge_rates\n",
    "    roles = G0.graph.get('roles', {})\n",
    "    if sinks is None:\n",
    "        sinks = tuple(n for n, r in roles.items() if r == 'Compression')\n",
    "    if sources is None:\n",
    "        sources = ('C',)\n",
    "    if pumps is None:\n",
    "        pumps = tuple(n for n, r in roles.items() if r in {'Expression', 'Emission'})\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        base_rate = float(edge_rates.get((u, v), 0.0))\n",
    "        rate = base_rate\n",
    "        data['base_rate'] = base_rate\n",
    "        if phase == 'in' and (v in sinks or v in sources):\n",
    "            rate *= inhale_gain\n",
    "        elif phase == 'out' and (u in sources and v in pumps):\n",
    "            rate *= exhale_gain\n",
    "        data.setdefault('kind', EDGE_KINDS.get((u, v), data.get('kind', 'work')))\n",
    "        data['rate'] = rate\n",
    "    return G, phase\n",
    "\n",
    "print(f\"Markov layer: {len(EDGE_RATES)} edges across kinds {sorted(set(EDGE_KINDS.values()))}\")\n",
    "if USE_QUAT:\n",
    "    print(\"Quaternion state initialised for coherent projections.\")\n"
   ],
   "metadata": {
    "id": "lVELWkflMr7b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "83f6d39d-6e91-4b4e-afdc-750df57c383e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DEC operators (∂, Hodge stars, audits)"
   ],
   "metadata": {
    "id": "geaJ8kVwPFBv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title 4. **DEC Backbone — ∂ Operators & Diagonal Hodge Stars (with Audits)** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Builds the simplicial backbone (independent of the Markov graph): vertices, oriented edges, faces.\n",
    "# @markdown - Constructs boundary maps: **B₁** (nodes→edges) and **B₂** (edges→faces).\n",
    "# @markdown - Defines **diagonal SPD Hodge stars** `Star1` (edges×edges) and `Star2` (faces×faces).\n",
    "# @markdown - Runs audits: `||B₁·B₂||∞ ≈ 0`, ranks of B₁/B₂, SPD minima; exposes `energy_field(E,B)`.\n",
    "# @markdown **Notes**\n",
    "# @markdown - No rectangular/“incidence-averaged” Hodge stand-ins here. Those are deprecated.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# ---- 1) Vertex & face set (S1 always; S2 included if USE_STAR=True) ----\n",
    "try:\n",
    "    USE_STAR\n",
    "except NameError:\n",
    "    USE_STAR = False\n",
    "\n",
    "# Vertices: S1 plus shared centroid C; extend with S2 in star mode\n",
    "V = ['0','1','2','3','C'] + (['4','5','6','7'] if USE_STAR else [])\n",
    "\n",
    "# Faces:\n",
    "# - S1 outer + centroid faces\n",
    "F_S1_outer = [('0','1','2'), ('0','1','3'), ('0','2','3'), ('1','2','3')]\n",
    "F_S1_cent  = [('0','1','C'), ('0','2','C'), ('0','3','C'), ('1','2','C'), ('1','3','C'), ('2','3','C')]\n",
    "\n",
    "# - Optional S2 outer + centroid faces (only if USE_STAR)\n",
    "F_S2_outer = [('4','5','6'), ('4','5','7'), ('4','6','7'), ('5','6','7')]\n",
    "F_S2_cent  = [('4','5','C'), ('4','6','C'), ('4','7','C'), ('5','6','C'), ('5','7','C'), ('6','7','C')]\n",
    "\n",
    "F = F_S1_outer + F_S1_cent + (F_S2_outer + F_S2_cent if USE_STAR else [])\n",
    "\n",
    "# ---- 2) Oriented edges derived from faces (backbone edges only) ----\n",
    "edges_backbone = sorted({(a,b) for (a,b,c) in F for (a,b) in ((a,b),(b,c),(c,a))})\n",
    "\n",
    "# Index maps\n",
    "node_id = {v:i for i,v in enumerate(V)}\n",
    "edge_id = {e:i for i,e in enumerate(edges_backbone)}\n",
    "face_id = {f:i for i,f in enumerate(F)}\n",
    "\n",
    "# ---- 3) Boundary maps ----\n",
    "# B1: nodes×edges (∂1)\n",
    "B1 = np.zeros((len(V), len(edges_backbone)), dtype=float)\n",
    "for (u,v), ei in edge_id.items():\n",
    "    B1[node_id[u], ei] = -1.0\n",
    "    B1[node_id[v], ei] = +1.0\n",
    "B1 = csr_matrix(B1)\n",
    "\n",
    "# B2: edges×faces (∂2) with oriented incidence\n",
    "B2 = np.zeros((len(edges_backbone), len(F)), dtype=float)\n",
    "for fj,(v0,v1,v2) in enumerate(F):\n",
    "    for (a,b) in ((v0,v1),(v1,v2),(v2,v0)):\n",
    "        sign = +1.0\n",
    "        e = (a,b)\n",
    "        if e not in edge_id:\n",
    "            e = (b,a); sign = -1.0\n",
    "        B2[edge_id[e], fj] += sign\n",
    "B2 = csr_matrix(B2)\n",
    "\n",
    "# ---- 4) Diagonal Hodge stars (regularised circumcentric stand-ins) ----\n",
    "# Use a unit geometric scale here; SI scaling lives in the optional calibration cell.\n",
    "L = 1.0  # assumed primal edge length scale for now\n",
    "nE, nF = len(edges_backbone), len(F)\n",
    "\n",
    "\n",
    "# primal measures\n",
    "len_e  = np.full(nE, L, dtype=float)                       # |e|\n",
    "area_f = np.full(nF, (np.sqrt(3)/4.0)*L*L, dtype=float)    # |f| (equilateral)\n",
    "\n",
    "# crude-but-coherent dual measures for a regular/star tetra\n",
    "dual_e = np.full(nE, (L*L)/4.0, dtype=float)               # |*e|\n",
    "dual_f = np.full(nF, (L/3.0), dtype=float)                 # |*f|\n",
    "\n",
    "star1_diag = dual_e / len_e          # edges→edges\n",
    "star2_diag = dual_f / area_f         # faces→faces\n",
    "\n",
    "Star1 = np.diag(star1_diag)          # SPD\n",
    "Star2 = np.diag(star2_diag)\n",
    "\n",
    "def star1(x): return Star1 @ x\n",
    "def star2(x): return Star2 @ x\n",
    "\n",
    "# ---- 5) Audits ----\n",
    "D1 = B1.toarray(); D2 = B2.toarray()\n",
    "B1B2 = D1 @ D2\n",
    "inf_norm = float(np.max(np.abs(B1B2))) if B1B2.size else 0.0\n",
    "rank_D1 = int(np.linalg.matrix_rank(D1))\n",
    "rank_D2 = int(np.linalg.matrix_rank(D2))\n",
    "is_spd_star1 = bool(np.min(star1_diag) > 0)\n",
    "is_spd_star2 = bool(np.min(star2_diag) > 0)\n",
    "\n",
    "print(f\"[dims] |V|={len(V)} |E|={nE} |F|={nF}\")\n",
    "print(f\"||B1·B2||_∞ = {inf_norm:.3e} (expect 0)\")\n",
    "print(f\"rank(B1)={rank_D1}, rank(B2)={rank_D2}\")\n",
    "print(f\"Star1 SPD? {is_spd_star1}   Star2 SPD? {is_spd_star2}\")\n",
    "print(f\"star1_diag min/max = {star1_diag.min():.3e} / {star1_diag.max():.3e}\")\n",
    "print(f\"star2_diag min/max = {star2_diag.min():.3e} / {star2_diag.max():.3e}\")\n",
    "\n",
    "# ---- 6) Energy helper ----\n",
    "def energy_field(E, B):\n",
    "    \"\"\"Discrete EM energy: 0.5*(E⋅(⋆1 E) + B⋅(⋆2 B)).\"\"\"\n",
    "    return 0.5*(E @ (Star1 @ E) + B @ (Star2 @ B))\n",
    "\n",
    "# ---- 7) shape asserts ----\n",
    "\n",
    "assert D1.shape == (len(V), len(edge_id))          # nodes × edges\n",
    "assert D2.shape == (len(edge_id), len(F))          # edges × faces\n",
    "assert (D2.T @ np.zeros(D1.shape[1])).shape[0] == len(F)\n",
    "assert (D2 @ np.zeros(len(F))).shape[0] == len(edge_id)\n"
   ],
   "metadata": {
    "id": "b9aJlYAHbv8B",
    "outputId": "452b21bc-81a5-48df-970f-1fb39d96f9d6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# @title 5. **(Optional) SI Calibration — Scales, Materials & CFL Guard** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Sets dimensionful scales (edge length `L_m`), material guesses (ε_r, μ_r), and a conservative CFL-like `global_dt`\n",
    "# @markdown - Leaves DEC stars (`Star1/Star2`) untouched; use this only for reporting or SI-coupled experiments.\n",
    "\n",
    "import numpy as np\n",
    "from mpmath import mpf\n",
    "\n",
    "# ---- 1) Geometry scale (metres) ----\n",
    "L_m = mpf('1e-9')  # 1 nm representative edge length (tune as needed)\n",
    "\n",
    "# ---- 2) Materials (metal-like defaults) ----\n",
    "eps0 = mpf('8.854187817e-12')     # F/m\n",
    "mu0  = mpf('1.25663706212e-6')    # H/m\n",
    "eps_r = mpf('20')                  # relative permittivity (order 10–100)\n",
    "mu_r  = mpf('1')                   # non-magnetic\n",
    "sigma = mpf('1e6')                 # S/m (ballpark for metals; tune/disable if not using ohmic loss)\n",
    "\n",
    "eps = eps_r * eps0\n",
    "mu  = mu_r  * mu0\n",
    "c_si = 1.0 / float(np.sqrt(eps * mu))   # wave speed in medium\n",
    "\n",
    "# ---- 3) CFL-like time step guard (from Markov rates if available) ----\n",
    "def cfl_dt_from_rates(edge_rates, safety=0.1):\n",
    "    if not edge_rates:\n",
    "        return None\n",
    "    mr = max(float(r) for r in edge_rates.values())\n",
    "    if mr <= 0.0:\n",
    "        return None\n",
    "    return safety / mr\n",
    "\n",
    "dt_rate = cfl_dt_from_rates(EDGE_RATES, safety=0.1)\n",
    "\n",
    "# geometric CFL (Yee-like): dt ≤ 0.5 * L / c\n",
    "dt_geom = 0.5 * float(L_m) / float(c_si)\n",
    "\n",
    "# choose most conservative if both exist\n",
    "candidates = [x for x in (dt_rate, dt_geom) if x is not None]\n",
    "global_dt = min(candidates) if candidates else dt_geom\n",
    "\n",
    "# ---- 4) Export SI globals ----\n",
    "global_epsilon = float(eps)\n",
    "global_mu      = float(mu)\n",
    "global_sigma   = float(sigma)\n",
    "global_c       = float(c_si)\n",
    "\n",
    "print(f\"L = {float(L_m):.3e} m   eps_r={float(eps_r)}   mu_r={float(mu_r)}   sigma={float(sigma):.2e} S/m\")\n",
    "print(f\"c (medium) = {global_c:.3e} m/s\")\n",
    "print(f\"dt_geom = {dt_geom:.3e} s   dt_rate = {dt_rate if dt_rate is not None else 'n/a'}\")\n",
    "print(f\"=> global_dt = {global_dt:.3e} s\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1pqe2HQ_n5m",
    "outputId": "7c6c1390-e70e-4e93-d6ff-4b9acef0f97f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Time evolution (Maxwell-like DEC loop + optional Markov flux layer)"
   ],
   "metadata": {
    "id": "-_sS3jpKPOO2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title 6. **Coupling — Markov → DEC (edge currents & heat sink)** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Provides pure functions to couple the Markov layer to the DEC solver:\n",
    "# @markdown   • `markov_to_currents(Gk, edge_id, ...) → J` injects **coherent edge currents** on the DEC backbone.\n",
    "# @markdown   • `accumulate_heat(Gk, dt, ...) → ΔQ` integrates **dissipative heat** from designated edge kinds.\n",
    "# @markdown - Quaternion projections (optional) gate edge amplitudes via `project(kind, Ψ[u])`.\n",
    "# @markdown - Orientation-aware: if a directed Markov edge aligns with a DEC edge, +J; if reversed, −J; if not on the backbone, ignore.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _edge_sign_index(u, v, edge_id):\n",
    "    \"\"\"Return (sign, idx) for directed pair (u,v) against DEC backbone edge_id map.\"\"\"\n",
    "    uv = (u, v)\n",
    "    vu = (v, u)\n",
    "    if uv in edge_id:\n",
    "        return +1.0, edge_id[uv]\n",
    "    if vu in edge_id:\n",
    "        return -1.0, edge_id[vu]\n",
    "    return 0.0, None  # not on backbone\n",
    "\n",
    "def markov_to_currents(\n",
    "    Gk,\n",
    "    edge_id: dict,\n",
    "    coherence_gain: float = 0.1,\n",
    "    active_kinds: set | None = None,\n",
    "    state: dict | None = None,\n",
    "):\n",
    "    \"\"\"Map Markov rates to a coherent current vector J on DEC edges.\"\"\"\n",
    "    J = np.zeros(len(edge_id), dtype=float)\n",
    "    exclude = {'heat', 'heat_bridge', 'sink'}\n",
    "    if active_kinds is None:\n",
    "        active_kinds = set(EDGE_KINDS.values()) - exclude\n",
    "    state = QUAT_STATE if (state is None and USE_QUAT and QUAT_STATE) else state\n",
    "    for (u, v, data) in Gk.edges(data=True):\n",
    "        kind = data.get('kind', EDGE_KINDS.get((u, v), 'work'))\n",
    "        if kind not in active_kinds:\n",
    "            continue\n",
    "        rate = float(data.get('rate', 0.0))\n",
    "        if rate <= 0.0:\n",
    "            continue\n",
    "        sgn, ei = _edge_sign_index(str(u), str(v), edge_id)\n",
    "        if ei is None or sgn == 0.0:\n",
    "            continue\n",
    "        amp = 1.0\n",
    "        if state:\n",
    "            vec = state.get(str(u))\n",
    "            if vec is None: # Check for None explicitly\n",
    "                vec = state.get(u)\n",
    "            if vec is not None:\n",
    "                amp = float(np.asarray(project(kind, vec)))\n",
    "        J[ei] += sgn * coherence_gain * rate * amp\n",
    "    return J\n",
    "\n",
    "def accumulate_heat(\n",
    "    Gk,\n",
    "    dt: float,\n",
    "    heat_kinds: set | None = None,\n",
    "):\n",
    "    \"\"\"Integrate dissipative power from heat-class edges into a scalar sink Q.\"\"\"\n",
    "    if heat_kinds is None:\n",
    "        heat_kinds = {'heat', 'heat_bridge', 'sink'}\n",
    "    dQ = 0.0\n",
    "    for (u, v, data) in Gk.edges(data=True):\n",
    "        kind = data.get('kind', EDGE_KINDS.get((u, v), 'work'))\n",
    "        if kind not in heat_kinds:\n",
    "            continue\n",
    "        dQ += float(data.get('rate', 0.0)) * float(dt)\n",
    "    return dQ"
   ],
   "metadata": {
    "id": "3-57UGmhcWZz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "898ec073",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ee68d919-2d02-46b1-b452-5a20b7937920"
   },
   "source": [
    "\n",
    "# @title 7. **Core Engine — Leapfrog DEC Loop (Energy & Heat Audit)** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Integrates Maxwell-like fields on the DEC backbone with a **staggered (leapfrog/Yee)** scheme:\n",
    "# @markdown   • Faraday:   `B^{n+1/2} = B^{n-1/2} - dt * (∂₂ᵀ E^n)`\n",
    "# @markdown   • Ampère:    `⋆₁ E^{n+1} = ⋆₁ E^n + dt * (∂₁ᵀ ⋆₂ B^{n+1/2} - J^{n+1/2})`\n",
    "# @markdown - Couples to Markov layer via `apply_breath` (modulates rates) and `markov_to_currents` (injects **J** on edges).\n",
    "# @markdown - Audits **first-law closure**: logs field energy `U_field(t)`, cumulative heat `Q(t)`, and residual `Δ(U_field+Q)`.\n",
    "# @markdown\n",
    "# @markdown **Inputs expected from earlier cells**\n",
    "# @markdown - DEC: `B1, B2, Star1, Star2, energy_field`, and `edge_id` (from the DEC backbone cell).\n",
    "# @markdown - Markov: `G0` (geometry), `EDGE_RATES`, `EDGE_KINDS`, `apply_breath`, and optional `QUAT_STATE`.\n",
    "# @markdown - Optional SI: `global_dt` (else a safe dt is inferred from rates).\n",
    "# @markdown\n",
    "# @markdown **Outputs**\n",
    "# @markdown - `hist` dict with keys: `heat`, `energy`, `residual`, `phase`, `dt`, `samples`\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _safe_dt_from_rates(edge_rates, default_dt=1e-2, safety=0.1):\n",
    "    try:\n",
    "        mr = max((float(r) for r in edge_rates.values()), default=0.0)\n",
    "    except Exception:\n",
    "        mr = 0.0\n",
    "    if mr > 0.0:\n",
    "        return safety / mr\n",
    "    return default_dt\n",
    "\n",
    "def _edge_rate_weight(data, base_rates, u, v):\n",
    "    base_rates = globals().get('EDGE_RATES', {}) if base_rates is None else base_rates\n",
    "    rate = data.get('rate')\n",
    "    if rate is None:\n",
    "        rate = data.get('base_rate')\n",
    "    if rate is None and base_rates:\n",
    "        key = (str(u), str(v))\n",
    "        rate = base_rates.get(key, base_rates.get((u, v), 0.0))\n",
    "    try:\n",
    "        rate = float(rate)\n",
    "    except (TypeError, ValueError):\n",
    "        rate = 0.0\n",
    "    if not np.isfinite(rate) or rate < 0.0:\n",
    "        return 0.0\n",
    "    return rate\n",
    "\n",
    "def _centroid_reliance_local(Gk, base_rates=None):\n",
    "    base_rates = globals().get('EDGE_RATES', {}) if base_rates is None else base_rates\n",
    "    total = 0.0\n",
    "    via_c = 0.0\n",
    "    for u, v, data in Gk.edges(data=True):\n",
    "        w = _edge_rate_weight(data, base_rates, u, v)\n",
    "        total += w\n",
    "        if str(u) == 'C' or str(v) == 'C':\n",
    "            via_c += w\n",
    "    return via_c / total if total > 0.0 else 0.0\n",
    "\n",
    "def run_lenr_core(\n",
    "    G_base,\n",
    "    steps: int = 400,\n",
    "    dt: float | None = None,\n",
    "    coherence_gain: float = 0.1,\n",
    "    report_every: int = 20,\n",
    "    edge_rates: dict | None = None,\n",
    "    edge_kinds: dict | None = None,\n",
    "    state: dict | None = None,\n",
    "):\n",
    "    edge_rates = EDGE_RATES if edge_rates is None else edge_rates\n",
    "    edge_kinds = EDGE_KINDS if edge_kinds is None else edge_kinds\n",
    "    state = QUAT_STATE if (state is None and USE_QUAT and QUAT_STATE) else state\n",
    "\n",
    "    needed = ['B1', 'B2', 'Star1', 'Star2', 'energy_field', 'edge_id']\n",
    "    missing = [k for k in needed if k not in globals()]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing DEC objects: {missing}. Run the DEC backbone cell first.\")\n",
    "\n",
    "    D1 = B1.toarray()\n",
    "    D2 = B2.toarray()\n",
    "    DT1 = D1.T\n",
    "    DT2 = D2.T\n",
    "\n",
    "    star1_diag = np.diag(Star1).astype(float)\n",
    "    star2_mat = Star2\n",
    "    inv_star1_diag = 1.0 / star1_diag\n",
    "\n",
    "    if dt is None:\n",
    "        dt = globals().get('global_dt', None)\n",
    "    if dt is None:\n",
    "        dt = _safe_dt_from_rates(edge_rates, default_dt=1e-2, safety=0.1)\n",
    "    dt = float(dt)\n",
    "\n",
    "    nE = D1.shape[1]\n",
    "    nF = D2.shape[1]\n",
    "    E = np.zeros(nE, dtype=float)\n",
    "    Bf = np.zeros(nF, dtype=float)\n",
    "\n",
    "    Q_sink = 0.0\n",
    "    U_prev = energy_field(E, Bf)\n",
    "\n",
    "    hist = {\"heat\": [], \"energy\": [], \"residual\": [], \"phase\": [], \"dt\": dt, \"samples\": []}\n",
    "    rc_phase = {'in': [], 'out': []}\n",
    "    rc_samples = []\n",
    "    rc_phases = []\n",
    "\n",
    "    for n in range(steps):\n",
    "        Gk, phase = apply_breath(G_base, n, edge_rates=edge_rates)\n",
    "        rc_val = _centroid_reliance_local(Gk, base_rates=edge_rates)\n",
    "        rc_phase.setdefault(phase, []).append(rc_val)\n",
    "\n",
    "        J = markov_to_currents(Gk, edge_id=edge_id, coherence_gain=coherence_gain, state=state)\n",
    "\n",
    "        phase_err = None\n",
    "        if callable(linter_fn):\n",
    "            try:\n",
    "                phase_err = float(linter_fn(n))\n",
    "            except Exception:\n",
    "                phase_err = None\n",
    "        if phase_err is not None:\n",
    "            hist[\"phase_error\"].append(phase_err)\n",
    "            hist[\"phase_error_step\"].append(n)\n",
    "\n",
    "        Bf = Bf - dt * (DT2 @ E)\n",
    "\n",
    "        drive = D2 @ (Star2 @ Bf) - J\n",
    "        E = E + dt * (drive * inv_star1_diag)\n",
    "\n",
    "        Q_sink += accumulate_heat(Gk, dt)\n",
    "\n",
    "        U_now = energy_field(E, Bf)\n",
    "        residual = (U_now + Q_sink) - U_prev\n",
    "        U_prev = U_now + Q_sink\n",
    "\n",
    "        Em = float(np.mean(np.abs(E)))\n",
    "        Bm = float(np.mean(np.abs(Bf)))\n",
    "\n",
    "        if (n == 0) or (n % max(1, int(report_every)) == 0) or (n == steps - 1):\n",
    "            hist[\"heat\"].append(float(Q_sink))\n",
    "            hist[\"energy\"].append(float(U_now))\n",
    "            hist[\"residual\"].append(float(residual))\n",
    "            hist[\"phase\"].append(phase)\n",
    "            hist[\"samples\"].append(n)\n",
    "            rc_samples.append(rc_val)\n",
    "            rc_phases.append(phase)\n",
    "            hist.setdefault(\"E_mean\", []).append(Em)\n",
    "            hist.setdefault(\"B_mean\", []).append(Bm)\n",
    "            if 'pe' in globals() and pe is not None:\n",
    "                hist.setdefault(\"phase_error\", []).append(float(pe))\n",
    "\n",
    "    hist['Rc_samples'] = rc_samples\n",
    "    hist['Rc_phases'] = rc_phases\n",
    "    hist['Rc_in'] = float(np.mean(rc_phase['in'])) if rc_phase['in'] else np.nan\n",
    "    hist['Rc_out'] = float(np.mean(rc_phase['out'])) if rc_phase['out'] else np.nan\n",
    "    hist['Rc_in_series'] = rc_phase['in']\n",
    "    hist['Rc_out_series'] = rc_phase['out']\n",
    "    return hist\n",
    "\n",
    "print(\"USE_STAR:\", USE_STAR, \"|E|=\", len(edge_id), \"|F|=\", len(face_id))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Diagnostics (energy, EPR, phase, visuals)"
   ],
   "metadata": {
    "id": "cwVkgWSFPaxV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# @title 8. **Diagnostics — Energy, EPR & Phase Metrics (pure functions)** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Computes compact diagnostics from your core engine and Markov layer:\n",
    "# @markdown   • Energy & heat summaries from `hist`\n",
    "# @markdown   • Steady-state **EPR** (Schnakenberg) per sampled step using `apply_breath(G, n)`\n",
    "# @markdown   • Optional phase metrics if your `hist` includes them (else skipped)\n",
    "# @markdown   • Structural audits: centroid reliance, illegal edges (post-policy), sink throughput.\n",
    "# @markdown - Returns a `diag` dict you can print or plot.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def detect_bursts_from_Q(samples, heat, jitter_frac=0.1):\n",
    "    s = np.asarray(samples, dtype=int)\n",
    "    q = np.asarray(heat, dtype=float)\n",
    "    if q.size < 2:\n",
    "        return {\"n\": 0, \"unit\": 0.0, \"idx\": []}\n",
    "    dq = np.diff(q)\n",
    "    pos = dq[dq > 0]\n",
    "    if pos.size == 0:\n",
    "        return {\"n\": 0, \"unit\": 0.0, \"idx\": []}\n",
    "    unit = float(np.median(pos))\n",
    "    if not np.isfinite(unit) or unit <= 0:\n",
    "        unit = float(np.mean(pos)) if pos.size else 0.0\n",
    "    thresh = unit * (1.0 + float(jitter_frac)) if unit > 0 else float(np.max(pos))\n",
    "    if not np.isfinite(thresh):\n",
    "        thresh = 0.0\n",
    "    idx = [int(s[i + 1]) for i, delta in enumerate(dq) if delta > thresh]\n",
    "    return {\"n\": len(idx), \"unit\": unit, \"idx\": idx}\n",
    "\n",
    "def diag_centroid_reliance(G):\n",
    "    tot = G.number_of_edges()\n",
    "    viaC = sum(1 for u, v in G.edges() if u == 'C' or v == 'C')\n",
    "    edge_rates = globals().get('EDGE_RATES', {}) if edge_rates is None else edge_rates\n",
    "    if '_centroid_reliance_local' in globals():\n",
    "        return _centroid_reliance_local(G, base_rates=edge_rates)\n",
    "    total = 0.0\n",
    "    via_c = 0.0\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        rate = data.get('rate')\n",
    "        if rate is None:\n",
    "            rate = data.get('base_rate')\n",
    "        if rate is None:\n",
    "            key = (str(u), str(v))\n",
    "            rate = edge_rates.get(key, edge_rates.get((u, v), 0.0))\n",
    "        try:\n",
    "            weight = float(rate)\n",
    "        except (TypeError, ValueError):\n",
    "            weight = 0.0\n",
    "        if not np.isfinite(weight) or weight < 0.0:\n",
    "            weight = 0.0\n",
    "        total += weight\n",
    "        if str(u) == 'C' or str(v) == 'C':\n",
    "            via_c += weight\n",
    "    return via_c / total if total > 0.0 else 0.0\n",
    "\n",
    "def diag_role_audit(G, roles, policy):\n",
    "    H = enforce_policy(G.copy(), roles, policy)\n",
    "    return G.number_of_edges() - H.number_of_edges()\n",
    "\n",
    "def diag_sink_throughput(edge_rates, kinds):\n",
    "    return sum(r for (u, v), r in edge_rates.items() if kinds.get((u, v)) == 'sink')\n",
    "\n",
    "def _energy_summary(hist):\n",
    "    e = np.asarray(hist.get(\"energy\", []), dtype=float)\n",
    "    q = np.asarray(hist.get(\"heat\", []), dtype=float)\n",
    "    r = np.asarray(hist.get(\"residual\", []), dtype=float)\n",
    "    out = {\n",
    "        \"E_min\": float(np.nanmin(e)) if e.size else np.nan,\n",
    "        \"E_max\": float(np.nanmax(e)) if e.size else np.nan,\n",
    "        \"Q_final\": float(q[-1]) if q.size else np.nan,\n",
    "        \"resid_max_abs\": float(np.nanmax(np.abs(r))) if r.size else np.nan,\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def _build_generator(Gk, node_list=None):\n",
    "    \"\"\"Continuous-time generator Q from rates; nodes ordered by node_list or sorted labels.\"\"\"\n",
    "    if node_list is None:\n",
    "        node_list = sorted([str(n) for n in Gk.nodes()])\n",
    "    idx = {u: i for i, u in enumerate(node_list)}\n",
    "    n = len(node_list)\n",
    "    Q = np.zeros((n, n), dtype=float)\n",
    "    for u, v, d in Gk.edges(data=True):\n",
    "        u, v = str(u), str(v)\n",
    "        if u not in idx or v not in idx:\n",
    "            continue\n",
    "        rate = float(d.get('rate', 0.0))\n",
    "        if rate <= 0:\n",
    "            continue\n",
    "        i, j = idx[u], idx[v]\n",
    "        Q[i, j] += rate\n",
    "    for i in range(n):\n",
    "        Q[i, i] = -np.sum(Q[i, :])\n",
    "    return Q, node_list\n",
    "\n",
    "def _stationary_dist(Q):\n",
    "    \"\"\"Solve Q^T π = 0 with Σπ=1 (least-squares + constraint).\"\"\"\n",
    "    n = Q.shape[0]\n",
    "    A = np.vstack([Q.T, np.ones((1, n))])\n",
    "    b = np.zeros(n + 1)\n",
    "    b[-1] = 1.0\n",
    "    pi, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
    "    pi = np.clip(pi, 0.0, None)\n",
    "    s = pi.sum()\n",
    "    return (pi / s) if s > 0 else np.full(n, 1.0 / n)\n",
    "\n",
    "def _epr_schnakenberg(Gk, node_order=None):\n",
    "    \"\"\"Schnakenberg EPR at steady state: σ = Σ_{u<v} J_uv * ln( (π_u k_uv)/(π_v k_vu) ).\"\"\"\n",
    "    Q, nodes = _build_generator(Gk, node_order)\n",
    "    pi = _stationary_dist(Q)\n",
    "    idx = {u: i for i, u in enumerate(nodes)}\n",
    "    sigma = 0.0\n",
    "    seen = set()\n",
    "    for u, v, d in Gk.edges(data=True):\n",
    "        u, v = str(u), str(v)\n",
    "        if (v, u) in seen or u == v:\n",
    "            continue\n",
    "        seen.add((u, v))\n",
    "        k_uv = float(Gk[u][v].get('rate', 0.0))\n",
    "        k_vu = float(Gk[v][u].get('rate', 0.0)) if Gk.has_edge(v, u) else 0.0\n",
    "        i, j = idx[u], idx[v]\n",
    "        j_uv = pi[i] * k_uv - pi[j] * k_vu\n",
    "        num = (pi[i] * k_uv) if (pi[i] > 0 and k_uv > 0) else 0.0\n",
    "        den = (pi[j] * k_vu) if (pi[j] > 0 and k_vu > 0) else 0.0\n",
    "        if num > 0 and den > 0:\n",
    "            sigma += j_uv * np.log(num / den)\n",
    "        else:\n",
    "            if num > 0 and j_uv > 0:\n",
    "                sigma += j_uv * np.log(num / 1e-12)\n",
    "            elif den > 0 and j_uv < 0:\n",
    "                sigma += j_uv * np.log(1e-12 / den)\n",
    "    return float(max(sigma, 0.0))\n",
    "\n",
    "def compute_epr_series(G, hist, edge_rates=None):\n",
    "    \"\"\"EPR at each reported sample using breath-modulated G_k at sample step n.\"\"\"\n",
    "    samples = hist.get(\"samples\", [])\n",
    "    epr = []\n",
    "    edge_rates = EDGE_RATES if edge_rates is None else edge_rates\n",
    "    for n in samples:\n",
    "        Gk, _phase = apply_breath(G, int(n), edge_rates=edge_rates)\n",
    "        epr.append(_epr_schnakenberg(Gk))\n",
    "    return {\"samples\": samples, \"epr\": epr}\n",
    "\n",
    "def compute_phase_metrics(hist):\n",
    "    \"\"\"If you log phase errors, summarise; else return empty.\"\"\"\n",
    "    if \"phase_error\" in hist:\n",
    "        pe = np.asarray(hist[\"phase_error\"], dtype=float)\n",
    "        return {\"phase_err_mean\": float(np.nanmean(pe)), \"phase_err_max\": float(np.nanmax(np.abs(pe)))}\n",
    "    return {}\n",
    "\n",
    "def diagnostics(\n",
    "    G,\n",
    "    hist,\n",
    "    roles=None,\n",
    "    policy=None,\n",
    "    edge_rates=None,\n",
    "    edge_kinds=None,\n",
    "):\n",
    "    roles = G0.graph.get('roles', {}) if roles is None else roles\n",
    "    policy = G0.graph.get('policy', {}) if policy is None else policy\n",
    "    edge_rates = EDGE_RATES if edge_rates is None else edge_rates\n",
    "    edge_kinds = EDGE_KINDS if edge_kinds is None else edge_kinds\n",
    "    diag = {}\n",
    "    diag.update(_energy_summary(hist))\n",
    "    try:\n",
    "        diag.update({\"EPR_series\": compute_epr_series(G, hist, edge_rates=edge_rates)})\n",
    "    except Exception:\n",
    "        diag.update({\"EPR_series\": {\"samples\": hist.get(\"samples\", []), \"epr\": []}})\n",
    "    diag.update(compute_phase_metrics(hist))\n",
    "    diag[\"centroid_reliance\"] = diag_centroid_reliance(G, edge_rates=edge_rates)\n",
    "    diag[\"illegal_edges\"] = diag_role_audit(G, roles, policy)\n",
    "    sink_rates = np.asarray(hist.get(\"sink_rate\", []), dtype=float)\n",
    "    if sink_rates.size:\n",
    "        diag[\"sink_throughput\"] = float(np.nanmean(sink_rates))\n",
    "    else:\n",
    "        diag[\"sink_throughput\"] = diag_sink_throughput(edge_rates, edge_kinds)\n",
    "    diag['Rc_in'] = hist.get('Rc_in', np.nan)\n",
    "    diag['Rc_out'] = hist.get('Rc_out', np.nan)\n",
    "    return diag\n"
   ],
   "metadata": {
    "id": "npVHj1YjZm8-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title 9. **Phase Linter — Targets & Error (Diagnostic, Optional Control)** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Maintains a tiny Kuramoto-style phase model on the node set.\n",
    "# @markdown - Targets ~90° E–M lags (1–2, 5–6), ~90° work bridge (3–6), and ~180° heat dumps (7–4, 7–2, 5–0).\n",
    "# @markdown - Softly anchors the centroid **C** to 0 phase.\n",
    "# @markdown - Provides `linter_measure(step)` → mean phase-error (degrees), safe to call from the core loop.\n",
    "# @markdown\n",
    "# @markdown **Notes**\n",
    "# @markdown - Purely diagnostic by default (no coupling back to DEC); you can weight `J` later by `(1 - k*error)` if desired.\n",
    "# @markdown - Works for S1-only (`USE_STAR=False`) and Star (`USE_STAR=True`).\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- Node set consistent with your geometry flags ---\n",
    "try:\n",
    "    USE_STAR\n",
    "except NameError:\n",
    "    USE_STAR = False\n",
    "\n",
    "S1 = ['0','1','2','3']\n",
    "S2 = ['4','5','6','7'] if USE_STAR else []\n",
    "node_list = S1 + S2 + ['C']\n",
    "idx = {k:i for i,k in enumerate(node_list)}\n",
    "\n",
    "def _wrap_pi(x):  # [-pi, pi)\n",
    "    return (x + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "# --- Coupling matrix kap and target lags theta ---\n",
    "kap   = np.zeros((len(node_list), len(node_list)))\n",
    "theta = np.zeros_like(kap)\n",
    "\n",
    "def _set_k(a,b,val):\n",
    "    i,j = idx[a], idx[b]; kap[i,j]=val; kap[j,i]=val\n",
    "def _set_th(a,b,rad):\n",
    "    i,j = idx[a], idx[b]; theta[i,j]=rad; theta[j,i]=rad\n",
    "\n",
    "# Baseline weak all-to-all within each shell (helps smooth convergence)\n",
    "for U in (S1, S2):\n",
    "    for i,u in enumerate(U):\n",
    "        for v in U[i+1:]:\n",
    "            _set_k(u, v, 0.02)\n",
    "\n",
    "# Stronger targets: EM pairs, work bridge, heat dumps\n",
    "if all(n in idx for n in ('1','2')): _set_k('1','2',0.12); _set_th('1','2', np.pi/2)\n",
    "if USE_STAR and all(n in idx for n in ('5','6')): _set_k('5','6',0.12); _set_th('5','6', np.pi/2)\n",
    "if USE_STAR and all(n in idx for n in ('3','6')): _set_k('3','6',0.08); _set_th('3','6', np.pi/2)\n",
    "\n",
    "for pair in [('7','4'), ('7','2'), ('5','0')]:\n",
    "    if all(n in idx for n in pair):\n",
    "        _set_k(*pair, val=0.05); _set_th(*pair, rad=np.pi)\n",
    "\n",
    "# Soft anchor to C\n",
    "gamma_C = 0.05\n",
    "\n",
    "# --- State & helpers ---\n",
    "phi_state = np.zeros(len(node_list))  # global linter state (radians)\n",
    "\n",
    "def phase_step(phi, dt=0.05):\n",
    "    \"\"\"One explicit step of the linter ODE.\"\"\"\n",
    "    d = np.zeros_like(phi)\n",
    "    for u in (S1 + S2):\n",
    "        i = idx[u]\n",
    "        acc = 0.0\n",
    "        for v in (S1 + S2):\n",
    "            if v == u:\n",
    "                continue\n",
    "            j = idx[v]\n",
    "            acc += kap[i,j] * np.sin(phi[j] - phi[i] - theta[i,j])\n",
    "        acc -= gamma_C * np.sin(phi[i] - 0.0)   # anchor to C=0\n",
    "        d[i] = acc\n",
    "    phi[:len(S1)+len(S2)] += dt * d[:len(S1)+len(S2)]\n",
    "    return _wrap_pi(phi)\n",
    "\n",
    "def phase_report(phi):\n",
    "    \"\"\"Return key pair errors (deg) for readability.\"\"\"\n",
    "    def err(a,b,trg):\n",
    "        if a not in idx or b not in idx:\n",
    "            return np.nan\n",
    "        ia, ib = idx[a], idx[b]\n",
    "        return float(np.degrees(_wrap_pi((phi[ia] - phi[ib]) - trg)))\n",
    "    rep = {\"C_phase_deg\": float(np.degrees(phi[idx['C']]))}\n",
    "    if '1' in idx and '2' in idx: rep['EM_S1_deg']  = err('1','2', np.pi/2)\n",
    "    if '5' in idx and '6' in idx: rep['EM_S2_deg']  = err('5','6', np.pi/2)\n",
    "    if '3' in idx and '6' in idx: rep['work_3_6_deg'] = err('3','6', np.pi/2)\n",
    "    if '7' in idx and '4' in idx: rep['heat_7_4_deg'] = err('7','4', np.pi)\n",
    "    if '7' in idx and '2' in idx: rep['heat_7_2_deg'] = err('7','2', np.pi)\n",
    "    if '5' in idx and '0' in idx: rep['heat_5_0_deg'] = err('5','0', np.pi)\n",
    "    return rep\n",
    "\n",
    "def phase_error_deg(rep):\n",
    "    \"\"\"Mean absolute error (deg) across available targets.\"\"\"\n",
    "    vals = [abs(v) for k,v in rep.items() if k.endswith('_deg') and np.isfinite(v)]\n",
    "    return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "def linter_measure(step, relax_steps=5, dt=0.05):\n",
    "    \"\"\"\n",
    "    Advance the linter a few micro-steps (relax) and return mean phase-error (deg).\n",
    "    Safe to call each core step; uses global phi_state.\n",
    "    \"\"\"\n",
    "    global phi_state\n",
    "    for _ in range(relax_steps):\n",
    "        phi_state = phase_step(phi_state, dt=dt)\n",
    "    rep = phase_report(phi_state)\n",
    "    return phase_error_deg(rep)\n",
    "\n",
    "def phase_error_deg(phi_report_dict):\n",
    "    # use whatever your phase_report() returns; fall back to 0 if missing\n",
    "    keys = [k for k in phi_report_dict.keys() if k.endswith('_deg')]\n",
    "    vals = [abs(float(phi_report_dict[k])) for k in keys]\n",
    "    return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "\n",
    "# Optional diagnostic readout (phase linter)\n",
    "pe = None\n",
    "try:\n",
    "    pe = linter_measure(n)  # mean phase error in degrees\n",
    "except Exception:\n",
    "    pass\n",
    "print(\"phase error:\", pe)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "H1alXmWUH6bZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed8f41e7-3f6e-46d7-8220-a9e8ea08c73f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8cdd9aab",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "515dbef6-36fd-4ed6-cb2d-481fefb86abc"
   },
   "source": [
    "\n",
    "# @title 10. **Visualisations — Energy, Heat, Residuals, EPR, Phase** { display-mode: \"form\" }\n",
    "# @markdown **What this does**\n",
    "# @markdown - Plots the main diagnostics:\n",
    "# @markdown   • Cumulative heat `Q(t)` and field energy `U_field(t)`\n",
    "# @markdown   • Energy-closure residual `Δ(U+Q)` (should hover near 0)\n",
    "# @markdown   • EPR over sampled steps (if computable)\n",
    "# @markdown   • Phase error (if provided in `hist`)\n",
    "# @markdown - Prints a simple PASS/FLAG summary based on tolerances and structural gates.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_diagnostics(hist, diag, tol_resid=1e-6):\n",
    "    s = np.asarray(hist.get(\"samples\", []), dtype=int)\n",
    "    Q = np.asarray(hist.get(\"heat\", []), dtype=float)\n",
    "    U = np.asarray(hist.get(\"energy\", []), dtype=float)\n",
    "    R = np.asarray(hist.get(\"residual\", []), dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(6.0, 3.8))\n",
    "    if U.size:\n",
    "        plt.plot(s, U, label=\"Field energy U\")\n",
    "    if Q.size:\n",
    "        plt.plot(s, Q, label=\"Cumulative heat Q\")\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"energy (arb.)\")\n",
    "    plt.title(\"Energy / Heat\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if R.size:\n",
    "        plt.figure(figsize=(6.0, 3.2))\n",
    "        plt.plot(s, R)\n",
    "        plt.xlabel(\"step\")\n",
    "        plt.ylabel(\"Δ(U+Q)\")\n",
    "        plt.title(\"Energy-closure residual\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    epr_s = diag.get(\"EPR_series\", {})\n",
    "    epr_vals = np.asarray(epr_s.get(\"epr\", []), dtype=float)\n",
    "    epr_samps = np.asarray(epr_s.get(\"samples\", []), dtype=int)\n",
    "    if epr_vals.size:\n",
    "        plt.figure(figsize=(6.0, 3.2))\n",
    "        plt.plot(epr_samps, epr_vals)\n",
    "        plt.xlabel(\"step\")\n",
    "        plt.ylabel(\"EPR (nats/step)\")\n",
    "        plt.title(\"Entropy Production Rate\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if \"phase_error\" in hist:\n",
    "        pe = np.asarray(hist[\"phase_error\"], dtype=float)\n",
    "        if pe.size:\n",
    "            steps = hist.get(\"phase_error_step\", [])\n",
    "            if isinstance(steps, (list, tuple)) and len(steps) == len(pe):\n",
    "                ps = np.asarray(steps, dtype=int)\n",
    "            else:\n",
    "                ps = np.arange(len(pe))\n",
    "            plt.figure(figsize=(6.0, 3.2))\n",
    "            plt.plot(ps, pe)\n",
    "            plt.xlabel(\"step\")\n",
    "            plt.ylabel(\"phase error (deg)\")\n",
    "            plt.title(\"Phase error\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    resid_max = float(np.nanmax(np.abs(R))) if R.size else np.nan\n",
    "    resid_pass = (not np.isfinite(resid_max)) or (resid_max <= tol_resid)\n",
    "    print(f\"Residual max |Δ(U+Q)| = {resid_max:.3e} :: {'PASS' if resid_pass else 'FLAG'}\")\n",
    "\n",
    "def gate_report(diag):\n",
    "    rc_in = diag.get('Rc_in', np.nan)\n",
    "    rc_out = diag.get('Rc_out', np.nan)\n",
    "    illegal = diag.get('illegal_edges', np.nan)\n",
    "    sink_tp = diag.get('sink_throughput', np.nan)\n",
    "    print(f\"Centroid reliance (in) = {rc_in:.3f} :: {'PASS' if rc_in >= 0.6 else 'FLAG'}\")\n",
    "    print(f\"Centroid reliance (out) = {rc_out:.3f} :: {'PASS' if rc_out < 0.6 else 'FLAG'}\")\n",
    "    print(f\"Illegal edges (post-enforce) = {illegal} :: {'PASS' if illegal == 0 else 'FLAG'}\")\n",
    "    if np.isfinite(sink_tp):\n",
    "        print(f\"Sink throughput = {sink_tp:.3f} :: {'PASS' if sink_tp > 0 else 'FLAG'}\")\n",
    "    return rc_in, rc_out, illegal, sink_tp\n",
    "\n",
    "# 0) Safety: inline plots (harmless if already set)\n",
    "%matplotlib inline\n",
    "\n",
    "# 1) Rebuild G (Geometry), Breath, DEC, Coupling — then:\n",
    "hist = run_lenr_core(\n",
    "    G0,\n",
    "    steps=120,\n",
    "    dt=None,\n",
    "    coherence_gain=0.1,\n",
    "    report_every=1,\n",
    "    edge_rates=EDGE_RATES,\n",
    "    edge_kinds=EDGE_KINDS,\n",
    "    state=QUAT_STATE,\n",
    ")\n",
    "print(\"counts:\", {k: len(hist.get(k, [])) for k in [\"samples\", \"energy\", \"heat\", \"residual\"]})\n",
    "\n",
    "# 2) Build diagnostics + plot (robust plotter handles missing x)\n",
    "diag = diagnostics(G0, hist, roles=G0.graph.get('roles', {}), policy=G0.graph.get('policy', {}), edge_rates=EDGE_RATES, edge_kinds=EDGE_KINDS)\n",
    "plot_diagnostics(hist, diag)\n",
    "gate_report(diag)\n",
    "\n",
    "bd = detect_bursts_from_Q(hist.get(\"samples\", []), hist.get(\"heat\", []), jitter_frac=0.15)\n",
    "print(f\"Bursts: {bd['n']} | unit ≈ {bd['unit']:.3e} | idx: {bd['idx'][:10]}\")\n",
    "phase_samples = len(hist.get(\"phase_error\", []))\n",
    "print(f\"Phase samples: {phase_samples}\")\n",
    "rc_in_mean = hist.get('Rc_in', np.nan)\n",
    "rc_out_mean = hist.get('Rc_out', np.nan)\n",
    "print(f\"R_C mean (in,out): {rc_in_mean:.3f} {rc_out_mean:.3f}\")\n",
    "sink_vals = np.asarray(hist.get(\"sink_rate\", []), dtype=float)\n",
    "sink_throughput = float(np.nanmean(sink_vals)) if sink_vals.size else float('nan')\n",
    "print(f\"Sink throughput (mean rate): {sink_throughput:.3f}\")\n",
    "\n",
    "print(\"counts:\", {k: len(hist.get(k, [])) for k in [\"samples\", \"energy\", \"heat\", \"residual\", \"phase_error\", \"phase_error_step\", \"sink_rate\", \"Rc_in_series\", \"Rc_out_series\", \"E_mean\", \"B_mean\"]})\n",
    "print(\"shapes:\", \"B1\", B1.shape, \"B2\", B2.shape, \"Star1\", np.diag(Star1).shape, \"Star2\", np.diag(Star2).shape)\n",
    "print(\"USE_STAR:\", USE_STAR, \"|E|=\", len(edge_id), \"|F|=\", len(face_id))\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}