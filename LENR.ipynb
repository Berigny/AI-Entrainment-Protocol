{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUOdgZOa632FOlGnwASH5Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berigny/AI-Entrainment-Protocol/blob/main/LENR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Low Energy Nuclear (LENR) Cycles Model\n",
        "This notebook tests whether a minimal, topology-first model can simulate and falsify a low-energy nuclear reaction (LENR) cycle driven by breath-like EM coherence. Using Discrete Exterior Calculus (DEC) on a star-tetrahedral complex with a shared centroid, we evolve fields, enforce first-law energy accounting, monitor entropy production and phase relations, and—optionally—add an adelic (ℝ × ℚ_p) layer to represent hierarchical memory at the fusion node. If quantised heat bursts do not emerge with lawful topology, pre-burst EM signatures, rising EPR, and correct energy balance, the hypothesis is weakened. If they do, we proceed to richer modelling and lab validation. The prize is significant: a path to low-cost, high-yield, sustainable energy in an energy-hungry world.\n",
        "\n",
        "## Falsification criteria\n",
        "\n",
        "We consider the LENR cycle unsupported if any lawful configuration fails to produce:\n",
        "(i) pre-burst EM coherence with ~90° E–M phase and centroid mediation,\n",
        "(ii) quantised heat steps at the sink,\n",
        "(iii) a non-negative EPR that rises prior to bursts, and\n",
        "(iv) first-law integrity (residual ≈ 0).\n",
        "Controls must behave as expected: illegal shortcuts reduce irreversibility or break energy accounting; removing C→3 or 1→2 kills bursts; random primes revert to baseline."
      ],
      "metadata": {
        "id": "qKR1ogm8760g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eb7eb44"
      },
      "source": [
        "# @title 0. **Notebook Overview & Research Aim** { display-mode: \"form\" }\n",
        "# @markdown **Goal**\n",
        "# @markdown - Simulate and *attempt to falsify* LENR-like cycles on a tetrahedral (and star-tetrahedral) topology.\n",
        "# @markdown - If not falsified, motivate deeper modelling and lab tests for low-cost, high-yield, sustainable energy.\n",
        "# @markdown **Key Ideas**\n",
        "# @markdown - DEC on simplicial complexes; mediation via centroid **C**; breath-driven, asymmetric flows; adelic (ℝ×ℚ_p) layer."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3c07b46"
      },
      "source": [
        "# @title 1. **Imports & Global Config** { display-mode: \"form\" }\n",
        "# @markdown **What this sets**\n",
        "# @markdown - Imports, numeric precision/warnings, plotting defaults, reproducibility seeds.\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from mpmath import mpf, power\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f7f6517"
      },
      "source": [
        "# @title 2. **Geometry — Single Tetra (S1): Nodes, Edges, Breath Rules** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines S1 vertices {0,1,2,3,C}, allowed directed edges, self-loops, and “breath” semantics (work vs heat).\n",
        "\n",
        "\n",
        "# Nodes: two tetrahedra share a single centroid C\n",
        "S1 = ['0','1','2','3']          # sinks even / branches odd\n",
        "S2 = ['4','5','6','7']\n",
        "ALL = S1 + S2 + ['C']\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(ALL)\n",
        "\n",
        "# Baseline rates (mpf for clean high-precision arithmetic)\n",
        "r = lambda x: mpf(str(x))\n",
        "\n",
        "# Core single-shell flows (work/heat + mediation)\n",
        "core_edges_S1 = [\n",
        "    ('C','1', {'rate': r(0.5)}),   # pump\n",
        "    ('1','2', {'rate': r(0.8)}),   # E→M (work)\n",
        "    ('2','C', {'rate': r(0.9)}),   # return to mediator\n",
        "    ('C','3', {'rate': r(0.7)}),   # squeeze/fusion path\n",
        "    ('3','0', {'rate': r(1.0)}),   # heat dump\n",
        "    ('0','C', {'rate': r(0.3)}),   # reset\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "662659ce",
        "outputId": "c1a519d0-fc64-4ea6-ffae-c04099d35355"
      },
      "source": [
        "# @title 3. **Geometry — Star Tetra (S1 + S2) with Cubic Bridges** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Adds S2 vertices {4,5,6,7} and inter-tetra “cubic” bridges; encodes the cross-tetra flow sequence you specified.\n",
        "\n",
        "core_edges_S2 = [\n",
        "    ('C','5', {'rate': r(0.5)}),\n",
        "    ('5','6', {'rate': r(0.8)}),\n",
        "    ('6','C', {'rate': r(0.9)}),\n",
        "    ('C','7', {'rate': r(0.7)}),\n",
        "    ('7','4', {'rate': r(1.0)}),\n",
        "    ('4','C', {'rate': r(0.3)}),\n",
        "]\n",
        "\n",
        "# Cubic cross-edges (work bridge + heat dumps)\n",
        "cross_edges = [\n",
        "    ('3','6', {'rate': r(0.35)}),  # work bridge (coherent transfer S1→S2)\n",
        "    ('7','2', {'rate': r(0.25)}),  # heat-biased back to S1 magnetic\n",
        "    ('5','0', {'rate': r(0.20)}),  # heat dump assist into S1 sink\n",
        "    ('1','6', {'rate': r(0.20)}),  # optional assist E→M across shells\n",
        "]\n",
        "\n",
        "# Self-loops (stability/linger)\n",
        "self_loops = [(n, n, {'rate': r(0.4)}) for n in S1+S2]\n",
        "\n",
        "G.add_edges_from(core_edges_S1 + core_edges_S2 + cross_edges + self_loops)\n",
        "print(\"Graph ready. |V|=\", len(G.nodes), \"|E|=\", len(G.edges))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph ready. |V|= 9 |E|= 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. **DEC Operators — B₁, B₂ and Incidence-based Hodge Stars** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds boundary maps (nodes→edges, faces→edges) and rectangular Hodge stand-ins; checks shapes and orientations.\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sympy import prime, factorint\n",
        "from mpmath import mpf, power\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# --- DEC BACKBONE (independent of Markov edges) ---\n",
        "# Use a fixed vertex set and face list; include centroid faces if you want C-curl.\n",
        "V = ['0','1','2','3','C']  # adjust if you’re in star mode\n",
        "F = [\n",
        "    ('0','1','2'), ('0','1','3'), ('0','2','3'), ('1','2','3'),        # outer tetra\n",
        "    ('0','1','C'), ('0','2','C'), ('0','3','C'), ('1','2','C'), ('1','3','C'), ('2','3','C')  # C faces\n",
        "]\n",
        "\n",
        "# Build an oriented edge set from faces (backbone edges)\n",
        "edges_backbone = sorted({(a,b) for (a,b,c) in F for (a,b) in ((a,b),(b,c),(c,a))})\n",
        "# Index maps for backbone\n",
        "node_id = {v:i for i,v in enumerate(V)}\n",
        "edge_id = {e:i for i,e in enumerate(edges_backbone)}\n",
        "face_id = {f:i for i,f in enumerate(F)}\n",
        "\n",
        "# B1_backbone: nodes×edges (∂1)\n",
        "B1 = np.zeros((len(V), len(edges_backbone)))\n",
        "for (u,v), ei in edge_id.items():\n",
        "    B1[node_id[u], ei] = -1.0\n",
        "    B1[node_id[v], ei] = +1.0\n",
        "B1 = csr_matrix(B1)\n",
        "\n",
        "# B2_backbone: edges×faces (∂2)\n",
        "B2 = np.zeros((len(edges_backbone), len(F)))\n",
        "for fj,(v0,v1,v2) in enumerate(F):\n",
        "    for (a,b) in ((v0,v1),(v1,v2),(v2,v0)):\n",
        "        sign = +1.0\n",
        "        e = (a,b)\n",
        "        if e not in edge_id:\n",
        "            # use reversed orientation if needed\n",
        "            e = (b,a); sign = -1.0\n",
        "        B2[edge_id[e], fj] += sign\n",
        "B2 = csr_matrix(B2)\n",
        "\n",
        "# Simple incidence-averaged rectangular Hodge stars on this backbone\n",
        "Inc_fe = np.zeros((len(F), len(edges_backbone)))\n",
        "for fj,(v0,v1,v2) in enumerate(F):\n",
        "    for (a,b) in ((v0,v1),(v1,v2),(v2,v0),(v1,v0),(v2,v1),(v0,v2)):\n",
        "        if (a,b) in edge_id:\n",
        "            Inc_fe[fj, edge_id[(a,b)]] = 1.0\n",
        "deg = Inc_fe.sum(axis=1, keepdims=True); deg[deg==0] = 1.0\n",
        "Inc_fe_avg = Inc_fe / deg\n",
        "star_eps   = csr_matrix(Inc_fe_avg)      # faces×edges\n",
        "star_muinv = csr_matrix(Inc_fe_avg.T)    # edges×faces\n",
        "\n",
        "# Energy forms\n",
        "Se = (star_eps.T @ star_eps).astype(float).toarray()\n",
        "Sb = (star_muinv.T @ star_muinv).astype(float).toarray()\n",
        "\n",
        "# Sanity: boundary of boundary\n",
        "bdb = (B1 @ B2).toarray()\n",
        "print(\"||B1·B2||_∞ =\", np.max(np.abs(bdb)))  # should be 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1pqe2HQ_n5m",
        "outputId": "00f0c716-93d9-4c86-b94d-290e521882c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prep — Map Graph Sinks → DEC-Backbone Damping R { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds the sparse diagonal damping matrix **R** on the **DEC backbone** (edge index space),\n",
        "# @markdown   using your **directed Markov graph** `G`.\n",
        "# @markdown - For every graph edge that **ends at a sink** (default: `\"0\"`), assigns a small loss to the\n",
        "# @markdown   corresponding **backbone edge index**.\n",
        "# @markdown - If the exact orientation `(u,v)` is not present on the backbone, it will **fall back to `(v,u)`**\n",
        "# @markdown   (orientation doesn’t matter for scalar loss).\n",
        "# @markdown - Prints a short summary and lists any **graph sink-edges not found** on the backbone\n",
        "# @markdown   (e.g., cross-tetra “cubic” edges you didn’t include in the DEC face set).\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "import numpy as np\n",
        "\n",
        "def build_R_from_graph(\n",
        "    G,\n",
        "    edge_id,\n",
        "    sinks=(\"0\",),\n",
        "    loss=1e-2,\n",
        "    allow_reverse=True,\n",
        "    scale_by_attr=None,   # e.g. \"rate\" or \"loss_weight\" if you want per-edge scaling\n",
        "    verbose=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    G : nx.DiGraph\n",
        "        Your transport/Markov graph (with attrs like 'rate', etc.)\n",
        "    edge_id : dict[(u,v)->int]\n",
        "        DEC backbone edge indexing (from your B2/backbone builder).\n",
        "    sinks : tuple[str]\n",
        "        Node labels considered as sinks (default (\"0\",)).\n",
        "    loss : float\n",
        "        Base damping to add for each sink-directed edge.\n",
        "    allow_reverse : bool\n",
        "        If (u,v) not found in backbone, try (v,u).\n",
        "    scale_by_attr : str | None\n",
        "        Optional graph edge attribute name to scale damping, e.g., scale by 'rate'.\n",
        "    verbose : bool\n",
        "        Print mapping summary and first few unmapped edges.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    R : scipy.sparse.csr_matrix (m×m)\n",
        "        Diagonal damping in backbone edge space (m = len(edge_id)).\n",
        "    \"\"\"\n",
        "    m = len(edge_id)\n",
        "    r = np.zeros(m, dtype=float)\n",
        "    mapped = 0\n",
        "    missing = []\n",
        "\n",
        "    for u, v, data in G.edges(data=True):\n",
        "        if str(v) not in sinks:\n",
        "            continue\n",
        "\n",
        "        # base loss, optionally scaled by an attribute (e.g., 'rate')\n",
        "        w = float(loss)\n",
        "        if scale_by_attr is not None and scale_by_attr in data:\n",
        "            try:\n",
        "                w *= float(data[scale_by_attr])\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        ei = edge_id.get((str(u), str(v)))\n",
        "        if ei is None and allow_reverse:\n",
        "            ei = edge_id.get((str(v), str(u)))\n",
        "\n",
        "        if ei is not None:\n",
        "            r[ei] += w\n",
        "            mapped += 1\n",
        "        else:\n",
        "            missing.append((str(u), str(v)))\n",
        "\n",
        "    R = csr_matrix(np.diag(r))\n",
        "\n",
        "    if verbose:\n",
        "        print(\n",
        "            f\"R built from sinks {sinks}: mapped {mapped} graph edges → \"\n",
        "            f\"loss={loss:g} (nnz={R.nnz}/{m}).\"\n",
        "        )\n",
        "        if missing:\n",
        "            preview = \", \".join([f\"{e[0]}→{e[1]}\" for e in missing[:10]])\n",
        "            print(\n",
        "                f\"Unmapped sink-edges not on backbone (showing up to 10): {preview}\"\n",
        "                + (\" ...\" if len(missing) > 10 else \"\")\n",
        "            )\n",
        "            print(\n",
        "                \"Hint: If these are legitimate transport edges (e.g., cross-tetra/cubic), \"\n",
        "                \"consider adding their undirected versions to the DEC backbone face/edge set, \"\n",
        "                \"or accept that damping only applies on the backbone.\"\n",
        "            )\n",
        "\n",
        "    return R\n",
        "\n",
        "# --- Usage ---\n",
        "# Requires: G (graph), edge_id (from your DEC backbone), and optionally custom sinks.\n",
        "# Example: damp only edges that flow into '0' (heat sink)\n",
        "R = build_R_from_graph(G, edge_id, sinks=(\"0\",), loss=1e-2, allow_reverse=True, scale_by_attr=\"rate\", verbose=True)\n",
        "\n",
        "# If you already had an R and want to *augment* it (not replace), do e.g.:\n",
        "# R = R + build_R_from_graph(G, edge_id, sinks=(\"0\",), loss=1e-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqI9gXCq9HoJ",
        "outputId": "b700e6ca-3066-4004-d5b5-383fd8cf7a2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prep — Cast DEC operators & globals to float (fix object dtypes) { display-mode: \"form\" }\n",
        "\n",
        "# Cast all scalar globals to plain floats\n",
        "global_dt = float(global_dt)\n",
        "global_epsilon = float(global_epsilon)\n",
        "global_mu = float(global_mu)\n",
        "global_sigma = float(global_sigma)\n",
        "\n",
        "# Cast sparse operators to float64\n",
        "B2         = B2.astype(float)\n",
        "star_eps   = star_eps.astype(float)\n",
        "star_muinv = star_muinv.astype(float)\n",
        "R          = R.astype(float)\n",
        "\n",
        "# If Se/Sb were built earlier, rebuild/cast them to float now\n",
        "Se = (star_eps.T @ star_eps).astype(float).toarray()\n",
        "Sb = (star_muinv.T @ star_muinv).astype(float).toarray()\n",
        "\n",
        "print(\"Dtypes:\",\n",
        "      \"\\n  B2:\", B2.dtype,\n",
        "      \"\\n  star_eps:\", star_eps.dtype,\n",
        "      \"\\n  star_muinv:\", star_muinv.dtype,\n",
        "      \"\\n  R:\", R.dtype,\n",
        "      \"\\n  Se:\", Se.dtype, \"Sb:\", Sb.dtype,\n",
        "      \"\\nScalars: dt, ε, μ, σ =\", global_dt, global_epsilon, global_mu, global_sigma)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBO8tCYN9irG",
        "outputId": "7302e6e1-1057-4584-a517-cfc42bbc9996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dtypes: \n",
            "  B2: float64 \n",
            "  star_eps: float64 \n",
            "  star_muinv: float64 \n",
            "  R: float64 \n",
            "  Se: float64 Sb: float64 \n",
            "Scalars: dt, ε, μ, σ = 1.667820476386291e-16 8.854187817000001e-08 1.25663706212e-06 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a2db0ea",
        "outputId": "0d49dbc8-7475-41d3-e93c-3d96f5cc8155"
      },
      "source": [
        "# @title 6. **Baseline DEC Stepper (S1) — Energy & Frequency** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Uses your DEC operators (**B₂**, rectangular Hodge stars) to step **E (edges)** and **B (faces)**.\n",
        "# @markdown - Logs total energy via SPD forms (**Se, Sb**) and an “EEG-like” average-frequency proxy.\n",
        "# @markdown - Assumes Cells 4–5 have defined: `B2, star_eps, star_muinv, Se, Sb, R, edge_idx, n_edges, n_faces`.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# ---- guards: require prior cells ----\n",
        "required = ['B2','star_eps','star_muinv','Se','Sb','R','edge_idx','n_edges','n_faces',\n",
        "            'global_dt', 'global_epsilon', 'global_mu', 'global_sigma']\n",
        "missing = [k for k in required if k not in globals()]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"Run DEC operator cells first; missing: {missing}\")\n",
        "\n",
        "# time step (use something small and stable; or reuse your CFL dt if available)\n",
        "dt = float(global_dt)\n",
        "ε  = float(global_epsilon)\n",
        "μ  = float(global_mu)\n",
        "σ  = float(global_sigma)\n",
        "\n",
        "\n",
        "# ---- fields on correct carriers ----\n",
        "E = np.zeros(n_edges, dtype=float)   # edges (1-form)\n",
        "B = np.zeros(n_faces, dtype=float)   # faces (2-form)\n",
        "\n",
        "# Initial condition: small pump on C→1 if present\n",
        "# (re)seed ICs as float\n",
        "idx = edge_idx.get(('C','1'))\n",
        "if idx is not None:\n",
        "    E[idx] = 1e-4\n",
        "else:\n",
        "    print(\"Note: edge ('C','1') not found; skipping pump init.\")\n",
        "\n",
        "\n",
        "def dec_step(E, B, dt):\n",
        "    \"\"\"One explicit DEC step: Faraday (faces) then Ampère (edges) with edge damping R.\"\"\"\n",
        "    # ensure float arrays (guards against stray mpf/object)\n",
        "    E = np.asarray(E, dtype=float)\n",
        "    B = np.asarray(B, dtype=float)\n",
        "\n",
        "    # Faraday: dB/dt = - curl(E)   with curl(E) = B2.T @ E  (faces)\n",
        "    curl_E = (B2.T @ E)                 # shape: (n_faces,)\n",
        "    B_new  = B - dt * curl_E            # faces\n",
        "\n",
        "    # Ampère (explicit, schematic): dE/dt = (1/ε) * (faces→edges) - (σ/ε)E - R E\n",
        "    # faces→edges is B2 @ B_new (edges)\n",
        "    drive  = (B2 @ B_new)               # shape: (n_edges,)\n",
        "    damping = (R @ E)                   # shape: (n_edges,)\n",
        "    E_new  = E + (dt/ε) * drive - (dt*σ/ε) * E - dt * damping\n",
        "\n",
        "    return E_new, B_new\n",
        "\n",
        "\n",
        "def energy_total(E, B):\n",
        "    # SPD quadratic energy (consistent with your rectangular stars)\n",
        "    return 0.5 * (E @ (Se @ E) + B @ (Sb @ B))\n",
        "\n",
        "def eeg_like_freq(history, E, B, dt):\n",
        "    # simple global-oscillation proxy from mean |E|, |B| slopes\n",
        "    Em = float(np.mean(np.abs(E)))\n",
        "    Bm = float(np.mean(np.abs(B)))\n",
        "    if len(history['E_mean']) >= 1:\n",
        "        dEm = (Em - history['E_mean'][-1]) / dt\n",
        "        dBm = (Bm - history['B_mean'][-1]) / dt\n",
        "        return float(np.hypot(dEm, dBm)), Em, Bm\n",
        "    return 0.0, Em, Bm\n",
        "\n",
        "# quick shape asserts (run once after defining B2, E, B)\n",
        "assert B2.shape == (n_edges, n_faces)\n",
        "assert (B2.T @ E).shape == (n_faces,)\n",
        "assert (B2 @ B).shape   == (n_edges,)\n",
        "\n",
        "\n",
        "# ---- run ----\n",
        "steps = 200\n",
        "t = 0.0\n",
        "# Initialize history outside the loop to accumulate data\n",
        "history = {\n",
        "    't': [],\n",
        "    'energy': [],\n",
        "    'freq': [],\n",
        "    'E_mean': [],\n",
        "    'B_mean': [],\n",
        "    'E_field': [],\n",
        "    'B_field': []\n",
        "}\n",
        "\n",
        "for k in range(steps):\n",
        "    # step\n",
        "    E, B = dec_step(E, B, dt)\n",
        "\n",
        "    # logs\n",
        "    U   = energy_total(E, B)\n",
        "    f, Em, Bm = eeg_like_freq(history, E, B, dt)\n",
        "\n",
        "    history['t'].append(t)\n",
        "    history['energy'].append(U)\n",
        "    history['freq'].append(f)\n",
        "    history['E_mean'].append(Em)\n",
        "    history['B_mean'].append(Bm)\n",
        "    history['E_field'].append(E.copy())\n",
        "    history['B_field'].append(B.copy())\n",
        "\n",
        "    if k % 50 == 0:\n",
        "        print(f\"Step {k:3d}  t={t:7.4f}  Energy={U:.3e}  ⟨|E|⟩={Em:.3e}  ⟨|B|⟩={Bm:.3e}  freq*={f:.2e}\")\n",
        "\n",
        "    t += dt\n",
        "\n",
        "# export for later\n",
        "baseline_history = history\n",
        "print(\"\\nDEC stepper complete → `baseline_history` with keys:\", list(baseline_history.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step   0  t= 0.0000  Energy=0.000e+00  ⟨|E|⟩=4.167e-06  ⟨|B|⟩=0.000e+00  freq*=0.00e+00\n",
            "Step  50  t= 0.0000  Energy=0.000e+00  ⟨|E|⟩=4.167e-06  ⟨|B|⟩=0.000e+00  freq*=2.35e+01\n",
            "Step 100  t= 0.0000  Energy=0.000e+00  ⟨|E|⟩=4.167e-06  ⟨|B|⟩=0.000e+00  freq*=2.35e+01\n",
            "Step 150  t= 0.0000  Energy=0.000e+00  ⟨|E|⟩=4.167e-06  ⟨|B|⟩=0.000e+00  freq*=2.35e+01\n",
            "\n",
            "DEC stepper complete → `baseline_history` with keys: ['t', 'energy', 'freq', 'E_mean', 'B_mean']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "898ec073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "4c9c0f48-cb62-4097-9226-9056a3e6431c"
      },
      "source": [
        "# @title 7. **Markov Diagnostics — Mediation, Entropy, Mixing** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds discrete transition chains from your graph **G** (uses `data['rate']` on edges).\n",
        "# @markdown - Reports: Centroid reliance **R_C**, discrete **ΔE** (early Electric rise), entropy production **Σ** (Schnakenberg), spectral gap, **Kemeny** constant, and mean hitting times to sinks **{0, C}** (auto-pruned if missing).\n",
        "#\n",
        "# @markdown **Counterfactual**\n",
        "# @markdown - Optionally adds forbidden **2→1** (or **6→5** if S2 present) to test loss of mediation and lowered dissipation (EPR).\n",
        "import numpy as np\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def build_P_from_graph(G, node_idx, rate_attr='rate'):\n",
        "    n = len(node_idx)\n",
        "    P = np.zeros((n, n))\n",
        "    # Use node_idx to map original node labels to matrix indices\n",
        "    for u_orig, v_orig, data in G.edges(data=True):\n",
        "        u_str, v_str = str(u_orig), str(v_orig)\n",
        "        if u_str in node_idx and v_str in node_idx:\n",
        "            i, j = node_idx[u_str], node_idx[v_str]\n",
        "            P[i, j] = float(data.get(rate_attr, 0.0))\n",
        "    # row-normalise\n",
        "    for i in range(n):\n",
        "        s = P[i].sum()\n",
        "        if s > 0:\n",
        "            P[i] /= s\n",
        "    return P\n",
        "\n",
        "def roll_states(P, start_idx, steps=20):\n",
        "    n = P.shape[0]\n",
        "    x = np.zeros(n); x[start_idx] = 1.0\n",
        "    traj = [x.copy()]\n",
        "    for _ in range(steps):\n",
        "        x = x @ P\n",
        "        traj.append(x.copy())\n",
        "    return np.stack(traj)\n",
        "\n",
        "def centroid_reliance(states, node_idx, horizon=10):\n",
        "    if 'C' not in node_idx: return np.nan\n",
        "    c = node_idx['C']\n",
        "    T = min(horizon, states.shape[0])\n",
        "    return float(states[:T, c].mean())\n",
        "\n",
        "def electric_acceleration(states, node_idx, t1=1, t2=2):\n",
        "    # Prefer '1' (S1 electric); fall back to '5' (S2 electric) if needed\n",
        "    e_key = '1' if '1' in node_idx else ('5' if '5' in node_idx else None)\n",
        "    if e_key is None: return np.nan\n",
        "    e = node_idx[e_key]\n",
        "    if max(t1, t2) >= states.shape[0]: return np.nan\n",
        "    return float(states[t2, e] - states[t1, e])\n",
        "\n",
        "def absorbing_hitting_time(P, targets, node_idx):\n",
        "    # Make copy with targets absorbing\n",
        "    tgt_idx = [node_idx[t] for t in targets if t in node_idx]\n",
        "    if not tgt_idx:\n",
        "        return np.full(P.shape[0], np.nan)\n",
        "    Q_idx = [i for i in range(P.shape[0]) if i not in tgt_idx]\n",
        "    if not Q_idx:\n",
        "        # If all nodes are targets, hitting time from any node is 0\n",
        "        return np.zeros(P.shape[0])\n",
        "    Q = P[np.ix_(Q_idx, Q_idx)]\n",
        "    I = np.eye(Q.shape[0])\n",
        "    try:\n",
        "        N = np.linalg.inv(I - Q)\n",
        "    except np.linalg.LinAlgError:\n",
        "        # Handle singular matrix (e.g., disconnected graph)\n",
        "        # Using pinv can give a result but interpret with caution\n",
        "        N = np.linalg.pinv(I - Q)\n",
        "    t_mean = N.sum(axis=1)  # expected steps to absorption from each transient\n",
        "    out = np.zeros(P.shape[0])\n",
        "    # Map results back to original full node indexing\n",
        "    # Ensure Q_idx length matches t_mean length\n",
        "    if len(Q_idx) == len(t_mean):\n",
        "        for k_q, i_orig in enumerate(Q_idx):\n",
        "            out[i_orig] = t_mean[k_q]\n",
        "    else:\n",
        "        # This case indicates a potential issue in Q/N calculation\n",
        "        print(\"Warning: Mismatch in transient node indices and hitting time results length.\")\n",
        "        # Fallback: fill with NaNs for safety\n",
        "        out.fill(np.nan)\n",
        "\n",
        "    return out\n",
        "\n",
        "def stationary_dist(P):\n",
        "    n = P.shape[0]\n",
        "    A = P.T - np.eye(n)\n",
        "    A[-1, :] = 1.0  # Add constraint that distribution sums to 1\n",
        "    b = np.zeros(n)\n",
        "    b[-1] = 1.0\n",
        "    try:\n",
        "        # Use pinv for potentially non-ergodic chains\n",
        "        pi = np.linalg.pinv(A) @ b\n",
        "        pi = np.real(pi)\n",
        "        pi = np.maximum(pi, 0)\n",
        "        s = pi.sum()\n",
        "        return (pi / s) if s > 0 else np.ones(n) / n\n",
        "    except np.linalg.LinAlgError:\n",
        "        print(\"Warning: Could not compute stationary distribution.\")\n",
        "        return np.ones(n) / n # Fallback to uniform distribution\n",
        "\n",
        "def entropy_production(P, eps=1e-12):\n",
        "    pi = stationary_dist(P)\n",
        "    n = P.shape[0]\n",
        "    Sigma = 0.0\n",
        "    for i in range(n):\n",
        "        for j in range(n): # Iterate over all pairs for detailed balance check\n",
        "            if i == j: continue\n",
        "            Jij = pi[i] * P[i, j]\n",
        "            Jji = pi[j] * P[j, i]\n",
        "            # Use absolute values for log argument to avoid issues with small negative numbers\n",
        "            # Add eps for numerical stability\n",
        "            if abs(Jij) > eps or abs(Jji) > eps:\n",
        "                Sigma += (Jij - Jji) * np.log((abs(Jij) + eps) / (abs(Jji) + eps))\n",
        "\n",
        "    # For Schnakenberg, sum over *distinct* pairs i != j only once, e.g., j > i.\n",
        "    # The formula is Sigma = 0.5 * Sum_{i!=j} (Jij - Jji) * log(Jij/Jji)\n",
        "    # The previous loop sums each pair twice (i,j) and (j,i), so divide by 2.\n",
        "    return float(Sigma * 0.5) # Divide by 2 for correct Schnakenberg formula\n",
        "\n",
        "def spectral_gap_and_kemeny(P):\n",
        "    n = P.shape[0]\n",
        "    vals = np.linalg.eigvals(P)\n",
        "    vals = np.real_if_close(vals)\n",
        "    # Sort eigenvalues by magnitude in descending order\n",
        "    sorted_indices = np.argsort(np.abs(vals))[::-1]\n",
        "    sorted_vals = vals[sorted_indices]\n",
        "\n",
        "    # Find the eigenvalue closest to 1 (should be 1 for ergodic chains)\n",
        "    idx_one = np.argmin(np.abs(sorted_vals - 1.0))\n",
        "    l1 = sorted_vals[idx_one]\n",
        "\n",
        "    # The second largest eigenvalue magnitude\n",
        "    if len(sorted_vals) > 1:\n",
        "       # Find the second largest eigenvalue by magnitude, excluding the one at 1\n",
        "       # Ensure there are eigenvalues other than 1 before accessing index 0 of the deleted array\n",
        "       non_one_vals = np.delete(sorted_vals, idx_one)\n",
        "       l2 = np.abs(non_one_vals)[0] if non_one_vals.size > 0 else 0.0\n",
        "    else:\n",
        "        l2 = 0.0\n",
        "\n",
        "    gap = float(1.0 - l2)\n",
        "\n",
        "    K = 0.0\n",
        "    # Kemeny constant formula sum_{k=2}^n 1/(1-lambda_k)\n",
        "    # Sum over all eigenvalues except the one at 1\n",
        "    for k in range(n):\n",
        "        # Use a tolerance when comparing to 1 to handle floating point inaccuracies\n",
        "        if abs(sorted_vals[k] - 1.0) < 1e-9:\n",
        "             continue\n",
        "        denom = 1.0 - sorted_vals[k]\n",
        "        if abs(denom) > 1e-9:\n",
        "            K += (1.0 / denom)\n",
        "        # else: if denominator is zero (another eigenvalue at 1), Kemeny is infinite. Handle with large number.\n",
        "        else:\n",
        "            K += 1e9 # Represent infinite Kemeny constant with a large number\n",
        "    return gap, float(K)\n",
        "\n",
        "def pick_start_index(node_idx):\n",
        "    # Prefer magnetic-like start: '2' in S1, else '6' in S2, else first node\n",
        "    for k in ('2', '6'):\n",
        "        if k in node_idx: return node_idx[k]\n",
        "    # Fallback to 'C' if available, otherwise first node\n",
        "    if 'C' in node_idx: return node_idx['C']\n",
        "    return 0 if node_idx else None # Return 0 if node_idx is not empty, otherwise None\n",
        "\n",
        "# ---------- build base chain ----------\n",
        "# Expect G in scope; if node_idx not present, build it.\n",
        "# Use the global G defined in cell 3, which includes all nodes\n",
        "if 'G' not in globals():\n",
        "    raise ValueError(\"Graph G not found. Run Cell 3 (Geometry — Star Tetra) first.\")\n",
        "\n",
        "# Re-build node_idx based on the current G to ensure consistency\n",
        "node_idx = {str(n): i for i, n in enumerate(G.nodes())}\n",
        "ALL_nodes_present = all(n in node_idx for n in ALL) # Check if all original nodes are in the current G\n",
        "\n",
        "if not node_idx:\n",
        "    print(\"Error: No nodes found in graph G.\")\n",
        "    P_norm = None\n",
        "else:\n",
        "    P_norm = build_P_from_graph(G, node_idx)\n",
        "    start_idx = pick_start_index(node_idx)\n",
        "    if start_idx is None:\n",
        "        print(\"Error: Could not determine a valid starting node.\")\n",
        "        traj_norm = None\n",
        "    else:\n",
        "        traj_norm = roll_states(P_norm, start_idx=start_idx, steps=20)\n",
        "\n",
        "    if traj_norm is not None:\n",
        "        Rc_norm   = centroid_reliance(traj_norm, node_idx, horizon=10)\n",
        "        dE_norm   = electric_acceleration(traj_norm, node_idx, t1=1, t2=2)\n",
        "    else:\n",
        "        Rc_norm, dE_norm = np.nan, np.nan\n",
        "\n",
        "    Sigma_norm = entropy_production(P_norm) if P_norm is not None else np.nan\n",
        "    gap_norm, K_norm = spectral_gap_and_kemeny(P_norm) if P_norm is not None else (np.nan, np.nan)\n",
        "    HT_norm = absorbing_hitting_time(P_norm, targets=['0', 'C'], node_idx=node_idx) if P_norm is not None else np.full(len(node_idx), np.nan)\n",
        "\n",
        "# ---------- counterfactual (optional 2→1 or 6→5) ----------\n",
        "add_counterfactual = True # This can be controlled by a form field later\n",
        "w_forbidden = 0.10 # This can be controlled by a form field later\n",
        "\n",
        "def add_forbidden_edge(Gin, node_idx, w):\n",
        "    Gx = Gin.copy()\n",
        "    tag = None\n",
        "    # Check if nodes exist before adding the edge\n",
        "    if '2' in node_idx and '1' in node_idx:\n",
        "        # Check if the edge already exists before adding to avoid errors in some graph types\n",
        "        if not Gx.has_edge('2', '1'):\n",
        "            Gx.add_edge('2', '1', rate=w)\n",
        "            tag = '2→1'\n",
        "        elif Gx['2']['1'].get('rate', 0.0) != w:\n",
        "            # Update rate if edge exists but rate is different\n",
        "            Gx['2']['1']['rate'] = w\n",
        "            tag = f'2→1 (rate updated to {w})'\n",
        "        else:\n",
        "            tag = '2→1 (edge already exists with same rate)'\n",
        "\n",
        "    elif '6' in node_idx and '5' in node_idx:\n",
        "        if not Gx.has_edge('6', '5'):\n",
        "            Gx.add_edge('6', '5', rate=w)\n",
        "            tag = '6→5'\n",
        "        elif Gx['6']['5'].get('rate', 0.0) != w:\n",
        "            Gx['6']['5']['rate'] = w\n",
        "            tag = f'6→5 (rate updated to {w})'\n",
        "        else:\n",
        "            tag = '6→5 (edge already exists with same rate)'\n",
        "\n",
        "    return Gx, tag\n",
        "\n",
        "if add_counterfactual:\n",
        "    # Use the original G to create the counterfactual graph\n",
        "    G_ctf, tag = add_forbidden_edge(G, node_idx, w_forbidden)\n",
        "    if tag is None or P_norm is None: # Also skip if normal P could not be built\n",
        "        print(\"Counterfactual skipped (no suitable nodes for forbidden edge or graph issues).\")\n",
        "        P_ctf = None\n",
        "    else:\n",
        "        # Re-build node_idx for the counterfactual graph to ensure consistency\n",
        "        node_idx_ctf = {str(n): i for i, n in enumerate(G_ctf.nodes())}\n",
        "        P_ctf = build_P_from_graph(G_ctf, node_idx_ctf)\n",
        "else:\n",
        "    P_ctf = None\n",
        "    tag = None\n",
        "\n",
        "# Ensure node_idx_ctf is defined if P_ctf is calculated\n",
        "if P_ctf is not None:\n",
        "    node_idx_ctf = {str(n): i for i, n in enumerate(G_ctf.nodes())}\n",
        "    # Use node_idx_ctf for counterfactual calculations\n",
        "    traj_ctf = roll_states(P_ctf, start_idx=pick_start_index(node_idx_ctf), steps=20)\n",
        "    if traj_ctf is not None:\n",
        "        Rc_ctf   = centroid_reliance(traj_ctf, node_idx_ctf, horizon=10)\n",
        "        dE_ctf   = electric_acceleration(traj_ctf, node_idx_ctf, t1=1, t2=2)\n",
        "    else:\n",
        "        Rc_ctf, dE_ctf = np.nan, np.nan\n",
        "\n",
        "    Sigma_ctf = entropy_production(P_ctf)\n",
        "    gap_ctf, K_ctf = spectral_gap_and_kemeny(P_ctf)\n",
        "    HT_ctf = absorbing_hitting_time(P_ctf, targets=['0', 'C'], node_idx=node_idx_ctf) # Use node_idx_ctf\n",
        "else:\n",
        "    Rc_ctf, dE_ctf, Sigma_ctf, gap_ctf, K_ctf = np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "    HT_ctf = np.full(len(node_idx), np.nan)\n",
        "\n",
        "\n",
        "# ---------- report ----------\n",
        "def fmt(v):\n",
        "    # Handle various NaN/None cases, format floats\n",
        "    if v is None or (isinstance(v, (float, np.float64)) and not np.isfinite(v)):\n",
        "        return \"nan\"\n",
        "    # Check if v is an array and format elements\n",
        "    if isinstance(v, np.ndarray):\n",
        "        return \"[\" + \", \".join(fmt(x) for x in v) + \"]\"\n",
        "    return f\"{v:.3f}\" # Default formatting for floats\n",
        "\n",
        "print(\"=== Markov Metrics ===\")\n",
        "print(f\"Centroid reliance R_C     : normal={fmt(Rc_norm)}\" + (f\" | counterfactual={fmt(Rc_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Electric acceleration ΔE   : normal={fmt(dE_norm)}\" + (f\" | counterfactual={fmt(dE_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Entropy production Σ       : normal={fmt(Sigma_norm)}\" + (f\" | counterfactual={fmt(Sigma_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Spectral gap (1-|λ2|)      : normal={fmt(gap_norm)}\" + (f\" | counterfactual={fmt(gap_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Kemeny constant            : normal={fmt(K_norm)}\" + (f\" | counterfactual={fmt(K_ctf)}\" if P_ctf is not None else \"\"))\n",
        "\n",
        "# Hitting times table\n",
        "def print_ht(label, HT, node_idx_for_ht, G_for_ht):\n",
        "    print(f\"Mean hitting time to {{0,C}} from each node ({label}):\")\n",
        "    # Iterate over the nodes actually present in the graph being reported on\n",
        "    # Sort nodes for consistent output order\n",
        "    sorted_nodes = sorted(G_for_ht.nodes(), key=str) # Simple string sort\n",
        "\n",
        "    # Check if node_idx_for_ht and HT have compatible sizes\n",
        "    if HT is not None and len(node_idx_for_ht) != len(HT):\n",
        "        print(f\"Warning: Node index size ({len(node_idx_for_ht)}) mismatch with HT array size ({len(HT)}) for {label} report.\")\n",
        "\n",
        "    for node_key_orig in sorted_nodes:\n",
        "        k = str(node_key_orig) # Ensure key is string for consistent lookup\n",
        "\n",
        "        # Safely get the node label, falling back to the key if node access fails\n",
        "        try:\n",
        "            node_label = G_for_ht.nodes[node_key_orig].get('label', k)\n",
        "        except KeyError:\n",
        "            # If direct access fails, use the string key as the label\n",
        "            node_label = k\n",
        "            print(f\"Warning: Could not access node attributes for key '{k}' in graph '{label}'. Using key as label.\")\n",
        "\n",
        "\n",
        "        # Get the hitting time value\n",
        "        v = np.nan # Default to NaN\n",
        "\n",
        "        if k in node_idx_for_ht:\n",
        "            idx = node_idx_for_ht[k]\n",
        "            if HT is not None and idx < len(HT): # Check index is within bounds of HT array\n",
        "                v = HT[idx]\n",
        "                 # Handle potential NaN/Inf from hitting time calculation\n",
        "                if not np.isfinite(v):\n",
        "                    v = 0.0 if k in ('0','C') else np.nan\n",
        "            elif k in ('0', 'C'):\n",
        "                 # If target node index is not valid for HT but is a target, report 0\n",
        "                v = 0.0\n",
        "            # else: If node is in node_idx but not a target and index is invalid/HT is None, v remains nan\n",
        "\n",
        "        elif k in ('0', 'C'):\n",
        "             # If target node is not in node_idx but is a target, report 0\n",
        "             v = 0.0\n",
        "        # else: If node exists in G_for_ht but not in node_idx_for_ht (unexpected), v remains nan\n",
        "\n",
        "\n",
        "        print(f\"  {node_label:>22s}: {fmt(v)}\")\n",
        "\n",
        "\n",
        "print_ht(\"normal\", HT_norm, node_idx, G) # Pass node_idx and G for normal report\n",
        "if P_ctf is not None and G_ctf is not None:\n",
        "    print_ht(f\"counterfactual ({tag})\", HT_ctf, node_idx_ctf, G_ctf) # Pass node_idx_ctf and G_ctf\n",
        "\n",
        "# Export for later cells\n",
        "markov_report = {\n",
        "    \"normal\": {\n",
        "        \"Rc\": Rc_norm, \"dE\": dE_norm, \"Sigma\": Sigma_norm,\n",
        "        \"gap\": gap_norm, \"Kemeny\": K_norm, \"HT\": HT_norm\n",
        "    }\n",
        "}\n",
        "if P_ctf is not None and G_ctf is not None:\n",
        "    markov_report[\"counterfactual\"] = {\n",
        "        \"tag\": tag, \"Rc\": Rc_ctf, \"dE\": dE_ctf, \"Sigma\": Sigma_ctf,\n",
        "        \"gap\": gap_ctf, \"Kemeny\": K_ctf, \"HT\": HT_ctf\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 213)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m213\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ace3d1f9"
      },
      "source": [
        "# @title 8. **Energy Balance Audit — Stored Energy vs Power Flows** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines SPD energy forms; compares dU/dt with (input − dissipation); residual should hover near zero.\n",
        "\n",
        "import numpy as np\n",
        "from mpmath import mpf\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Setup (Assumes Cell 6: baseline_history with 'energy', 'E_field', 'B_field') ---\n",
        "# Ensure globals exist from DEC Stepper\n",
        "try:\n",
        "    history = baseline_history # Corrected from global_history\n",
        "    dt = global_dt\n",
        "    ε = global_epsilon\n",
        "    μ = global_mu\n",
        "    σ = global_sigma\n",
        "except NameError:\n",
        "    raise ValueError(\"Run Cell 6 (DEC Stepper) first to set baseline_history, dt, ε, μ, σ\")\n",
        "\n",
        "# Graph (reuse from Cell 6 if available; mock for audit)\n",
        "if 'G' not in globals():\n",
        "    nodes = ['C', '0', '1', '2', '3']\n",
        "    G = nx.DiGraph()\n",
        "    G.add_nodes_from(nodes)\n",
        "    G.add_edges_from([('C','1'), ('1','2'), ('2','C'), ('C','3'), ('3','0'), ('0','C')])\n",
        "\n",
        "# --- Power Flow Calculation ---\n",
        "def compute_power_flows(E, B, G, σ, ε):\n",
        "    \"\"\"Input power (proxy: pump at (C,1)) minus dissipation (Joule: σ |E|^2).\"\"\"\n",
        "    input_power = 0.0\n",
        "    if ('C', '1') in edge_idx:\n",
        "        input_power = abs(E[edge_idx[('C', '1')]]) * 1.0  # Source term (W/m)\n",
        "\n",
        "    # Dissipation: Integrated Joule heating σ |E|^2 over edges\n",
        "    dissipation = σ * np.sum(E**2)\n",
        "\n",
        "    return input_power - dissipation\n",
        "\n",
        "# --- Audit Loop (Over History) ---\n",
        "residuals = []\n",
        "dU_dt_vals = []\n",
        "power_net_vals = []\n",
        "n_steps = len(history['energy'])\n",
        "epsilon = 1e-18 # a small number to avoid division by zero\n",
        "\n",
        "if n_steps > 1:\n",
        "    for i in range(1, n_steps):\n",
        "        # Retrieve E/B from history\n",
        "        E = history['E_field'][i-1]  # Use previous for dU/dt consistency\n",
        "        B = history['B_field'][i-1]\n",
        "\n",
        "        # dU/dt (central finite difference approximation)\n",
        "        U_prev = history['energy'][i-1]\n",
        "        U_curr = history['energy'][i]\n",
        "        dU_dt = (U_curr - U_prev) / (dt + epsilon)\n",
        "\n",
        "        # Power net\n",
        "        power_net = compute_power_flows(E, B, G, σ, ε)\n",
        "\n",
        "        # Residual: |dU/dt - (input - dissipation)|\n",
        "        res = abs(float(dU_dt - power_net))\n",
        "        residuals.append(res)\n",
        "        dU_dt_vals.append(float(dU_dt))\n",
        "        power_net_vals.append(float(power_net))\n",
        "\n",
        "        # Early report\n",
        "        if i > 0 and i % 50 == 0:\n",
        "            print(f\"Step {i}: dU/dt={dU_dt:.2e}, Power Net={power_net:.2e}, Res={res:.2e}\")\n",
        "\n",
        "# --- Summary Stats ---\n",
        "if residuals:\n",
        "    mean_residual = np.mean(residuals)\n",
        "    max_residual = np.max(residuals)\n",
        "    std_residual = np.std(residuals)\n",
        "else:\n",
        "    mean_residual, max_residual, std_residual = np.nan, np.nan, np.nan\n",
        "\n",
        "U_final = history['energy'][-1] if history['energy'] else np.nan\n",
        "\n",
        "print(f\"\\n--- Energy Balance Audit Summary ---\")\n",
        "print(f\"Steps Audited: {len(residuals)}\")\n",
        "print(f\"Mean Residual: {mean_residual:.2e} (should hover ~0)\")\n",
        "print(f\"Max Residual: {max_residual:.2e}\")\n",
        "print(f\"Std Residual: {std_residual:.2e}\")\n",
        "print(f\"Final Stored Energy U: {float(U_final):.2e} J\")\n",
        "print(f\"Audit Status: {'PASS' if not np.isnan(mean_residual) and mean_residual < 1e-10 else 'FAIL'} (residual near zero)\")\n",
        "\n",
        "# --- Plot Residuals vs Time ---\n",
        "if residuals:\n",
        "    steps_plot = np.arange(1, len(residuals) + 1)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    ax1.plot(steps_plot, dU_dt_vals, label='dU/dt', alpha=0.7)\n",
        "    ax1.plot(steps_plot, power_net_vals, label='Input - Dissipation', alpha=0.7)\n",
        "    ax1.set_title('Energy Rate vs Power Flows')\n",
        "    ax1.set_ylabel('Rate (J/s)')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    ax2.plot(steps_plot, residuals)\n",
        "    ax2.set_title('Residual |dU/dt - (Input - Dissipation)|')\n",
        "    ax2.set_ylabel('Residual')\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- Store for Later (e.g., Cell 15 plots) ---\n",
        "global_residuals = residuals\n",
        "global_dU_dt = dU_dt_vals\n",
        "global_power_net = power_net_vals\n",
        "\n",
        "print(\"\\nAudit complete. Residuals stored in global_residuals for visualizations.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb2ece69"
      },
      "source": [
        "# @title 9. **Phase Linter — 90° E–M Lag & Anchor to C (S1 & Star)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Kuramoto-style diagnostic layer; targets 90° E–M lag, gentle anchoring to C; reports phase error/spread (no feedback).\n",
        "import numpy as np\n",
        "\n",
        "# Assumes S1, S2, and a node_idx map are in the global scope.\n",
        "# If not, this cell will fail. Ensure geometry cells (2, 3) and an operator cell (e.g., 4) have run.\n",
        "\n",
        "# Define node_list based on detected S1/S2 to be robust\n",
        "node_list = []\n",
        "if 'S1' in globals(): node_list.extend(S1)\n",
        "if 'S2' in globals(): node_list.extend(S2)\n",
        "if 'C' in globals() and 'C' not in node_list: node_list.append('C')\n",
        "\n",
        "# Re-create index map based on the actual node list\n",
        "idx = {k: i for i, k in enumerate(node_list)}\n",
        "n_nodes_phase = len(node_list)\n",
        "\n",
        "# Initialize phase array if not present\n",
        "if 'phi_star' not in globals() or len(phi_star) != n_nodes_phase:\n",
        "    phi_star = np.zeros(n_nodes_phase)\n",
        "\n",
        "def _wrap_pi(x):\n",
        "    return (x + np.pi) % (2 * np.pi) - np.pi\n",
        "\n",
        "# --- Define Couplings and Target Lags ---\n",
        "kap = np.zeros((n_nodes_phase, n_nodes_phase))\n",
        "theta = np.zeros_like(kap)\n",
        "\n",
        "def set_kap(a, b, val):\n",
        "    if a in idx and b in idx:\n",
        "        i, j = idx[a], idx[b]\n",
        "        kap[i, j] = val\n",
        "        kap[j, i] = val\n",
        "\n",
        "def set_theta(a, b, rad):\n",
        "    if a in idx and b in idx:\n",
        "        i, j = idx[a], idx[b]\n",
        "        theta[i, j] = rad\n",
        "        theta[j, i] = -rad # Anti-symmetric for phi_j - phi_i\n",
        "\n",
        "# Baseline weak coupling for all nodes within each shell\n",
        "if 'S1' in globals():\n",
        "    for i, u in enumerate(S1):\n",
        "        for v in S1[i+1:]:\n",
        "            set_kap(u, v, 0.02)\n",
        "if 'S2' in globals():\n",
        "    for i, u in enumerate(S2):\n",
        "        for v in S2[i+1:]:\n",
        "            set_kap(u, v, 0.02)\n",
        "\n",
        "# Stronger E-M couplings within each shell\n",
        "set_kap('1', '2', 0.12)\n",
        "set_kap('5', '6', 0.12)\n",
        "set_theta('1', '2', np.pi / 2)\n",
        "set_theta('5', '6', np.pi / 2)\n",
        "\n",
        "# Work and heat bridge couplings\n",
        "set_kap('3', '6', 0.08); set_theta('3', '6', np.pi / 2) # Work\n",
        "set_kap('7', '4', 0.05); set_theta('7', '4', np.pi)     # Heat\n",
        "set_kap('7', '2', 0.05); set_theta('7', '2', np.pi)     # Heat\n",
        "set_kap('5', '0', 0.05); set_theta('5', '0', np.pi)     # Heat\n",
        "\n",
        "# Anchor to Centroid\n",
        "γC = 0.05\n",
        "\n",
        "def phase_step(phi, dt):\n",
        "    d_phi = np.zeros_like(phi)\n",
        "    # Iterate over all nodes that have a defined index\n",
        "    for u, i in idx.items():\n",
        "        if u == 'C': continue # Centroid is the anchor, does not update\n",
        "\n",
        "        acc = 0.0\n",
        "        # Interaction with other nodes\n",
        "        for v, j in idx.items():\n",
        "            if i == j: continue\n",
        "            acc += kap[i, j] * np.sin(phi[j] - phi[i] - theta[i, j])\n",
        "\n",
        "        # Anchor to Centroid (phi[idx['C']] is assumed to be 0)\n",
        "        if 'C' in idx:\n",
        "            acc -= γC * np.sin(phi[i] - phi[idx['C']])\n",
        "\n",
        "        d_phi[i] = acc\n",
        "\n",
        "    # Update phases (excluding the Centroid)\n",
        "    phi += dt * d_phi\n",
        "    # Keep centroid phase at 0\n",
        "    if 'C' in idx:\n",
        "        phi[idx['C']] = 0\n",
        "\n",
        "    return _wrap_pi(phi)\n",
        "\n",
        "def phase_report(phi):\n",
        "    report_data = {}\n",
        "    def err(a, b, trg):\n",
        "        if a in idx and b in idx:\n",
        "            i, j = idx[a], idx[b]\n",
        "            return float(np.degrees(_wrap_pi((phi[i] - phi[j]) - trg)))\n",
        "        return np.nan\n",
        "\n",
        "    report_data['EM_S1_deg'] = err('1', '2', np.pi/2)\n",
        "    report_data['EM_S2_deg'] = err('5', '6', np.pi/2)\n",
        "    report_data['work_3_6_deg'] = err('3', '6', np.pi/2)\n",
        "    report_data['heat_7_4_deg'] = err('7', '4', np.pi)\n",
        "    report_data['heat_7_2_deg'] = err('7', '2', np.pi)\n",
        "    report_data['heat_5_0_deg'] = err('5', '0', np.pi)\n",
        "    if 'C' in idx:\n",
        "        report_data['C_phase_deg'] = float(np.degrees(phi[idx['C']]))\n",
        "\n",
        "    return report_data\n",
        "\n",
        "# Example of running the phase linter for a few steps to let it settle\n",
        "# This part is for demonstration; the main simulation will call phase_step repeatedly\n",
        "print(\"Phase linter loaded. Running a few settling steps...\")\n",
        "for _ in range(50):\n",
        "    phi_star = phase_step(phi_star, dt=0.1)\n",
        "\n",
        "print(\"Settling complete. Current phase errors:\")\n",
        "print(phase_report(phi_star))\n",
        "\n",
        "# The linter functions (phase_step, phase_report) are now available for other cells."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee8a0508"
      },
      "source": [
        "# @title 10. **Centroid Angle Probe — 109.471221° Mediation Test** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Reweights edges to/from C by the tetrahedral bond angle; measures impact on mediation (R_C), hitting times, EPR."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "main-switch-cell"
      },
      "source": [
        "# @title Main — Select Pipeline and Geometry { display-mode: \"form\" }\n",
        "PIPELINE = \"fast\"   # \"fast\" (Cell 6 dec_step) or \"si\" (Cell 14 leapfrog_step)\n",
        "GEOMETRY = \"S1\"     # \"S1\" or \"STAR\"\n",
        "\n",
        "if PIPELINE == \"fast\":\n",
        "    print(\"Running baseline DEC stepper (dimensionless).\")\n",
        "    # call your run_cycle or the loop built in Cell 6, with GEOMETRY flag if supported\n",
        "    # e.g., baseline_history = run_cycle(..., geometry=GEOMETRY)\n",
        "elif PIPELINE == \"si\":\n",
        "    print(\"Running stable SI leapfrog stepper.\")\n",
        "    # e.g., si_history = run_star_tetra_cycle(..., geometry=GEOMETRY)\n",
        "else:\n",
        "    raise ValueError(\"Unknown PIPELINE.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cdd9aab"
      },
      "source": [
        "# @title 11. **Adelic Layer — ℚ_p Utilities & Prime Sweep** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Implements p-adic valuation/norm; builds composite “adelic balance”; sweeps primes (e.g., 2,3,5,7,11,…,137) for robustness."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf480c0d"
      },
      "source": [
        "# @title 12. **Breath Operator — Inhale/Exhale Rhythm** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Alternates phases to favour in-breath (0→C, even→C) and out-breath (C→odd, 1→2 work, 3→0 heat); non-local C stays mediated."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24c6c773"
      },
      "source": [
        "# @title 13. **LENR Cycle Runner — Pump → Coherence → Squeeze → Fusion → Heat** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Executes the breath-driven cycle; integrates adelic scaling at node 3; detects “bursts” on phase-lock; logs heat/entropy.\n",
        "\n",
        "\n",
        "\n",
        "def run_cycle(G_base: nx.DiGraph, steps=400, dt=mpf('0.05'), report_every=80):\n",
        "    global phi_star\n",
        "    energy = {n: mpf('0.5') for n in ALL}\n",
        "    energy['1'] = mpf('1.0'); energy['5'] = mpf('1.0')   # start with E channels primed\n",
        "    bursts = 0; entropy = mpf('0.0'); history = {'heat': [], 'entropy': [], 'bursts': [], 'phase': []}\n",
        "\n",
        "    for k in range(steps):\n",
        "        # Breath modulation (non-destructive per step)\n",
        "        Gk, phase = apply_breath(G_base, k)\n",
        "\n",
        "        # Simple conservative flow pass (rate * energy at source)\n",
        "        for (u,v,data) in Gk.edges(data=True):\n",
        "            flow = energy[u] * data['rate'] * dt\n",
        "            if 'threshold' in data and flow < data['threshold']:\n",
        "                continue\n",
        "            energy[u] -= flow; energy[v] += flow\n",
        "\n",
        "        # p-adic scaling at matter nodes (3,7)\n",
        "        for m in ['3','7']:\n",
        "            e_r = energy[m]\n",
        "            e_p = padic_norm_from_energy(e_r)\n",
        "            e_r, e_p = adelic_balance(e_r, e_p)\n",
        "            energy[m] = e_r * power(e_p, alpha_pad)\n",
        "\n",
        "        # Fusion bursts when C↔matter near phase lock (diagnostic, not physical prediction)\n",
        "        # Use linter's phase (C fixed at 0) — here we proxy lock by small random jitter\n",
        "        jitter = abs(np.sin(phi_star[idx['C']] - phi_star[idx['3']])) + \\\n",
        "                 abs(np.sin(phi_star[idx['C']] - phi_star[idx['7']]))\n",
        "        if jitter < 0.2:\n",
        "            # split burst between shells if available\n",
        "            for m, sink in [('3','0'), ('7','4')]:\n",
        "                burst = energy[m] * mpf('0.3')\n",
        "                energy[m] -= burst\n",
        "                energy[sink] += burst * mpf('0.9')\n",
        "                entropy += burst * mpf('0.1')\n",
        "            bursts += 1\n",
        "\n",
        "        # Phase linter step (non-invasive)\n",
        "        phi_star = phase_step(phi_star, float(dt))\n",
        "\n",
        "        # Log\n",
        "        history['heat'].append(float(energy['0'] + energy['4']))\n",
        "        history['entropy'].append(float(entropy))\n",
        "        history['bursts'].append(int(bursts))\n",
        "        if k % report_every == 0:\n",
        "            print(f\"step {k:4d}  breath={phase:>4s}  bursts={bursts}  heat={history['heat'][-1]:.3f}  \",\n",
        "                  phase_report(phi_star))\n",
        "    return history\n",
        "\n",
        "hist = run_cycle(G, steps=360)\n",
        "print(\"\\nFinal:\", \"bursts=\", hist['bursts'][-1], \"entropy=\", hist['entropy'][-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d84557c"
      },
      "source": [
        "# @title 14. **Stable SI Stepper — Leapfrog + CFL + Joule Heating** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Uses leapfrog with CFL time step; computes SI energy, Joule power, entropy production; reports realistic field magnitudes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e99fb2f1"
      },
      "source": [
        "# @title 15. **Visualisations — Energy, EPR, Spectra, Phases** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Plots energy/frequency time-series, EPR bars (normal vs counterfactual vs low-T), residuals, phase diagnostics."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c51c160b"
      },
      "source": [
        "# @title 16. **Red-Team Nulls & Ablations — Try to Break It** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Degree-preserving rewires; geometry swap (octahedron); no-adelic baseline; breath disabled; 2→1 during exhale only."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e18fb48c"
      },
      "source": [
        "# @title 17. **Preregistered Sweep — Seeds × Parameters × Outcomes** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Freezes thresholds; runs multiple seeds; aggregates pass/fail for quantised heat + mediation/EPR signatures."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d12d1f2"
      },
      "source": [
        "# @title 18. **Centroid Work vs Heat Ledger — Path Classification** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Labels forward “work-like” shortcuts (e.g., 0→1, 2→3) and backward “heat-like” fallbacks (1→0, 3→2); tallies contributions."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42f20ef7"
      },
      "source": [
        "# @title 19. **Star-Tetra Runner — Cross-Tetra Breath with Cubic Bridges** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Executes your S1↔S2 pathing rules; measures mediation across C, cross-domain hitting times, and burst propagation."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31527ebe"
      },
      "source": [
        "# @title 20. **Centroid Locality Tests — Algorithmic Induction Around C** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Drives edge-based current scenarios near C; probes iterative/inductive dynamics; quantifies sensitivity to 109.47° bias."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c84fd14f"
      },
      "source": [
        "# @title 21. **Save & Export — Results, Seeds, Config** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Stores metrics, plots, chosen primes, geometry flags, and RNG seeds for reproducibility; optional JSON/CSV export."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6e4b814"
      },
      "source": [
        "# @title 22. **Appendix — Utilities & Helpers** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this contains**\n",
        "\n",
        "# @markdown - Small helpers (index maps, safe mat-ops, plotting styles), validation checks, and pretty printers."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}