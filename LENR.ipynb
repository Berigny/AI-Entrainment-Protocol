{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS5QFOTM9pXCAL6o22lYtg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berigny/AI-Entrainment-Protocol/blob/main/LENR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Low Energy Nuclear (LENR) Cycles Model\n",
        "This notebook tests whether a minimal, topology-first model can simulate and falsify a low-energy nuclear reaction (LENR) cycle driven by breath-like EM coherence. Using Discrete Exterior Calculus (DEC) on a star-tetrahedral complex with a shared centroid, we evolve fields, enforce first-law energy accounting, monitor entropy production and phase relations, and—optionally—add an adelic (ℝ × ℚ_p) layer to represent hierarchical memory at the fusion node. If quantised heat bursts do not emerge with lawful topology, pre-burst EM signatures, rising EPR, and correct energy balance, the hypothesis is weakened. If they do, we proceed to richer modelling and lab validation. The prize is significant: a path to low-cost, high-yield, sustainable energy in an energy-hungry world.\n",
        "\n",
        "## Falsification criteria\n",
        "\n",
        "We consider the LENR cycle unsupported if any lawful configuration fails to produce:\n",
        "(i) pre-burst EM coherence with ~90° E–M phase and centroid mediation,\n",
        "(ii) quantised heat steps at the sink,\n",
        "(iii) a non-negative EPR that rises prior to bursts, and\n",
        "(iv) first-law integrity (residual ≈ 0).\n",
        "Controls must behave as expected: illegal shortcuts reduce irreversibility or break energy accounting; removing C→3 or 1→2 kills bursts; random primes revert to baseline."
      ],
      "metadata": {
        "id": "qKR1ogm8760g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eb7eb44"
      },
      "source": [
        "# @title 0. **Notebook Overview & Research Aim** { display-mode: \"form\" }\n",
        "# @markdown **Goal**\n",
        "# @markdown - Simulate and *attempt to falsify* LENR-like cycles on a tetrahedral (and star-tetrahedral) topology.\n",
        "# @markdown - If not falsified, motivate deeper modelling and lab tests for low-cost, high-yield, sustainable energy.\n",
        "# @markdown **Key Ideas**\n",
        "# @markdown - DEC on simplicial complexes; mediation via centroid **C**; breath-driven, asymmetric flows; adelic (ℝ×ℚ_p) layer."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3c07b46"
      },
      "source": [
        "# @title 1. **Imports & Global Config** { display-mode: \"form\" }\n",
        "# @markdown **What this sets**\n",
        "# @markdown - Imports, numeric precision/warnings, plotting defaults, reproducibility seeds.\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from mpmath import mpf, power\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f7f6517"
      },
      "source": [
        "# @title 2. **Geometry — Single Tetra (S1): Nodes, Edges, Breath Rules** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines S1 vertices {0,1,2,3,C}, allowed directed edges, self-loops, and “breath” semantics (work vs heat).\n",
        "\n",
        "\n",
        "# Nodes: two tetrahedra share a single centroid C\n",
        "S1 = ['0','1','2','3']          # sinks even / branches odd\n",
        "S2 = ['4','5','6','7']\n",
        "ALL = S1 + S2 + ['C']\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(ALL)\n",
        "\n",
        "# Baseline rates (mpf for clean high-precision arithmetic)\n",
        "r = lambda x: mpf(str(x))\n",
        "\n",
        "# Core single-shell flows (work/heat + mediation)\n",
        "core_edges_S1 = [\n",
        "    ('C','1', {'rate': r(0.5)}),   # pump\n",
        "    ('1','2', {'rate': r(0.8)}),   # E→M (work)\n",
        "    ('2','C', {'rate': r(0.9)}),   # return to mediator\n",
        "    ('C','3', {'rate': r(0.7)}),   # squeeze/fusion path\n",
        "    ('3','0', {'rate': r(1.0)}),   # heat dump\n",
        "    ('0','C', {'rate': r(0.3)}),   # reset\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "662659ce",
        "outputId": "49ffbc78-a31f-464f-fb6d-5e1b9768d368"
      },
      "source": [
        "# @title 3. **Geometry — Star Tetra (S1 + S2) with Cubic Bridges** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Adds S2 vertices {4,5,6,7} and inter-tetra “cubic” bridges; encodes the cross-tetra flow sequence you specified.\n",
        "\n",
        "core_edges_S2 = [\n",
        "    ('C','5', {'rate': r(0.5)}),\n",
        "    ('5','6', {'rate': r(0.8)}),\n",
        "    ('6','C', {'rate': r(0.9)}),\n",
        "    ('C','7', {'rate': r(0.7)}),\n",
        "    ('7','4', {'rate': r(1.0)}),\n",
        "    ('4','C', {'rate': r(0.3)}),\n",
        "]\n",
        "\n",
        "# Cubic cross-edges (work bridge + heat dumps)\n",
        "cross_edges = [\n",
        "    ('3','6', {'rate': r(0.35)}),  # work bridge (coherent transfer S1→S2)\n",
        "    ('7','2', {'rate': r(0.25)}),  # heat-biased back to S1 magnetic\n",
        "    ('5','0', {'rate': r(0.20)}),  # heat dump assist into S1 sink\n",
        "    ('1','6', {'rate': r(0.20)}),  # optional assist E→M across shells\n",
        "]\n",
        "\n",
        "# Self-loops (stability/linger)\n",
        "self_loops = [(n, n, {'rate': r(0.4)}) for n in S1+S2]\n",
        "\n",
        "G.add_edges_from(core_edges_S1 + core_edges_S2 + cross_edges + self_loops)\n",
        "print(\"Graph ready. |V|=\", len(G.nodes), \"|E|=\", len(G.edges))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph ready. |V|= 9 |E|= 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. **DEC Operators — B₁, B₂ and Incidence-based Hodge Stars** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds boundary maps (nodes→edges, faces→edges) and rectangular Hodge stand-ins; checks shapes and orientations.\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# --- Inputs assumed from earlier cells ---\n",
        "# - G: nx.DiGraph()\n",
        "# - ALL: list of node keys (must include 'C' and a tetra like {0,1,2,3}) # Corrected: use ALL instead of nodes\n",
        "# - edges: list of (u, v, data) or available via G.edges(data=True)\n",
        "\n",
        "# ---------- Indexing & edge list normalisation ----------\n",
        "# Using ALL which is defined in a previous cell\n",
        "if isinstance(ALL, dict): # Corrected: check ALL instead of nodes\n",
        "    node_keys = list(ALL.keys())\n",
        "else:\n",
        "    node_keys = list(ALL)\n",
        "\n",
        "node_idx = {n: i for i, n in enumerate(node_keys)}\n",
        "n_nodes = len(node_idx)\n",
        "\n",
        "# Normalise edges into (u,v,data) triples\n",
        "if 'edges' in globals():\n",
        "    _edge_triples = []\n",
        "    for e in edges:\n",
        "        if len(e) == 3:\n",
        "            _edge_triples.append(e)\n",
        "        else:\n",
        "            u, v = e\n",
        "            _edge_triples.append((u, v, G.get_edge_data(u, v, default={}) or {}))\n",
        "    edges = _edge_triples\n",
        "else:\n",
        "    edges = list(G.edges(data=True))\n",
        "\n",
        "n_edges = len(edges)\n",
        "edge_idx = {(u, v): i for i, (u, v, _) in enumerate(edges)}\n",
        "\n",
        "# ---------- B1: node→edge incidence (signed) ----------\n",
        "# Shape: (n_nodes, n_edges)\n",
        "B1 = np.zeros((n_nodes, n_edges), dtype=float)\n",
        "for e_i, (u, v, _) in enumerate(edges):\n",
        "    B1[node_idx[u], e_i] = -1.0\n",
        "    B1[node_idx[v], e_i] = +1.0\n",
        "B1 = csr_matrix(B1)\n",
        "\n",
        "# ---------- Faces (triangles) ----------\n",
        "# Use tetra faces over S1={0,1,2,3}; if S2={4,5,6,7} exists, add those too.\n",
        "faces = []\n",
        "if all(k in node_idx for k in ['0', '1', '2', '3']):\n",
        "    faces += [('0', '1', '2'), ('0', '1', '3'), ('0', '2', '3'), ('1', '2', '3')]\n",
        "if all(k in node_idx for k in ['4', '5', '6', '7']):\n",
        "    faces += [('4', '5', '6'), ('4', '5', '7'), ('4', '6', '7'), ('5', '6', '7')]\n",
        "\n",
        "n_faces = len(faces)\n",
        "\n",
        "# ---------- B2: face→edge incidence (signed, oriented) ----------\n",
        "# We store B2 as (n_edges, n_faces) so curl-like ops use B2.T @ E and B2 @ B.\n",
        "B2 = np.zeros((n_edges, n_faces), dtype=float)\n",
        "for f_j, (a, b, c) in enumerate(faces):\n",
        "    oriented = [(a, b), (b, c), (c, a)]  # counter-clockwise orientation\n",
        "    for (u, v) in oriented:\n",
        "        if (u, v) in edge_idx:\n",
        "            B2[edge_idx[(u, v)], f_j] = +1.0\n",
        "        elif (v, u) in edge_idx:\n",
        "            B2[edge_idx[(v, u)], f_j] = -1.0\n",
        "        # else: directed edge absent in this face; remains 0\n",
        "B2 = csr_matrix(B2)\n",
        "\n",
        "# ---------- Incidence-based rectangular Hodge stand-ins ----------\n",
        "# faces×edges indicator (orientation-agnostic, averaged to unit mass per face)\n",
        "Inc_fe = np.zeros((n_faces, n_edges), dtype=float)\n",
        "for f_j, (a, b, c) in enumerate(faces):\n",
        "    undirected_six = [(a, b), (b, c), (c, a), (b, a), (c, b), (a, c)]\n",
        "    seen = set()\n",
        "    for (u, v) in undirected_six:\n",
        "        if (u, v) in edge_idx and (u, v) not in seen:\n",
        "            Inc_fe[f_j, edge_idx[(u, v)]] = 1.0\n",
        "            seen.add((u, v))\n",
        "# normalise rows so each face sums to 1 (if any edges present)\n",
        "row_sums = Inc_fe.sum(axis=1, keepdims=True)\n",
        "row_sums[row_sums == 0.0] = 1.0\n",
        "Inc_fe_avg = Inc_fe / row_sums                 # faces × edges\n",
        "Inc_ef_avg = Inc_fe_avg.T                      # edges × faces\n",
        "\n",
        "# Rectangular Hodge stand-ins\n",
        "# star_eps   : edges→faces (acts like ε⋆ on E to produce D-like face field)\n",
        "# star_muinv : faces→edges (acts like μ^{-1}⋆ on B to produce H-like edge field)\n",
        "star_eps   = csr_matrix(Inc_fe_avg)            # (n_faces, n_edges)\n",
        "star_muinv = csr_matrix(Inc_ef_avg)            # (n_edges, n_faces)\n",
        "\n",
        "# ---------- Sanity checks ----------\n",
        "def _nnz(M): return int(M.nnz) if hasattr(M, 'nnz') else int(np.count_nonzero(M))\n",
        "\n",
        "print(f\"B1 shape: {B1.shape}  nnz={_nnz(B1)}   (nodes→edges, signed)\")\n",
        "print(f\"B2 shape: {B2.shape}  nnz={_nnz(B2)}   (edges→faces, signed)\")\n",
        "print(f\"star_eps   (faces×edges): {star_eps.shape}  nnz={_nnz(star_eps)}\")\n",
        "print(f\"star_muinv (edges×faces): {star_muinv.shape}  nnz={_nnz(star_muinv)}\")\n",
        "\n",
        "# Boundary-of-boundary check on fully represented faces (should be ≈0)\n",
        "# Only evaluate faces where all three directed (or reverse-directed) edges exist.\n",
        "full_cols = []\n",
        "for j in range(n_faces):\n",
        "    if np.count_nonzero(B2.toarray()[:, j]) == 3:\n",
        "        full_cols.append(j)\n",
        "if full_cols:\n",
        "    bb = (B1 @ B2[:, full_cols]).toarray()     # nodes×faces subset\n",
        "    print(f\"‣ ||B1 @ B2||_F on full faces: {np.linalg.norm(bb):.3e}\")\n",
        "else:\n",
        "    print(\"‣ No fully represented faces (directed) to test B1@B2≈0; this is OK for asymmetric graphs.\")\n",
        "\n",
        "# Preview first face’s oriented edge signs (if any)\n",
        "if n_faces:\n",
        "    j = 0\n",
        "    col = B2.toarray()[:, j]\n",
        "    present = [(e, col[e]) for e in np.where(col != 0)[0]]\n",
        "    face_str = f\"{faces[j][0]}-{faces[j][1]}-{faces[j][2]}\"\n",
        "    print(f\"Face[0]={face_str} has {len(present)} directed edges in graph (±1 signs show orientation).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1pqe2HQ_n5m",
        "outputId": "9ecae4a5-68e1-4413-b697-1bb5d5e642e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B1 shape: (9, 24)  nnz=40   (nodes→edges, signed)\n",
            "B2 shape: (24, 8)  nnz=8   (edges→faces, signed)\n",
            "star_eps   (faces×edges): (8, 24)  nnz=8\n",
            "star_muinv (edges×faces): (24, 8)  nnz=8\n",
            "‣ No fully represented faces (directed) to test B1@B2≈0; this is OK for asymmetric graphs.\n",
            "Face[0]=0-1-2 has 1 directed edges in graph (±1 signs show orientation).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. **Phase Linter — Double Tetra (drop-in) { display-mode: \"form\" }**\n",
        "# @markdown Non-invasive phase hygiene. Targets ~90° between E–M in each shell (1–2, 5–6),\n",
        "# @markdown ~90° on work bridge (3–6), and ~180° on heat dumps (7–4, 7–2, 5–0). Anchors softly to C=0.\n",
        "import numpy as np\n",
        "\n",
        "node_list = ['0','1','2','3','4','5','6','7','C']\n",
        "idx = {k:i for i,k in enumerate(node_list)}\n",
        "if 'phi_star' not in globals(): phi_star = np.zeros(len(node_list))\n",
        "\n",
        "def _wrap_pi(x): return (x + np.pi) % (2*np.pi) - np.pi\n",
        "\n",
        "# Couplings\n",
        "kap = np.zeros((len(node_list), len(node_list)))\n",
        "def setk(a,b,val):\n",
        "    i,j = idx[a], idx[b]; kap[i,j]=val; kap[j,i]=val\n",
        "\n",
        "# Baseline weak, stronger EM, work/heat targets\n",
        "for U in (S1,S2):\n",
        "    for i,u in enumerate(U):\n",
        "        for v in U[i+1:]: setk(u,v,0.02)\n",
        "setk('1','2',0.12); setk('5','6',0.12)\n",
        "setk('3','6',0.08); setk('7','4',0.05); setk('7','2',0.05); setk('5','0',0.05)\n",
        "\n",
        "# Target lags\n",
        "theta = np.zeros_like(kap)\n",
        "def setθ(a,b,rad):\n",
        "    i,j=idx[a],idx[b]; theta[i,j]=rad; theta[j,i]=rad\n",
        "setθ('1','2', np.pi/2); setθ('5','6', np.pi/2); setθ('3','6', np.pi/2)\n",
        "setθ('7','4', np.pi);   setθ('7','2', np.pi);   setθ('5','0', np.pi)\n",
        "\n",
        "γC = 0.05  # anchor to C\n",
        "\n",
        "def phase_step(phi, dt):\n",
        "    d = np.zeros_like(phi)\n",
        "    for u in S1+S2:\n",
        "        i = idx[u]; acc = 0.0\n",
        "        for v in S1+S2:\n",
        "            if v==u: continue\n",
        "            j = idx[v]\n",
        "            acc += kap[i,j]*np.sin(phi[j]-phi[i]-theta[i,j])\n",
        "        acc -= γC*np.sin(phi[i]-0.0)\n",
        "        d[i]=acc\n",
        "    phi[:8]+=dt*d[:8]; return _wrap_pi(phi)\n",
        "\n",
        "def phase_report(phi):\n",
        "    def err(a,b,trg):\n",
        "        i,j=idx[a],idx[b]; return float(np.degrees(_wrap_pi((phi[i]-phi[j])-trg)))\n",
        "    return {\n",
        "        'EM_S1_deg': err('1','2',np.pi/2),\n",
        "        'EM_S2_deg': err('5','6',np.pi/2),\n",
        "        'work_3_6_deg': err('3','6',np.pi/2),\n",
        "        'heat_7_4_deg': err('7','4',np.pi),\n",
        "        'heat_7_2_deg': err('7','2',np.pi),\n",
        "        'heat_5_0_deg': err('5','0',np.pi),\n",
        "        'C_phase_deg': float(np.degrees(phi[idx['C']])),\n",
        "    }\n",
        "\n",
        "print(\"Phase linter loaded (double tetra).\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKkeHbZI-4fJ",
        "outputId": "60ae9ba1-5d8f-4285-d90e-0eee98351f86",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase linter loaded (double tetra).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fc07da8",
        "outputId": "5a79c17f-9a8b-4a73-fdb6-21b6d80a098b"
      },
      "source": [
        "# @title 4. **DEC Operators — B₁, B₂ and Incidence-based Hodge Stars** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds boundary maps **B₁** (nodes→edges) and **B₂** (faces→edges; stored as edges×faces for convenient curls).\n",
        "# @markdown - Derives simple, incidence-averaged rectangular Hodge stand-ins: **star_eps: faces×edges**, **star_muinv: edges×faces**.\n",
        "# @markdown - Auto-detects **S1** faces (0–3) and, if present, **S2** faces (4–7) for the star-tetrahedron.\n",
        "# @markdown - Verifies the topological identity **B₁·B₂ = 0** (boundary of a boundary is zero) and reports orientation coverage.\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# --- Safety checks / inputs from earlier cells ---\n",
        "assert 'G' in globals(), \"Expected a DiGraph G from earlier geometry cells.\"\n",
        "edges_with_data = list(G.edges(data=True))\n",
        "assert len(edges_with_data) > 0, \"Graph has no edges.\"\n",
        "\n",
        "# Canonical string labels (robust to int/str mixing)\n",
        "node_labels = [str(n) for n in G.nodes()]\n",
        "node_idx = {lbl: i for i, lbl in enumerate(node_labels)}\n",
        "n_nodes = len(node_labels)\n",
        "\n",
        "# Edge order (u,v) as strings -> index\n",
        "edge_order = [(str(u), str(v)) for (u, v, _) in edges_with_data]\n",
        "edge_idx = {e: i for i, e in enumerate(edge_order)}\n",
        "n_edges = len(edge_order)\n",
        "\n",
        "# --- Face list (auto-detect S1 and S2 tetra faces; ignore C in faces) ---\n",
        "faces = []\n",
        "S1 = {'0', '1', '2', '3'}\n",
        "S2 = {'4', '5', '6', '7'}\n",
        "if S1.issubset(set(node_labels)):\n",
        "    faces += [('0', '1', '2'), ('0', '1', '3'), ('0', '2', '3'), ('1', '2', '3')]\n",
        "if S2.issubset(set(node_labels)):\n",
        "    faces += [('4', '5', '6'), ('4', '5', '7'), ('4', '6', '7'), ('5', '6', '7')]\n",
        "n_faces = len(faces)\n",
        "assert n_faces > 0, \"No tetra faces detected (need nodes 0–3 and/or 4–7).\"\n",
        "\n",
        "# --- B1: nodes (rows) → edges (cols) ---\n",
        "# Convention: tail = -1 at source(u), head = +1 at target(v)\n",
        "B1 = np.zeros((n_nodes, n_edges), dtype=float)\n",
        "for e_idx, (u, v) in enumerate(edge_order):\n",
        "    B1[node_idx[u], e_idx] = -1.0\n",
        "    B1[node_idx[v], e_idx] = +1.0\n",
        "B1 = csr_matrix(B1)\n",
        "\n",
        "# --- B2: edges (rows) → faces (cols), with oriented incidence ---\n",
        "# For each face (a,b,c), use oriented cycle (a→b, b→c, c→a)\n",
        "B2 = np.zeros((n_edges, n_faces), dtype=float)\n",
        "missing_orientations = []\n",
        "coverage_per_face = []\n",
        "for f_idx, (a, b, c) in enumerate(faces):\n",
        "    oriented = [(a, b), (b, c), (c, a)]\n",
        "    covered = 0\n",
        "    for (p, q) in oriented:\n",
        "        if (p, q) in edge_idx:\n",
        "            B2[edge_idx[(p, q)], f_idx] = +1.0\n",
        "            covered += 1\n",
        "        elif (q, p) in edge_idx:\n",
        "            B2[edge_idx[(q, p)], f_idx] = -1.0\n",
        "            covered += 1\n",
        "        else:\n",
        "            missing_orientations.append(((p, q), f_idx))\n",
        "    coverage_per_face.append(covered)\n",
        "B2 = csr_matrix(B2)\n",
        "\n",
        "# --- Rectangular Hodge stand-ins (incidence-averaged) ---\n",
        "# Inc_fe: faces×edges with 1 if edge touches face (ignore sign)\n",
        "Inc_fe = (B2.T.copy()).toarray()\n",
        "Inc_fe[Inc_fe != 0.0] = 1.0\n",
        "row_sums = Inc_fe.sum(axis=1, keepdims=True)\n",
        "row_sums[row_sums == 0.0] = 1.0  # avoid divide-by-zero\n",
        "Inc_fe_avg = Inc_fe / row_sums                      # faces × edges\n",
        "Inc_ef_avg = Inc_fe_avg.T                           # edges × faces\n",
        "\n",
        "# Hodge-like maps used in the DEC stepper\n",
        "# D = star_eps @ E   (faces)\n",
        "# H = star_muinv @ B (edges)\n",
        "star_eps   = csr_matrix(Inc_fe_avg)                 # faces × edges\n",
        "star_muinv = csr_matrix(Inc_ef_avg)                 # edges × faces\n",
        "\n",
        "# --- Topological consistency check: B₁ · B₂ = 0 ---\n",
        "BB = (B1 @ B2).toarray()                            # nodes × faces\n",
        "bb_max = np.max(np.abs(BB)) if BB.size else 0.0\n",
        "\n",
        "# --- Reports ---\n",
        "print(f\"B1 shape (nodes→edges):     {B1.shape}\")\n",
        "print(f\"B2 shape (edges→faces):     {B2.shape}\")\n",
        "print(f\"star_eps shape (faces×edges):   {star_eps.shape}\")\n",
        "print(f\"star_muinv shape (edges×faces): {star_muinv.shape}\")\n",
        "print(f\"Faces detected: {n_faces}  (S1={'yes' if S1.issubset(set(node_labels)) else 'no'}, \"\n",
        "      f\"S2={'yes' if S2.issubset(set(node_labels)) else 'no'})\")\n",
        "\n",
        "if missing_orientations:\n",
        "    print(f\"Warning: {len(missing_orientations)} face-edge orientations missing from the graph.\")\n",
        "else:\n",
        "    print(\"All oriented face edges found in the graph.\")\n",
        "\n",
        "print(\"Per-face oriented edge coverage (expect 3 per face):\", coverage_per_face)\n",
        "print(f\"Boundary-of-boundary check ||B1·B2||_∞ = {bb_max:.1e} (should be 0.0 within integer arithmetic)\")\n",
        "\n",
        "# --- Exports for later cells ---\n",
        "# node_idx, edge_idx, faces, n_nodes, n_edges, n_faces, B1, B2, star_eps, star_muinv remain in scope.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B1 shape (nodes→edges):     (9, 24)\n",
            "B2 shape (edges→faces):     (24, 8)\n",
            "star_eps shape (faces×edges):   (8, 24)\n",
            "star_muinv shape (edges×faces): (24, 8)\n",
            "Faces detected: 8  (S1=yes, S2=yes)\n",
            "Warning: 16 face-edge orientations missing from the graph.\n",
            "Per-face oriented edge coverage (expect 3 per face): [1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Boundary-of-boundary check ||B1·B2||_∞ = 1.0e+00 (should be 0.0 within integer arithmetic)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a16d488b",
        "outputId": "b85e5835-458f-429d-b386-0e9e629c2787"
      },
      "source": [
        "# @title 5. **SI Calibration — Lengths, Areas, Materials, CFL** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Sets edge lengths, face areas, dual measures; picks tissue-like ε, μ, σ; derives star_1, star_2; computes CFL-limited Δt.\n",
        "\n",
        "import numpy as np\n",
        "from mpmath import mpf\n",
        "\n",
        "# --- Geometric Setup (Assumes n_edges, n_faces from Cell 4) ---\n",
        "# Ensure n_edges and n_faces are available from Cell 4 globals\n",
        "try:\n",
        "    n_edges = globals()['n_edges'] # Get n_edges from global scope (set in Cell 4)\n",
        "    n_faces = globals()['n_faces'] # Get n_faces from global scope (set in Cell 4)\n",
        "except KeyError:\n",
        "    raise ValueError(\"Run Cell 4 (DEC Operators) first to set global n_edges and n_faces.\")\n",
        "\n",
        "\n",
        "# Edge length a (SI: meters; nanoscale for LENR lattice, e.g., Pd interatomic ~0.275 nm)\n",
        "a = mpf('1e-9')  # 1 nm side length\n",
        "\n",
        "# Edge lengths vector (all equal for regular, but dimensioned for the full graph)\n",
        "# Assuming a uniform edge length 'a' for all edges in the complex for simplicity in this calibration step.\n",
        "edge_lengths = np.full(n_edges, float(a))\n",
        "\n",
        "# Face areas: Equilateral triangle area = (sqrt(3)/4) * a^2\n",
        "# Assuming all faces have the same area based on edge length 'a' for simplicity.\n",
        "face_area = (np.sqrt(3)/4) * float(a)**2\n",
        "face_areas = np.full(n_faces, face_area)\n",
        "\n",
        "# Dual measures (DEC Hodge stars: *1 for edges ≈ dual edge lengths, *2 for faces ≈ dual volumes)\n",
        "# For primal simplicial complex, *1(e) ≈ length of dual edge (circumcentric dual, approx a for simplicity)\n",
        "star_1_measure = np.full(n_edges, float(a))  # Dual 1-form measure on edges\n",
        "\n",
        "# *2(f) ≈ volume of dual cell (approx face_area * height, but for flat, use face_area)\n",
        "star_2_measure = np.full(n_faces, face_area)  # Dual 2-form measure on faces\n",
        "\n",
        "print(f\"Using n_edges={n_edges}, n_faces={n_faces} from Cell 4.\")\n",
        "print(f\"Edge lengths (vector size {len(edge_lengths)}): {edge_lengths[:5]}...\") # Print first few for brevity\n",
        "print(f\"Face areas (vector size {len(face_areas)}): {face_areas[:5]}...\") # Print first few for brevity\n",
        "print(f\"star_1_measure (dual edges, size {len(star_1_measure)}): {star_1_measure[:5]}...\")\n",
        "print(f\"star_2_measure (dual faces, size {len(star_2_measure)}): {star_2_measure[:5]}...\")\n",
        "\n",
        "\n",
        "# --- Materials (Tissue-like for Bio/LENR Analogy: High ε, Moderate σ) ---\n",
        "# Relative permittivity ε_r (tissue ~10^4 at low freq), permeability μ_r=1 (non-magnetic)\n",
        "ε_r = mpf('1e4')\n",
        "μ_r = mpf('1')\n",
        "\n",
        "# Absolute ε, μ (vacuum base: ε0=8.85e-12 F/m, μ0=1.2566e-6 H/m)\n",
        "ε0 = mpf('8.854187817e-12')\n",
        "μ0 = mpf('1.25663706212e-6')\n",
        "ε = ε_r * ε0\n",
        "μ = μ_r * μ0\n",
        "\n",
        "# Conductivity σ (S/m; tissue ~0.5 S/m for Joule heating proxy)\n",
        "σ = mpf('0.5')\n",
        "\n",
        "print(f\"ε_r = {ε_r}, μ_r = {μ_r}\")\n",
        "print(f\"ε = {float(ε):.2e} F/m, μ = {float(μ):.2e} H/m\")\n",
        "print(f\"σ = {σ} S/m\")\n",
        "\n",
        "# --- CFL Computation ---\n",
        "# Wave speed c = 1 / sqrt(ε μ)\n",
        "c = mpf('1') / np.sqrt(float(ε * μ))\n",
        "\n",
        "# Spatial step Δx = min edge length\n",
        "# Using the minimum value from the edge_lengths array\n",
        "Δx = np.min(edge_lengths)\n",
        "\n",
        "# CFL condition: Δt ≤ CFL_factor * Δx / c (CFL_factor=0.5 for stability in leapfrog)\n",
        "CFL_factor = mpf('0.5')\n",
        "Δt_max = CFL_factor * Δx / c\n",
        "\n",
        "print(f\"Wave speed c = {float(c):.2e} m/s\")\n",
        "print(f\"Δx_min = {float(Δx):.2e} m\")\n",
        "print(f\"Max stable Δt = {float(Δt_max):.2e} s (CFL_factor={float(CFL_factor)})\")\n",
        "\n",
        "# --- Store Globals for Later Cells ---\n",
        "# (These will be used in stepper, e.g., for dt in leapfrog)\n",
        "global_dt = Δt_max\n",
        "global_epsilon = ε\n",
        "global_mu = μ\n",
        "global_sigma = σ\n",
        "global_c = c\n",
        "\n",
        "print(\"\\nCalibration complete. Globals set: dt_max, ε, μ, σ, c.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using n_edges=24, n_faces=8 from Cell 4.\n",
            "Edge lengths (vector size 24): [1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]...\n",
            "Face areas (vector size 8): [4.33012702e-19 4.33012702e-19 4.33012702e-19 4.33012702e-19\n",
            " 4.33012702e-19]...\n",
            "star_1_measure (dual edges, size 24): [1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]...\n",
            "star_2_measure (dual faces, size 8): [4.33012702e-19 4.33012702e-19 4.33012702e-19 4.33012702e-19\n",
            " 4.33012702e-19]...\n",
            "ε_r = 10000.0, μ_r = 1.0\n",
            "ε = 8.85e-08 F/m, μ = 1.26e-06 H/m\n",
            "σ = 0.5 S/m\n",
            "Wave speed c = 3.00e+06 m/s\n",
            "Δx_min = 1.00e-09 m\n",
            "Max stable Δt = 1.67e-16 s (CFL_factor=0.5)\n",
            "\n",
            "Calibration complete. Globals set: dt_max, ε, μ, σ, c.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prep — Energy Forms (Se, Sb) and Edge Damping (R) { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds SPD energy matrices **Se = star_epsᵀ star_eps** (edges×edges) and **Sb = star_muinvᵀ star_muinv** (faces×faces).\n",
        "# @markdown - Creates a sparse diagonal damping **R** on edges that flow **into the Null node (…→0)** to model heat loss.\n",
        "# @markdown - Re-run this cell whenever you change the graph/topology or Hodge operators.\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Guards: require rectangular Hodge stars and indexing from earlier cells\n",
        "needed = ['star_eps','star_muinv','edges','edge_idx','n_edges','n_faces']\n",
        "missing = [k for k in needed if k not in globals()]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"Run your DEC operator cells first; missing: {missing}\")\n",
        "\n",
        "# --- SPD energy forms (dense for simplicity) ---\n",
        "Se = (star_eps.T @ star_eps).toarray()       # edges × edges\n",
        "Sb = (star_muinv.T @ star_muinv).toarray()   # faces × faces\n",
        "\n",
        "# --- Edge damping R (sparse diag) ---\n",
        "# Default: damp edges that END at the Null node '0'  (… → 0)\n",
        "r = np.zeros(n_edges, dtype=float)\n",
        "for (u, v, _d) in edges:\n",
        "    e = edge_idx.get((u, v))\n",
        "    if e is None:\n",
        "        continue\n",
        "    if v == '0':\n",
        "        r[e] = 1e-2   # small loss; tune as needed\n",
        "\n",
        "R = csr_matrix(np.diag(r))\n",
        "\n",
        "print(\"Se shape:\", Se.shape, \" | Sb shape:\", Sb.shape, \" | R nnz:\", R.nnz)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqI9gXCq9HoJ",
        "outputId": "eb2f943e-f9e2-4fea-da35-85e3895cd996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se shape: (24, 24)  | Sb shape: (8, 8)  | R nnz: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prep — Cast DEC operators & globals to float (fix object dtypes) { display-mode: \"form\" }\n",
        "\n",
        "# Cast all scalar globals to plain floats\n",
        "global_dt = float(global_dt)\n",
        "global_epsilon = float(global_epsilon)\n",
        "global_mu = float(global_mu)\n",
        "global_sigma = float(global_sigma)\n",
        "\n",
        "# Cast sparse operators to float64\n",
        "B2         = B2.astype(float)\n",
        "star_eps   = star_eps.astype(float)\n",
        "star_muinv = star_muinv.astype(float)\n",
        "R          = R.astype(float)\n",
        "\n",
        "# If Se/Sb were built earlier, rebuild/cast them to float now\n",
        "Se = (star_eps.T @ star_eps).astype(float).toarray()\n",
        "Sb = (star_muinv.T @ star_muinv).astype(float).toarray()\n",
        "\n",
        "print(\"Dtypes:\",\n",
        "      \"\\n  B2:\", B2.dtype,\n",
        "      \"\\n  star_eps:\", star_eps.dtype,\n",
        "      \"\\n  star_muinv:\", star_muinv.dtype,\n",
        "      \"\\n  R:\", R.dtype,\n",
        "      \"\\n  Se:\", Se.dtype, \"Sb:\", Sb.dtype,\n",
        "      \"\\nScalars: dt, ε, μ, σ =\", global_dt, global_epsilon, global_mu, global_sigma)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBO8tCYN9irG",
        "outputId": "3ed8bfc8-5cf2-4dbe-ce33-0435af6d9a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dtypes: \n",
            "  B2: float64 \n",
            "  star_eps: float64 \n",
            "  star_muinv: float64 \n",
            "  R: float64 \n",
            "  Se: float64 Sb: float64 \n",
            "Scalars: dt, ε, μ, σ = 1.667820476386291e-16 8.854187817000001e-08 1.25663706212e-06 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a2db0ea",
        "outputId": "43defd5f-1f0c-4dbe-8016-cd80e11b0d3d"
      },
      "source": [
        "# @title 6. **Baseline DEC Stepper (S1) — Energy & Frequency** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Uses your DEC operators (**B₂**, rectangular Hodge stars) to step **E (edges)** and **B (faces)**.\n",
        "# @markdown - Logs total energy via SPD forms (**Se, Sb**) and an “EEG-like” average-frequency proxy.\n",
        "# @markdown - Assumes Cells 4–5 have defined: `B2, star_eps, star_muinv, Se, Sb, R, edge_idx, n_edges, n_faces`.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# ---- guards: require prior cells ----\n",
        "required = ['B2','star_eps','star_muinv','Se','Sb','R','edge_idx','n_edges','n_faces',\n",
        "            'global_dt', 'global_epsilon', 'global_mu', 'global_sigma']\n",
        "missing = [k for k in required if k not in globals()]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"Run DEC operator cells first; missing: {missing}\")\n",
        "\n",
        "# time step (use something small and stable; or reuse your CFL dt if available)\n",
        "dt = float(global_dt)\n",
        "ε  = float(global_epsilon)\n",
        "μ  = float(global_mu)\n",
        "σ  = float(global_sigma)\n",
        "\n",
        "\n",
        "# ---- fields on correct carriers ----\n",
        "E = np.zeros(n_edges, dtype=float)   # edges (1-form)\n",
        "B = np.zeros(n_faces, dtype=float)   # faces (2-form)\n",
        "\n",
        "# Initial condition: small pump on C→1 if present\n",
        "# (re)seed ICs as float\n",
        "idx = edge_idx.get(('C','1'))\n",
        "if idx is not None:\n",
        "    E[idx] = 1e-4\n",
        "else:\n",
        "    print(\"Note: edge ('C','1') not found; skipping pump init.\")\n",
        "\n",
        "\n",
        "def dec_step(E, B, dt):\n",
        "    \"\"\"One explicit DEC step: Faraday (faces) then Ampère (edges) with edge damping R.\"\"\"\n",
        "    # ensure float arrays (guards against stray mpf/object)\n",
        "    E = np.asarray(E, dtype=float)\n",
        "    B = np.asarray(B, dtype=float)\n",
        "\n",
        "    # Faraday: dB/dt = - curl(E)   with curl(E) = B2.T @ E  (faces)\n",
        "    curl_E = (B2.T @ E)                 # shape: (n_faces,)\n",
        "    B_new  = B - dt * curl_E            # faces\n",
        "\n",
        "    # Ampère (explicit, schematic): dE/dt = (1/ε) * (faces→edges) - (σ/ε)E - R E\n",
        "    # faces→edges is B2 @ B_new (edges)\n",
        "    drive  = (B2 @ B_new)               # shape: (n_edges,)\n",
        "    damping = (R @ E)                   # shape: (n_edges,)\n",
        "    E_new  = E + (dt/ε) * drive - (dt*σ/ε) * E - dt * damping\n",
        "\n",
        "    return E_new, B_new\n",
        "\n",
        "\n",
        "def energy_total(E, B):\n",
        "    # SPD quadratic energy (consistent with your rectangular stars)\n",
        "    return 0.5 * (E @ (Se @ E) + B @ (Sb @ B))\n",
        "\n",
        "def eeg_like_freq(history, E, B, dt):\n",
        "    # simple global-oscillation proxy from mean |E|, |B| slopes\n",
        "    Em = float(np.mean(np.abs(E)))\n",
        "    Bm = float(np.mean(np.abs(B)))\n",
        "    if len(history['E_mean']) >= 1:\n",
        "        dEm = (Em - history['E_mean'][-1]) / dt\n",
        "        dBm = (Bm - history['B_mean'][-1]) / dt\n",
        "        return float(np.hypot(dEm, dBm)), Em, Bm\n",
        "    return 0.0, Em, Bm\n",
        "\n",
        "# quick shape asserts (run once after defining B2, E, B)\n",
        "assert B2.shape == (n_edges, n_faces)\n",
        "assert (B2.T @ E).shape == (n_faces,)\n",
        "assert (B2 @ B).shape   == (n_edges,)\n",
        "\n",
        "\n",
        "# ---- run ----\n",
        "steps = 200\n",
        "t = 0.0\n",
        "# Initialize history outside the loop to accumulate data\n",
        "history = {\n",
        "    't': [],\n",
        "    'energy': [],\n",
        "    'freq': [],\n",
        "    'E_mean': [],\n",
        "    'B_mean': []\n",
        "}\n",
        "\n",
        "for k in range(steps):\n",
        "    # step\n",
        "    E, B = dec_step(E, B, dt)\n",
        "\n",
        "    # logs\n",
        "    U   = energy_total(E, B)\n",
        "    f, Em, Bm = eeg_like_freq(history, E, B, dt)\n",
        "\n",
        "    history['t'].append(t)\n",
        "    history['energy'].append(U)\n",
        "    history['freq'].append(f)\n",
        "    history['E_mean'].append(Em)\n",
        "    history['B_mean'].append(Bm)\n",
        "\n",
        "    if k % 50 == 0:\n",
        "        print(f\"Step {k:3d}  t={t:7.4f}  Energy={U:.3e}  ⟨|E|⟩={Em:.3e}  ⟨|B|⟩={Bm:.3e}  freq*={f:.2e}\")\n",
        "\n",
        "    t += dt\n",
        "\n",
        "# export for later\n",
        "baseline_history = history\n",
        "print(\"\\nDEC stepper complete → `baseline_history` with keys:\", list(baseline_history.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step   0  t= 0.0000  Energy=0.000e+00  ⟨|E|⟩=4.167e-06  ⟨|B|⟩=0.000e+00  freq*=0.00e+00\n",
            "Step  50  t= 0.0000  Energy=0.000e+00  ⟨|E|⟩=4.167e-06  ⟨|B|⟩=0.000e+00  freq*=2.35e+01\n",
            "Step 100  t= 0.0000  Energy=0.000e+00  ⟨|E|⟩=4.167e-06  ⟨|B|⟩=0.000e+00  freq*=2.35e+01\n",
            "Step 150  t= 0.0000  Energy=0.000e+00  ⟨|E|⟩=4.167e-06  ⟨|B|⟩=0.000e+00  freq*=2.35e+01\n",
            "\n",
            "DEC stepper complete → `baseline_history` with keys: ['t', 'energy', 'freq', 'E_mean', 'B_mean']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "898ec073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8cd719-c709-4558-b75a-5b6098bb8fc0"
      },
      "source": [
        "# @title 7. **Markov Diagnostics — Mediation, Entropy, Mixing** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds discrete transition chains from your graph **G** (uses `data['rate']` on edges).\n",
        "# @markdown - Reports: Centroid reliance **R_C**, discrete **ΔE** (early Electric rise), entropy production **Σ** (Schnakenberg), spectral gap, **Kemeny** constant, and mean hitting times to sinks **{0, C}** (auto-pruned if missing).\n",
        "#\n",
        "# @markdown **Counterfactual**\n",
        "# @markdown - Optionally adds forbidden **2→1** (or **6→5** if S2 present) to test loss of mediation and lowered dissipation (EPR).\n",
        "import numpy as np\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def build_P_from_graph(G, node_idx, rate_attr='rate'):\n",
        "    n = len(node_idx)\n",
        "    P = np.zeros((n, n))\n",
        "    # Use node_idx to map original node labels to matrix indices\n",
        "    for u_orig, v_orig, data in G.edges(data=True):\n",
        "        u_str, v_str = str(u_orig), str(v_orig)\n",
        "        if u_str in node_idx and v_str in node_idx:\n",
        "            i, j = node_idx[u_str], node_idx[v_str]\n",
        "            P[i, j] = float(data.get(rate_attr, 0.0))\n",
        "    # row-normalise\n",
        "    for i in range(n):\n",
        "        s = P[i].sum()\n",
        "        if s > 0:\n",
        "            P[i] /= s\n",
        "    return P\n",
        "\n",
        "def roll_states(P, start_idx, steps=20):\n",
        "    n = P.shape[0]\n",
        "    x = np.zeros(n); x[start_idx] = 1.0\n",
        "    traj = [x.copy()]\n",
        "    for _ in range(steps):\n",
        "        x = x @ P\n",
        "        traj.append(x.copy())\n",
        "    return np.stack(traj)\n",
        "\n",
        "def centroid_reliance(states, node_idx, horizon=10):\n",
        "    if 'C' not in node_idx: return np.nan\n",
        "    c = node_idx['C']\n",
        "    T = min(horizon, states.shape[0])\n",
        "    return float(states[:T, c].mean())\n",
        "\n",
        "def electric_acceleration(states, node_idx, t1=1, t2=2):\n",
        "    # Prefer '1' (S1 electric); fall back to '5' (S2 electric) if needed\n",
        "    e_key = '1' if '1' in node_idx else ('5' if '5' in node_idx else None)\n",
        "    if e_key is None: return np.nan\n",
        "    e = node_idx[e_key]\n",
        "    if max(t1, t2) >= states.shape[0]: return np.nan\n",
        "    return float(states[t2, e] - states[t1, e])\n",
        "\n",
        "def absorbing_hitting_time(P, targets, node_idx):\n",
        "    # Make copy with targets absorbing\n",
        "    tgt_idx = [node_idx[t] for t in targets if t in node_idx]\n",
        "    if not tgt_idx:\n",
        "        return np.full(P.shape[0], np.nan)\n",
        "    Q_idx = [i for i in range(P.shape[0]) if i not in tgt_idx]\n",
        "    if not Q_idx:\n",
        "        # If all nodes are targets, hitting time from any node is 0\n",
        "        return np.zeros(P.shape[0])\n",
        "    Q = P[np.ix_(Q_idx, Q_idx)]\n",
        "    I = np.eye(Q.shape[0])\n",
        "    try:\n",
        "        N = np.linalg.inv(I - Q)\n",
        "    except np.linalg.LinAlgError:\n",
        "        # Handle singular matrix (e.g., disconnected graph)\n",
        "        # Using pinv can give a result but interpret with caution\n",
        "        N = np.linalg.pinv(I - Q)\n",
        "    t_mean = N.sum(axis=1)  # expected steps to absorption from each transient\n",
        "    out = np.zeros(P.shape[0])\n",
        "    # Map results back to original full node indexing\n",
        "    # Ensure Q_idx length matches t_mean length\n",
        "    if len(Q_idx) == len(t_mean):\n",
        "        for k_q, i_orig in enumerate(Q_idx):\n",
        "            out[i_orig] = t_mean[k_q]\n",
        "    else:\n",
        "        # This case indicates a potential issue in Q/N calculation\n",
        "        print(\"Warning: Mismatch in transient node indices and hitting time results length.\")\n",
        "        # Fallback: fill with NaNs for safety\n",
        "        out.fill(np.nan)\n",
        "\n",
        "    return out\n",
        "\n",
        "def stationary_dist(P):\n",
        "    n = P.shape[0]\n",
        "    A = P.T - np.eye(n)\n",
        "    A[-1, :] = 1.0  # Add constraint that distribution sums to 1\n",
        "    b = np.zeros(n)\n",
        "    b[-1] = 1.0\n",
        "    try:\n",
        "        # Use pinv for potentially non-ergodic chains\n",
        "        pi = np.linalg.pinv(A) @ b\n",
        "        pi = np.real(pi)\n",
        "        pi = np.maximum(pi, 0)\n",
        "        s = pi.sum()\n",
        "        return (pi / s) if s > 0 else np.ones(n) / n\n",
        "    except np.linalg.LinAlgError:\n",
        "        print(\"Warning: Could not compute stationary distribution.\")\n",
        "        return np.ones(n) / n # Fallback to uniform distribution\n",
        "\n",
        "def entropy_production(P, eps=1e-12):\n",
        "    pi = stationary_dist(P)\n",
        "    n = P.shape[0]\n",
        "    Sigma = 0.0\n",
        "    for i in range(n):\n",
        "        for j in range(n): # Iterate over all pairs for detailed balance check\n",
        "            if i == j: continue\n",
        "            Jij = pi[i] * P[i, j]\n",
        "            Jji = pi[j] * P[j, i]\n",
        "            # Use absolute values for log argument to avoid issues with small negative numbers\n",
        "            # Add eps for numerical stability\n",
        "            if abs(Jij) > eps or abs(Jji) > eps:\n",
        "                Sigma += (Jij - Jji) * np.log((abs(Jij) + eps) / (abs(Jji) + eps))\n",
        "\n",
        "    # For Schnakenberg, sum over *distinct* pairs i != j only once, e.g., j > i.\n",
        "    # The formula is Sigma = 0.5 * Sum_{i!=j} (Jij - Jji) * log(Jij/Jji)\n",
        "    # The previous loop sums each pair twice (i,j) and (j,i), so divide by 2.\n",
        "    return float(Sigma * 0.5) # Divide by 2 for correct Schnakenberg formula\n",
        "\n",
        "def spectral_gap_and_kemeny(P):\n",
        "    n = P.shape[0]\n",
        "    vals = np.linalg.eigvals(P)\n",
        "    vals = np.real_if_close(vals)\n",
        "    # Sort eigenvalues by magnitude in descending order\n",
        "    sorted_indices = np.argsort(np.abs(vals))[::-1]\n",
        "    sorted_vals = vals[sorted_indices]\n",
        "\n",
        "    # Find the eigenvalue closest to 1 (should be 1 for ergodic chains)\n",
        "    idx_one = np.argmin(np.abs(sorted_vals - 1.0))\n",
        "    l1 = sorted_vals[idx_one]\n",
        "\n",
        "    # The second largest eigenvalue magnitude\n",
        "    if len(sorted_vals) > 1:\n",
        "       # Find the second largest eigenvalue by magnitude, excluding the one at 1\n",
        "       # Ensure there are eigenvalues other than 1 before accessing index 0 of the deleted array\n",
        "       non_one_vals = np.delete(sorted_vals, idx_one)\n",
        "       l2 = np.abs(non_one_vals)[0] if non_one_vals.size > 0 else 0.0\n",
        "    else:\n",
        "        l2 = 0.0\n",
        "\n",
        "    gap = float(1.0 - l2)\n",
        "\n",
        "    K = 0.0\n",
        "    # Kemeny constant formula sum_{k=2}^n 1/(1-lambda_k)\n",
        "    # Sum over all eigenvalues except the one at 1\n",
        "    for k in range(n):\n",
        "        # Use a tolerance when comparing to 1 to handle floating point inaccuracies\n",
        "        if abs(sorted_vals[k] - 1.0) < 1e-9:\n",
        "             continue\n",
        "        denom = 1.0 - sorted_vals[k]\n",
        "        if abs(denom) > 1e-9:\n",
        "            K += (1.0 / denom)\n",
        "        # else: if denominator is zero (another eigenvalue at 1), Kemeny is infinite. Handle with large number.\n",
        "        else:\n",
        "            K += 1e9 # Represent infinite Kemeny constant with a large number\n",
        "    return gap, float(K)\n",
        "\n",
        "def pick_start_index(node_idx):\n",
        "    # Prefer magnetic-like start: '2' in S1, else '6' in S2, else first node\n",
        "    for k in ('2', '6'):\n",
        "        if k in node_idx: return node_idx[k]\n",
        "    # Fallback to 'C' if available, otherwise first node\n",
        "    if 'C' in node_idx: return node_idx['C']\n",
        "    return 0 if node_idx else None # Return 0 if node_idx is not empty, otherwise None\n",
        "\n",
        "# ---------- build base chain ----------\n",
        "# Expect G in scope; if node_idx not present, build it.\n",
        "# Use the global G defined in cell 3, which includes all nodes\n",
        "if 'G' not in globals():\n",
        "    raise ValueError(\"Graph G not found. Run Cell 3 (Geometry — Star Tetra) first.\")\n",
        "\n",
        "# Re-build node_idx based on the current G to ensure consistency\n",
        "node_idx = {str(n): i for i, n in enumerate(G.nodes())}\n",
        "ALL_nodes_present = all(n in node_idx for n in ALL) # Check if all original nodes are in the current G\n",
        "\n",
        "if not node_idx:\n",
        "    print(\"Error: No nodes found in graph G.\")\n",
        "    P_norm = None\n",
        "else:\n",
        "    P_norm = build_P_from_graph(G, node_idx)\n",
        "    start_idx = pick_start_index(node_idx)\n",
        "    if start_idx is None:\n",
        "        print(\"Error: Could not determine a valid starting node.\")\n",
        "        traj_norm = None\n",
        "    else:\n",
        "        traj_norm = roll_states(P_norm, start_idx=start_idx, steps=20)\n",
        "\n",
        "    if traj_norm is not None:\n",
        "        Rc_norm   = centroid_reliance(traj_norm, node_idx, horizon=10)\n",
        "        dE_norm   = electric_acceleration(traj_norm, node_idx, t1=1, t2=2)\n",
        "    else:\n",
        "        Rc_norm, dE_norm = np.nan, np.nan\n",
        "\n",
        "    Sigma_norm = entropy_production(P_norm) if P_norm is not None else np.nan\n",
        "    gap_norm, K_norm = spectral_gap_and_kemeny(P_norm) if P_norm is not None else (np.nan, np.nan)\n",
        "    HT_norm = absorbing_hitting_time(P_norm, targets=['0', 'C'], node_idx=node_idx) if P_norm is not None else np.full(len(node_idx), np.nan)\n",
        "\n",
        "# ---------- counterfactual (optional 2→1 or 6→5) ----------\n",
        "add_counterfactual = True # This can be controlled by a form field later\n",
        "w_forbidden = 0.10 # This can be controlled by a form field later\n",
        "\n",
        "def add_forbidden_edge(Gin, node_idx, w):\n",
        "    Gx = Gin.copy()\n",
        "    tag = None\n",
        "    # Check if nodes exist before adding the edge\n",
        "    if '2' in node_idx and '1' in node_idx:\n",
        "        # Check if the edge already exists before adding to avoid errors in some graph types\n",
        "        if not Gx.has_edge('2', '1'):\n",
        "            Gx.add_edge('2', '1', rate=w)\n",
        "            tag = '2→1'\n",
        "        elif Gx['2']['1'].get('rate', 0.0) != w:\n",
        "            # Update rate if edge exists but rate is different\n",
        "            Gx['2']['1']['rate'] = w\n",
        "            tag = f'2→1 (rate updated to {w})'\n",
        "        else:\n",
        "            tag = '2→1 (edge already exists with same rate)'\n",
        "\n",
        "    elif '6' in node_idx and '5' in node_idx:\n",
        "        if not Gx.has_edge('6', '5'):\n",
        "            Gx.add_edge('6', '5', rate=w)\n",
        "            tag = '6→5'\n",
        "        elif Gx['6']['5'].get('rate', 0.0) != w:\n",
        "            Gx['6']['5']['rate'] = w\n",
        "            tag = f'6→5 (rate updated to {w})'\n",
        "        else:\n",
        "            tag = '6→5 (edge already exists with same rate)'\n",
        "\n",
        "    return Gx, tag\n",
        "\n",
        "if add_counterfactual:\n",
        "    # Use the original G to create the counterfactual graph\n",
        "    G_ctf, tag = add_forbidden_edge(G, node_idx, w_forbidden)\n",
        "    if tag is None or P_norm is None: # Also skip if normal P could not be built\n",
        "        print(\"Counterfactual skipped (no suitable nodes for forbidden edge or graph issues).\")\n",
        "        P_ctf = None\n",
        "    else:\n",
        "        # Re-build node_idx for the counterfactual graph to ensure consistency\n",
        "        node_idx_ctf = {str(n): i for i, n in enumerate(G_ctf.nodes())}\n",
        "        P_ctf = build_P_from_graph(G_ctf, node_idx_ctf)\n",
        "else:\n",
        "    P_ctf = None\n",
        "    tag = None\n",
        "\n",
        "# Ensure node_idx_ctf is defined if P_ctf is calculated\n",
        "if P_ctf is not None:\n",
        "    node_idx_ctf = {str(n): i for i, n in enumerate(G_ctf.nodes())}\n",
        "    # Use node_idx_ctf for counterfactual calculations\n",
        "    traj_ctf = roll_states(P_ctf, start_idx=pick_start_index(node_idx_ctf), steps=20)\n",
        "    if traj_ctf is not None:\n",
        "        Rc_ctf   = centroid_reliance(traj_ctf, node_idx_ctf, horizon=10)\n",
        "        dE_ctf   = electric_acceleration(traj_ctf, node_idx_ctf, t1=1, t2=2)\n",
        "    else:\n",
        "        Rc_ctf, dE_ctf = np.nan, np.nan\n",
        "\n",
        "    Sigma_ctf = entropy_production(P_ctf)\n",
        "    gap_ctf, K_ctf = spectral_gap_and_kemeny(P_ctf)\n",
        "    HT_ctf = absorbing_hitting_time(P_ctf, targets=['0', 'C'], node_idx=node_idx_ctf) # Use node_idx_ctf\n",
        "else:\n",
        "    Rc_ctf, dE_ctf, Sigma_ctf, gap_ctf, K_ctf = np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "    HT_ctf = np.full(len(node_idx), np.nan)\n",
        "\n",
        "\n",
        "# ---------- report ----------\n",
        "def fmt(v):\n",
        "    # Handle various NaN/None cases, format floats\n",
        "    if v is None or (isinstance(v, (float, np.float64)) and not np.isfinite(v)):\n",
        "        return \"nan\"\n",
        "    # Check if v is an array and format elements\n",
        "    if isinstance(v, np.ndarray):\n",
        "        return \"[\" + \", \".join(fmt(x) for x in v) + \"]\"\n",
        "    return f\"{v:.3f}\" # Default formatting for floats\n",
        "\n",
        "print(\"=== Markov Metrics ===\")\n",
        "print(f\"Centroid reliance R_C     : normal={fmt(Rc_norm)}\" + (f\" | counterfactual={fmt(Rc_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Electric acceleration ΔE   : normal={fmt(dE_norm)}\" + (f\" | counterfactual={fmt(dE_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Entropy production Σ       : normal={fmt(Sigma_norm)}\" + (f\" | counterfactual={fmt(Sigma_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Spectral gap (1-|λ2|)      : normal={fmt(gap_norm)}\" + (f\" | counterfactual={fmt(gap_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Kemeny constant            : normal={fmt(K_norm)}\" + (f\" | counterfactual={fmt(K_ctf)}\" if P_ctf is not None else \"\"))\n",
        "\n",
        "# Hitting times table\n",
        "def print_ht(label, HT, node_idx_for_ht, G_for_ht):\n",
        "    print(f\"Mean hitting time to {{0,C}} from each node ({label}):\")\n",
        "    # Iterate over the nodes actually present in the graph being reported on\n",
        "    # Sort nodes for consistent output order\n",
        "    sorted_nodes = sorted(G_for_ht.nodes(), key=str) # Simple string sort\n",
        "\n",
        "    # Check if node_idx_for_ht and HT have compatible sizes\n",
        "    if HT is not None and len(node_idx_for_ht) != len(HT):\n",
        "        print(f\"Warning: Node index size ({len(node_idx_for_ht)}) mismatch with HT array size ({len(HT)}) for {label} report.\")\n",
        "\n",
        "    for node_key_orig in sorted_nodes:\n",
        "        k = str(node_key_orig) # Ensure key is string for consistent lookup\n",
        "\n",
        "        # Safely get the node label, falling back to the key if node access fails\n",
        "        try:\n",
        "            node_label = G_for_ht.nodes[node_key_orig].get('label', k)\n",
        "        except KeyError:\n",
        "            # If direct access fails, use the string key as the label\n",
        "            node_label = k\n",
        "            print(f\"Warning: Could not access node attributes for key '{k}' in graph '{label}'. Using key as label.\")\n",
        "\n",
        "\n",
        "        # Get the hitting time value\n",
        "        v = np.nan # Default to NaN\n",
        "\n",
        "        if k in node_idx_for_ht:\n",
        "            idx = node_idx_for_ht[k]\n",
        "            if HT is not None and idx < len(HT): # Check index is within bounds of HT array\n",
        "                v = HT[idx]\n",
        "                 # Handle potential NaN/Inf from hitting time calculation\n",
        "                if not np.isfinite(v):\n",
        "                    v = 0.0 if k in ('0','C') else np.nan\n",
        "            elif k in ('0', 'C'):\n",
        "                 # If target node index is not valid for HT but is a target, report 0\n",
        "                v = 0.0\n",
        "            # else: If node is in node_idx but not a target and index is invalid/HT is None, v remains nan\n",
        "\n",
        "        elif k in ('0', 'C'):\n",
        "             # If target node is not in node_idx but is a target, report 0\n",
        "             v = 0.0\n",
        "        # else: If node exists in G_for_ht but not in node_idx_for_ht (unexpected), v remains nan\n",
        "\n",
        "\n",
        "        print(f\"  {node_label:>22s}: {fmt(v)}\")\n",
        "\n",
        "\n",
        "print_ht(\"normal\", HT_norm, node_idx, G) # Pass node_idx and G for normal report\n",
        "if P_ctf is not None and G_ctf is not None:\n",
        "    print_ht(f\"counterfactual ({tag})\", HT_ctf, node_idx_ctf, G_ctf) # Pass node_idx_ctf and G_ctf\n",
        "\n",
        "# Export for later cells\n",
        "markov_report = {\n",
        "    \"normal\": {\n",
        "        \"Rc\": Rc_norm, \"dE\": dE_norm, \"Sigma\": Sigma_norm,\n",
        "        \"gap\": gap_norm, \"Kemeny\": K_norm, \"HT\": HT_norm\n",
        "    }\n",
        "}\n",
        "if P_ctf is not None and G_ctf is not None:\n",
        "    markov_report[\"counterfactual\"] = {\n",
        "        \"tag\": tag, \"Rc\": Rc_ctf, \"dE\": dE_ctf, \"Sigma\": Sigma_ctf,\n",
        "        \"gap\": gap_ctf, \"Kemeny\": K_ctf, \"HT\": HT_ctf\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Markov Metrics ===\n",
            "Centroid reliance R_C     : normal=0.248 | counterfactual=0.239\n",
            "Electric acceleration ΔE   : normal=0.144 | counterfactual=0.103\n",
            "Entropy production Σ       : normal=17.486 | counterfactual=16.393\n",
            "Spectral gap (1-|λ2|)      : normal=0.352 | counterfactual=0.360\n",
            "Kemeny constant            : normal=11.063 | counterfactual=11.216\n",
            "Mean hitting time to {0,C} from each node (normal):\n",
            "                       0: 0.000\n",
            "                       1: 2.844\n",
            "                       2: 1.444\n",
            "                       3: 1.671\n",
            "                       4: 2.333\n",
            "                       5: 2.556\n",
            "                       6: 1.444\n",
            "                       7: 3.476\n",
            "                       C: 0.000\n",
            "Mean hitting time to {0,C} from each node (counterfactual (2→1)):\n",
            "                       0: 0.000\n",
            "                       1: 3.053\n",
            "                       2: 1.705\n",
            "                       3: 1.671\n",
            "                       4: 2.333\n",
            "                       5: 2.556\n",
            "                       6: 1.444\n",
            "                       7: 3.528\n",
            "                       C: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3529139570.py:154: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return gap, float(K)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ace3d1f9",
        "outputId": "d9d753fc-f5fa-4a78-cfb6-51aaa9f02199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# @title 8. **Energy Balance Audit — Stored Energy vs Power Flows** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines SPD energy forms; compares dU/dt with (input − dissipation); residual should hover near zero.\n",
        "\n",
        "import numpy as np\n",
        "from mpmath import mpf\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Setup (Assumes Cell 6: baseline_history with 'energy', 'E_field', 'B_field') ---\n",
        "# Ensure globals exist from DEC Stepper\n",
        "try:\n",
        "    history = baseline_history\n",
        "    dt = global_dt\n",
        "    ε = global_epsilon\n",
        "    μ = global_mu\n",
        "    σ = global_sigma\n",
        "except NameError:\n",
        "    raise ValueError(\"Run Cell 6 (DEC Stepper) first to set baseline_history, dt, ε, μ, σ\")\n",
        "\n",
        "# Graph (reuse from Cell 6 if available; mock for audit)\n",
        "if 'G' not in globals():\n",
        "    nodes = ['C', '0', '1', '2', '3']\n",
        "    G = nx.DiGraph()\n",
        "    G.add_nodes_from(nodes)\n",
        "    G.add_edges_from([('C','1'), ('1','2'), ('2','C'), ('C','3'), ('3','0'), ('0','C')])\n",
        "\n",
        "# --- Power Flow Calculation ---\n",
        "def compute_power_flows(E, B, G, σ, ε):\n",
        "    \"\"\"Input power (proxy: pump at (C,1)) minus dissipation (Joule: σ |E|^2).\"\"\"\n",
        "    input_power = 0.0\n",
        "    if ('C', '1') in edge_idx:\n",
        "        input_power = abs(E[edge_idx[('C', '1')]]) * 1.0  # Source term (W/m)\n",
        "\n",
        "    # Dissipation: Integrated Joule heating σ |E|^2 over edges\n",
        "    dissipation = σ * np.sum(E**2)\n",
        "\n",
        "    return input_power - dissipation\n",
        "\n",
        "# --- Audit Loop (Over History) ---\n",
        "residuals = []\n",
        "dU_dt_vals = []\n",
        "power_net_vals = []\n",
        "n_steps = len(history['energy'])\n",
        "epsilon = 1e-18 # a small number to avoid division by zero\n",
        "\n",
        "if n_steps > 1:\n",
        "    for i in range(1, n_steps):\n",
        "        # Retrieve E/B from history\n",
        "        E = history['E_field'][i-1]  # Use previous for dU/dt consistency\n",
        "        B = history['B_field'][i-1]\n",
        "\n",
        "        # dU/dt (central finite difference approximation)\n",
        "        U_prev = history['energy'][i-1]\n",
        "        U_curr = history['energy'][i]\n",
        "        dU_dt = (U_curr - U_prev) / (dt + epsilon)\n",
        "\n",
        "        # Power net\n",
        "        power_net = compute_power_flows(E, B, G, σ, ε)\n",
        "\n",
        "        # Residual: |dU/dt - (input - dissipation)|\n",
        "        res = abs(float(dU_dt - power_net))\n",
        "        residuals.append(res)\n",
        "        dU_dt_vals.append(float(dU_dt))\n",
        "        power_net_vals.append(float(power_net))\n",
        "\n",
        "        # Early report\n",
        "        if i > 0 and i % 50 == 0:\n",
        "            print(f\"Step {i}: dU/dt={dU_dt:.2e}, Power Net={power_net:.2e}, Res={res:.2e}\")\n",
        "\n",
        "# --- Summary Stats ---\n",
        "if residuals:\n",
        "    mean_residual = np.mean(residuals)\n",
        "    max_residual = np.max(residuals)\n",
        "    std_residual = np.std(residuals)\n",
        "else:\n",
        "    mean_residual, max_residual, std_residual = np.nan, np.nan, np.nan\n",
        "\n",
        "U_final = history['energy'][-1] if history['energy'] else np.nan\n",
        "\n",
        "print(f\"\\n--- Energy Balance Audit Summary ---\")\n",
        "print(f\"Steps Audited: {len(residuals)}\")\n",
        "print(f\"Mean Residual: {mean_residual:.2e} (should hover ~0)\")\n",
        "print(f\"Max Residual: {max_residual:.2e}\")\n",
        "print(f\"Std Residual: {std_residual:.2e}\")\n",
        "print(f\"Final Stored Energy U: {float(U_final):.2e} J\")\n",
        "print(f\"Audit Status: {'PASS' if not np.isnan(mean_residual) and mean_residual < 1e-10 else 'FAIL'} (residual near zero)\")\n",
        "\n",
        "# --- Plot Residuals vs Time ---\n",
        "if residuals:\n",
        "    steps_plot = np.arange(1, len(residuals) + 1)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    ax1.plot(steps_plot, dU_dt_vals, label='dU/dt', alpha=0.7)\n",
        "    ax1.plot(steps_plot, power_net_vals, label='Input - Dissipation', alpha=0.7)\n",
        "    ax1.set_title('Energy Rate vs Power Flows')\n",
        "    ax1.set_ylabel('Rate (J/s)')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    ax2.plot(steps_plot, residuals)\n",
        "    ax2.set_title('Residual |dU/dt - (Input - Dissipation)|')\n",
        "    ax2.set_ylabel('Residual')\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- Store for Later (e.g., Cell 15 plots) ---\n",
        "global_residuals = residuals\n",
        "global_dU_dt = dU_dt_vals\n",
        "global_power_net = power_net_vals\n",
        "\n",
        "print(\"\\nAudit complete. Residuals stored in global_residuals for visualizations.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Run Cell 6 (DEC Stepper) first to set global_history, dt, ε, μ, σ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1410348486.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_dt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'global_history' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1410348486.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mσ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_sigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run Cell 6 (DEC Stepper) first to set global_history, dt, ε, μ, σ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Graph (reuse from Cell 6 if available; mock for audit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Run Cell 6 (DEC Stepper) first to set global_history, dt, ε, μ, σ"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb2ece69"
      },
      "source": [
        "# @title 9. **Phase Linter — 90° E–M Lag & Anchor to C (S1 & Star)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Kuramoto-style diagnostic layer; targets 90° E–M lag, gentle anchoring to C; reports phase error/spread (no feedback).\n",
        "import numpy as np\n",
        "\n",
        "# Assumes S1, S2, and a node_idx map are in the global scope.\n",
        "# If not, this cell will fail. Ensure geometry cells (2, 3) and an operator cell (e.g., 4) have run.\n",
        "\n",
        "# Define node_list based on detected S1/S2 to be robust\n",
        "node_list = []\n",
        "if 'S1' in globals(): node_list.extend(S1)\n",
        "if 'S2' in globals(): node_list.extend(S2)\n",
        "if 'C' in globals() and 'C' not in node_list: node_list.append('C')\n",
        "\n",
        "# Re-create index map based on the actual node list\n",
        "idx = {k: i for i, k in enumerate(node_list)}\n",
        "n_nodes_phase = len(node_list)\n",
        "\n",
        "# Initialize phase array if not present\n",
        "if 'phi_star' not in globals() or len(phi_star) != n_nodes_phase:\n",
        "    phi_star = np.zeros(n_nodes_phase)\n",
        "\n",
        "def _wrap_pi(x):\n",
        "    return (x + np.pi) % (2 * np.pi) - np.pi\n",
        "\n",
        "# --- Define Couplings and Target Lags ---\n",
        "kap = np.zeros((n_nodes_phase, n_nodes_phase))\n",
        "theta = np.zeros_like(kap)\n",
        "\n",
        "def set_kap(a, b, val):\n",
        "    if a in idx and b in idx:\n",
        "        i, j = idx[a], idx[b]\n",
        "        kap[i, j] = val\n",
        "        kap[j, i] = val\n",
        "\n",
        "def set_theta(a, b, rad):\n",
        "    if a in idx and b in idx:\n",
        "        i, j = idx[a], idx[b]\n",
        "        theta[i, j] = rad\n",
        "        theta[j, i] = -rad # Anti-symmetric for phi_j - phi_i\n",
        "\n",
        "# Baseline weak coupling for all nodes within each shell\n",
        "if 'S1' in globals():\n",
        "    for i, u in enumerate(S1):\n",
        "        for v in S1[i+1:]:\n",
        "            set_kap(u, v, 0.02)\n",
        "if 'S2' in globals():\n",
        "    for i, u in enumerate(S2):\n",
        "        for v in S2[i+1:]:\n",
        "            set_kap(u, v, 0.02)\n",
        "\n",
        "# Stronger E-M couplings within each shell\n",
        "set_kap('1', '2', 0.12)\n",
        "set_kap('5', '6', 0.12)\n",
        "set_theta('1', '2', np.pi / 2)\n",
        "set_theta('5', '6', np.pi / 2)\n",
        "\n",
        "# Work and heat bridge couplings\n",
        "set_kap('3', '6', 0.08); set_theta('3', '6', np.pi / 2) # Work\n",
        "set_kap('7', '4', 0.05); set_theta('7', '4', np.pi)     # Heat\n",
        "set_kap('7', '2', 0.05); set_theta('7', '2', np.pi)     # Heat\n",
        "set_kap('5', '0', 0.05); set_theta('5', '0', np.pi)     # Heat\n",
        "\n",
        "# Anchor to Centroid\n",
        "γC = 0.05\n",
        "\n",
        "def phase_step(phi, dt):\n",
        "    d_phi = np.zeros_like(phi)\n",
        "    # Iterate over all nodes that have a defined index\n",
        "    for u, i in idx.items():\n",
        "        if u == 'C': continue # Centroid is the anchor, does not update\n",
        "\n",
        "        acc = 0.0\n",
        "        # Interaction with other nodes\n",
        "        for v, j in idx.items():\n",
        "            if i == j: continue\n",
        "            acc += kap[i, j] * np.sin(phi[j] - phi[i] - theta[i, j])\n",
        "\n",
        "        # Anchor to Centroid (phi[idx['C']] is assumed to be 0)\n",
        "        if 'C' in idx:\n",
        "            acc -= γC * np.sin(phi[i] - phi[idx['C']])\n",
        "\n",
        "        d_phi[i] = acc\n",
        "\n",
        "    # Update phases (excluding the Centroid)\n",
        "    phi += dt * d_phi\n",
        "    # Keep centroid phase at 0\n",
        "    if 'C' in idx:\n",
        "        phi[idx['C']] = 0\n",
        "\n",
        "    return _wrap_pi(phi)\n",
        "\n",
        "def phase_report(phi):\n",
        "    report_data = {}\n",
        "    def err(a, b, trg):\n",
        "        if a in idx and b in idx:\n",
        "            i, j = idx[a], idx[b]\n",
        "            return float(np.degrees(_wrap_pi((phi[i] - phi[j]) - trg)))\n",
        "        return np.nan\n",
        "\n",
        "    report_data['EM_S1_deg'] = err('1', '2', np.pi/2)\n",
        "    report_data['EM_S2_deg'] = err('5', '6', np.pi/2)\n",
        "    report_data['work_3_6_deg'] = err('3', '6', np.pi/2)\n",
        "    report_data['heat_7_4_deg'] = err('7', '4', np.pi)\n",
        "    report_data['heat_7_2_deg'] = err('7', '2', np.pi)\n",
        "    report_data['heat_5_0_deg'] = err('5', '0', np.pi)\n",
        "    if 'C' in idx:\n",
        "        report_data['C_phase_deg'] = float(np.degrees(phi[idx['C']]))\n",
        "\n",
        "    return report_data\n",
        "\n",
        "# Example of running the phase linter for a few steps to let it settle\n",
        "# This part is for demonstration; the main simulation will call phase_step repeatedly\n",
        "print(\"Phase linter loaded. Running a few settling steps...\")\n",
        "for _ in range(50):\n",
        "    phi_star = phase_step(phi_star, dt=0.1)\n",
        "\n",
        "print(\"Settling complete. Current phase errors:\")\n",
        "print(phase_report(phi_star))\n",
        "\n",
        "# The linter functions (phase_step, phase_report) are now available for other cells."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee8a0508"
      },
      "source": [
        "# @title 10. **Centroid Angle Probe — 109.471221° Mediation Test** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Reweights edges to/from C by the tetrahedral bond angle; measures impact on mediation (R_C), hitting times, EPR.\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from mpmath import mpf\n",
        "\n",
        "# --- Parameters ---\n",
        "# Tetrahedral angle in radians (cos(-1/3))\n",
        "TETRA_ANGLE_RAD = mpf('1.9106332362490186') # Approx 109.47 degrees\n",
        "\n",
        "# --- Helper to apply angle-based weighting ---\n",
        "def weight_graph_by_angle(G_in, angle_rad):\n",
        "    \"\"\"\n",
        "    Creates a deep copy of the graph and re-weights edges to/from the Centroid 'C'\n",
        "    by a factor related to the tetrahedral angle.\n",
        "    \"\"\"\n",
        "    G_weighted = G_in.copy() # Deep copy to avoid modifying the original graph\n",
        "\n",
        "    # Weighting factor (e.g., use the angle directly, or a function of it)\n",
        "    # Using a simple scaling factor for demonstration.\n",
        "    # A more physically-motivated model might use cos(angle) or other geometric factors.\n",
        "    weight_factor = float(angle_rad / np.pi) # Normalize by pi to get a reasonable factor\n",
        "\n",
        "    for u, v, data in G_weighted.edges(data=True):\n",
        "        rate = data.get('rate', mpf('1.0'))\n",
        "        # Apply weighting if the edge involves the Centroid\n",
        "        if u == 'C' or v == 'C':\n",
        "            data['rate'] = rate * weight_factor\n",
        "\n",
        "    return G_weighted\n",
        "\n",
        "# --- Create the weighted graph ---\n",
        "G_angled = weight_graph_by_angle(G, TETRA_ANGLE_RAD)\n",
        "\n",
        "# --- Re-run Markov Diagnostics on the weighted graph ---\n",
        "# We need the Markov analysis helper functions. If they are not in the global scope,\n",
        "# this cell will fail. This assumes Cell 7 has been run.\n",
        "try:\n",
        "    # We need a new node_idx for the potentially modified graph\n",
        "    node_idx_angled = {str(n): i for i, n in enumerate(G_angled.nodes())}\n",
        "\n",
        "    # Build the transition matrix\n",
        "    P_angled = build_P_from_graph(G_angled, node_idx_angled)\n",
        "\n",
        "    # Run diagnostics\n",
        "    start_idx_angled = pick_start_index(node_idx_angled)\n",
        "    if start_idx_angled is not None:\n",
        "        traj_angled = roll_states(P_angled, start_idx_angled, steps=20)\n",
        "        Rc_angled = centroid_reliance(traj_angled, node_idx_angled)\n",
        "        dE_angled = electric_acceleration(traj_angled, node_idx_angled)\n",
        "    else:\n",
        "        Rc_angled, dE_angled = np.nan, np.nan\n",
        "\n",
        "    Sigma_angled = entropy_production(P_angled)\n",
        "    gap_angled, K_angled = spectral_gap_and_kemeny(P_angled)\n",
        "    HT_angled = absorbing_hitting_time(P_angled, targets=['0', 'C'], node_idx=node_idx_angled)\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"Error: A required function from Markov Diagnostics (Cell 7) is missing: {e}\")\n",
        "    print(\"Please run Cell 7 before this one.\")\n",
        "    # Set dummy values to avoid breaking subsequent cells\n",
        "    Rc_angled, dE_angled, Sigma_angled, gap_angled, K_angled, HT_angled = [np.nan] * 6\n",
        "\n",
        "# --- Report Comparison ---\n",
        "print(\"--- Centroid Angle Probe Results ---\")\n",
        "print(f\"Weighting edges to/from 'C' by a factor derived from {float(TETRA_ANGLE_RAD):.3f} rad ({np.degrees(float(TETRA_ANGLE_RAD)):.2f}°).\")\n",
        "print(\"\\n--- Comparison of Markov Metrics (Normal vs. Angle-Weighted) ---\")\n",
        "\n",
        "# A helper to format for comparison\n",
        "def fmt_comp(val_norm, val_angled):\n",
        "    # Check if values are valid numbers before formatting\n",
        "    is_norm_valid = val_norm is not None and np.isfinite(val_norm)\n",
        "    is_angled_valid = val_angled is not None and np.isfinite(val_angled)\n",
        "\n",
        "    norm_str = f\"{val_norm:.3f}\" if is_norm_valid else \"nan\"\n",
        "    angled_str = f\"{val_angled:.3f}\" if is_angled_valid else \"nan\"\n",
        "\n",
        "    delta_str = \"\"\n",
        "    if is_norm_valid and is_angled_valid:\n",
        "        delta = val_angled - val_norm\n",
        "        delta_str = f\"  (Δ: {delta:+.3f})\"\n",
        "\n",
        "    return f\"{norm_str:>8}  ->  {angled_str:>8}{delta_str}\"\n",
        "\n",
        "# Fetch the normal metrics from the 'markov_report' global created in Cell 7\n",
        "try:\n",
        "    normal_metrics = markov_report['normal']\n",
        "    print(f\"Centroid Reliance (R_C): {fmt_comp(normal_metrics.get('Rc'), Rc_angled)}\")\n",
        "    print(f\"Electric Accel (ΔE):   {fmt_comp(normal_metrics.get('dE'), dE_angled)}\")\n",
        "    print(f\"Entropy Prod (Σ):      {fmt_comp(normal_metrics.get('Sigma'), Sigma_angled)}\")\n",
        "    print(f\"Spectral Gap:          {fmt_comp(normal_metrics.get('gap'), gap_angled)}\")\n",
        "    print(f\"Kemeny Constant:       {fmt_comp(normal_metrics.get('Kemeny'), K_angled)}\")\n",
        "\n",
        "    # Compare mean hitting times (excluding targets)\n",
        "    ht_norm = normal_metrics.get('HT', [])\n",
        "    # Filter out NaNs and Infs for a clean mean calculation\n",
        "    ht_norm_mean = np.nanmean([t for t in ht_norm if np.isfinite(t) and t > 0])\n",
        "    ht_angled_mean = np.nanmean([t for t in HT_angled if np.isfinite(t) and t > 0])\n",
        "    print(f\"Mean Hitting Time:     {fmt_comp(ht_norm_mean, ht_angled_mean)}\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"\\n'markov_report' not found. Cannot compare with baseline. Run Cell 7 first.\")\n",
        "except KeyError:\n",
        "    print(\"\\n'normal' key not in 'markov_report'. Cannot compare with baseline.\")\n",
        "\n",
        "# Store results for later use\n",
        "angle_probe_report = {\n",
        "    \"Rc\": Rc_angled,\n",
        "    \"dE\": dE_angled,\n",
        "    \"Sigma\": Sigma_angled,\n",
        "    \"gap\": gap_angled,\n",
        "    \"Kemeny\": K_angled,\n",
        "    \"HT_mean\": ht_angled_mean if 'ht_angled_mean' in locals() else np.nan\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cdd9aab"
      },
      "source": [
        "# @title 11. **Adelic Layer — ℚ_p Utilities & Prime Sweep** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Implements p-adic valuation/norm; builds composite “adelic balance”; sweeps primes (e.g., 2,3,5,7,11,…,137) for robustness."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf480c0d"
      },
      "source": [
        "# @title 12. **Breath Operator — Inhale/Exhale Rhythm** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Alternates phases to favour in-breath (0→C, even→C) and out-breath (C→odd, 1→2 work, 3→0 heat); non-local C stays mediated."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24c6c773"
      },
      "source": [
        "# @title 13. **LENR Cycle Runner — Pump → Coherence → Squeeze → Fusion → Heat** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Executes the breath-driven cycle; integrates adelic scaling at node 3; detects “bursts” on phase-lock; logs heat/entropy.\n",
        "\n",
        "\n",
        "\n",
        "def run_cycle(G_base: nx.DiGraph, steps=400, dt=mpf('0.05'), report_every=80):\n",
        "    global phi_star\n",
        "    energy = {n: mpf('0.5') for n in ALL}\n",
        "    energy['1'] = mpf('1.0'); energy['5'] = mpf('1.0')   # start with E channels primed\n",
        "    bursts = 0; entropy = mpf('0.0'); history = {'heat': [], 'entropy': [], 'bursts': [], 'phase': []}\n",
        "\n",
        "    for k in range(steps):\n",
        "        # Breath modulation (non-destructive per step)\n",
        "        Gk, phase = apply_breath(G_base, k)\n",
        "\n",
        "        # Simple conservative flow pass (rate * energy at source)\n",
        "        for (u,v,data) in Gk.edges(data=True):\n",
        "            flow = energy[u] * data['rate'] * dt\n",
        "            if 'threshold' in data and flow < data['threshold']:\n",
        "                continue\n",
        "            energy[u] -= flow; energy[v] += flow\n",
        "\n",
        "        # p-adic scaling at matter nodes (3,7)\n",
        "        for m in ['3','7']:\n",
        "            e_r = energy[m]\n",
        "            e_p = padic_norm_from_energy(e_r)\n",
        "            e_r, e_p = adelic_balance(e_r, e_p)\n",
        "            energy[m] = e_r * power(e_p, alpha_pad)\n",
        "\n",
        "        # Fusion bursts when C↔matter near phase lock (diagnostic, not physical prediction)\n",
        "        # Use linter's phase (C fixed at 0) — here we proxy lock by small random jitter\n",
        "        jitter = abs(np.sin(phi_star[idx['C']] - phi_star[idx['3']])) + \\\n",
        "                 abs(np.sin(phi_star[idx['C']] - phi_star[idx['7']]))\n",
        "        if jitter < 0.2:\n",
        "            # split burst between shells if available\n",
        "            for m, sink in [('3','0'), ('7','4')]:\n",
        "                burst = energy[m] * mpf('0.3')\n",
        "                energy[m] -= burst\n",
        "                energy[sink] += burst * mpf('0.9')\n",
        "                entropy += burst * mpf('0.1')\n",
        "            bursts += 1\n",
        "\n",
        "        # Phase linter step (non-invasive)\n",
        "        phi_star = phase_step(phi_star, float(dt))\n",
        "\n",
        "        # Log\n",
        "        history['heat'].append(float(energy['0'] + energy['4']))\n",
        "        history['entropy'].append(float(entropy))\n",
        "        history['bursts'].append(int(bursts))\n",
        "        if k % report_every == 0:\n",
        "            print(f\"step {k:4d}  breath={phase:>4s}  bursts={bursts}  heat={history['heat'][-1]:.3f}  \",\n",
        "                  phase_report(phi_star))\n",
        "    return history\n",
        "\n",
        "hist = run_cycle(G, steps=360)\n",
        "print(\"\\nFinal:\", \"bursts=\", hist['bursts'][-1], \"entropy=\", hist['entropy'][-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d84557c"
      },
      "source": [
        "# @title 14. **Stable SI Stepper — Leapfrog + CFL + Joule Heating** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Uses leapfrog with CFL time step; computes SI energy, Joule power, entropy production; reports realistic field magnitudes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e99fb2f1"
      },
      "source": [
        "# @title 15. **Visualisations — Energy, EPR, Spectra, Phases** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Plots energy/frequency time-series, EPR bars (normal vs counterfactual vs low-T), residuals, phase diagnostics."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c51c160b"
      },
      "source": [
        "# @title 16. **Red-Team Nulls & Ablations — Try to Break It** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Degree-preserving rewires; geometry swap (octahedron); no-adelic baseline; breath disabled; 2→1 during exhale only."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e18fb48c"
      },
      "source": [
        "# @title 17. **Preregistered Sweep — Seeds × Parameters × Outcomes** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Freezes thresholds; runs multiple seeds; aggregates pass/fail for quantised heat + mediation/EPR signatures."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d12d1f2"
      },
      "source": [
        "# @title 18. **Centroid Work vs Heat Ledger — Path Classification** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Labels forward “work-like” shortcuts (e.g., 0→1, 2→3) and backward “heat-like” fallbacks (1→0, 3→2); tallies contributions."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42f20ef7"
      },
      "source": [
        "# @title 19. **Star-Tetra Runner — Cross-Tetra Breath with Cubic Bridges** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Executes your S1↔S2 pathing rules; measures mediation across C, cross-domain hitting times, and burst propagation."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31527ebe"
      },
      "source": [
        "# @title 20. **Centroid Locality Tests — Algorithmic Induction Around C** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Drives edge-based current scenarios near C; probes iterative/inductive dynamics; quantifies sensitivity to 109.47° bias."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c84fd14f"
      },
      "source": [
        "# @title 21. **Save & Export — Results, Seeds, Config** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Stores metrics, plots, chosen primes, geometry flags, and RNG seeds for reproducibility; optional JSON/CSV export."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6e4b814"
      },
      "source": [
        "# @title 22. **Appendix — Utilities & Helpers** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this contains**\n",
        "\n",
        "# @markdown - Small helpers (index maps, safe mat-ops, plotting styles), validation checks, and pretty printers."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}