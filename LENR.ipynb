{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBC8JwRuNMELtNReoFJxQy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berigny/AI-Entrainment-Protocol/blob/main/LENR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Low Energy Nuclear (LENR) Cycles Model\n",
        "This notebook tests whether a minimal, topology-first model can simulate and falsify a low-energy nuclear reaction (LENR) cycle driven by breath-like EM coherence. Using Discrete Exterior Calculus (DEC) on a star-tetrahedral complex with a shared centroid, we evolve fields, enforce first-law energy accounting, monitor entropy production and phase relations, and—optionally—add an adelic (ℝ × ℚ_p) layer to represent hierarchical memory at the fusion node. If quantised heat bursts do not emerge with lawful topology, pre-burst EM signatures, rising EPR, and correct energy balance, the hypothesis is weakened. If they do, we proceed to richer modelling and lab validation. The prize is significant: a path to low-cost, high-yield, sustainable energy in an energy-hungry world.\n",
        "\n",
        "## Falsification criteria\n",
        "\n",
        "We consider the LENR cycle unsupported if any lawful configuration fails to produce:\n",
        "(i) pre-burst EM coherence with ~90° E–M phase and centroid mediation,\n",
        "(ii) quantised heat steps at the sink,\n",
        "(iii) a non-negative EPR that rises prior to bursts, and\n",
        "(iv) first-law integrity (residual ≈ 0).\n",
        "Controls must behave as expected: illegal shortcuts reduce irreversibility or break energy accounting; removing C→3 or 1→2 kills bursts; random primes revert to baseline.\n",
        "\n",
        "## Notebook Overview & Research Aim\n",
        "### Goal\n",
        "- Simulate and *attempt to falsify* LENR-like cycles on a tetrahedral (and star-tetrahedral) topology.\n",
        "- If not falsified, motivate deeper modelling and lab tests for low-cost, high-yield, sustainable energy.\n",
        "### Key Ideas\n",
        "- DEC on simplicial complexes; mediation via centroid **C**; breath-driven, asymmetric flows; adelic (ℝ×ℚ_p) layer."
      ],
      "metadata": {
        "id": "qKR1ogm8760g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3c07b46"
      },
      "source": [
        "# @title 1. **Imports & Global Config** { display-mode: \"form\" }\n",
        "# @markdown **What this sets**\n",
        "# @markdown - Imports, numeric precision/warnings, plotting defaults, reproducibility seeds.\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from mpmath import mpf, power\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geometry (simplices, orientations, dual volumes)"
      ],
      "metadata": {
        "id": "rWI-4DAHO92i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb7ea8f2",
        "outputId": "85f3a320-68e7-44e0-831d-50e34294dd2b"
      },
      "source": [
        "# @title 2. **Geometry — S1 (Single Tetra) and Star (S1+S2) with Cubic Bridges** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds the base directed graph `G` for one tetrahedron (S1) or the full star (S1+S2) if `USE_STAR=True`.\n",
        "# @markdown - Defines vertices `{0,1,2,3,C}` for S1 and adds `{4,5,6,7}` for S2 in star mode.\n",
        "# @markdown - Encodes work-like edges, heat-dump edges, and mediation paths through centroid `C`.\n",
        "# @markdown - Adds optional cross-tetra “cubic” bridges for coherent work transfer and heat redistribution.\n",
        "# @markdown - Inserts self-loops for stability/linger dynamics.\n",
        "# @markdown - Labels canonical edge sets (`work_edges`, `heat_edges`) inside `G.graph` for later diagnostics.\n",
        "\n",
        "# === Geometry — S1 (tetra) and optional Star (S1+S2) with cubic bridges ===\n",
        "# Inputs: USE_STAR (bool) defined in C01_config; default to False if missing\n",
        "try:\n",
        "    USE_STAR\n",
        "except NameError:\n",
        "    USE_STAR = False\n",
        "\n",
        "import networkx as nx\n",
        "from mpmath import mpf\n",
        "\n",
        "# Nodes\n",
        "S1 = ['0','1','2','3']      # sinks even / branches odd\n",
        "S2 = ['4','5','6','7']\n",
        "ALL = (S1 + ['C']) if not USE_STAR else (S1 + S2 + ['C'])\n",
        "\n",
        "# Helper\n",
        "r = lambda x: mpf(str(x))\n",
        "\n",
        "# Core single-shell flows (work/heat + mediation) on S1\n",
        "core_edges_S1 = [\n",
        "    ('C','1', {'rate': r(0.5)}),     # pump\n",
        "    ('1','2', {'rate': r(0.8)}),     # E→M (work)\n",
        "    ('2','C', {'rate': r(0.9)}),     # return to mediator\n",
        "    ('C','3', {'rate': r(0.7)}),     # squeeze/fusion path\n",
        "    ('3','0', {'rate': r(1.0)}),     # heat dump\n",
        "    ('0','C', {'rate': r(0.3)}),     # reset\n",
        "]\n",
        "\n",
        "# Optional second shell (S2)\n",
        "core_edges_S2 = [\n",
        "    ('C','5', {'rate': r(0.5)}),\n",
        "    ('5','6', {'rate': r(0.8)}),\n",
        "    ('6','C', {'rate': r(0.9)}),\n",
        "    ('C','7', {'rate': r(0.7)}),\n",
        "    ('7','4', {'rate': r(1.0)}),\n",
        "    ('4','C', {'rate': r(0.3)}),\n",
        "]\n",
        "\n",
        "# Cross-shell bridges (only used if USE_STAR)\n",
        "cross_edges = [\n",
        "    ('3','6', {'rate': r(0.35)}),  # work bridge S1→S2\n",
        "    ('7','2', {'rate': r(0.25)}),  # heat-biased return to S1 magnetic\n",
        "    ('5','0', {'rate': r(0.20)}),  # heat assist into S1 sink\n",
        "    ('1','6', {'rate': r(0.20)}),  # optional E→M assist across shells\n",
        "]\n",
        "\n",
        "# Build graph once\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(ALL)\n",
        "G.add_edges_from(core_edges_S1)\n",
        "\n",
        "if USE_STAR:\n",
        "    G.add_edges_from(core_edges_S2 + cross_edges)\n",
        "    self_loop_nodes = S1 + S2\n",
        "else:\n",
        "    self_loop_nodes = S1\n",
        "\n",
        "# Self-loops (linger/stability)\n",
        "G.add_edges_from([(n, n, {'rate': r(0.4)}) for n in self_loop_nodes])\n",
        "\n",
        "# Label canonical edge sets (for later coupling/diagnostics)\n",
        "work_edges = {('1','2'), ('3','6')} if USE_STAR else {('1','2')}\n",
        "heat_edges = {('3','0')} | ({('7','2'), ('5','0')} if USE_STAR else set())\n",
        "\n",
        "G.graph['work_edges'] = work_edges\n",
        "G.graph['heat_edges'] = heat_edges\n",
        "\n",
        "print(f\"Graph ready. USE_STAR={USE_STAR} |V|={G.number_of_nodes()} |E|={G.number_of_edges()}\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph ready. USE_STAR=False |V|=5 |E|=10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. **Breath Operator — Inhale/Exhale Rhythm** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines a transformer `apply_breath(G_base, step)` that scales edge rates\n",
        "# @markdown   according to the breath cycle.\n",
        "# @markdown - Even steps = inhale: favour flows into sinks (`0,4`) and mediator `C`.\n",
        "# @markdown - Odd steps = exhale: favour flows out of `C` toward pump branches (`1,3,5,7`).\n",
        "# @markdown - Parameters `inhale_gain` and `exhale_gain` control modulation strength.\n",
        "# @markdown - Returns a fresh graph copy and the current phase label (`\"in\"` / `\"out\"`).\n",
        "\n",
        "\n",
        "def apply_breath(G_base, step, inhale_gain=1.15, exhale_gain=1.10,\n",
        "                 sinks=('0','4'), sources=('C',), pumps=('1','3','5','7')):\n",
        "    \"\"\"Scale edge rates by breath phase. Even steps = inhale (toward sinks/C), odd = exhale (from C→pumps).\"\"\"\n",
        "    phase = 'in' if (step % 2) == 0 else 'out'\n",
        "    G = G_base.copy()\n",
        "    for u, v, d in G.edges(data=True):\n",
        "        r = float(d.get('rate', 0.0))\n",
        "        if phase == 'in' and (v in sinks or v in sources):\n",
        "            d['rate'] = r * inhale_gain\n",
        "        elif phase == 'out' and (u in sources and v in pumps):\n",
        "            d['rate'] = r * exhale_gain\n",
        "    return G, phase\n"
      ],
      "metadata": {
        "id": "lVELWkflMr7b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEC operators (∂, Hodge stars, audits)"
      ],
      "metadata": {
        "id": "geaJ8kVwPFBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. **DEC Backbone — ∂ Operators & Diagonal Hodge Stars (with Audits)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds the simplicial backbone (independent of the Markov graph): vertices, oriented edges, faces.\n",
        "# @markdown - Constructs boundary maps: **B₁** (nodes→edges) and **B₂** (edges→faces).\n",
        "# @markdown - Defines **diagonal SPD Hodge stars** `Star1` (edges×edges) and `Star2` (faces×faces).\n",
        "# @markdown - Runs audits: `||B₁·B₂||∞ ≈ 0`, ranks of B₁/B₂, SPD minima; exposes `energy_field(E,B)`.\n",
        "# @markdown **Notes**\n",
        "# @markdown - No rectangular/“incidence-averaged” Hodge stand-ins here. Those are deprecated.\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# ---- 1) Vertex & face set (S1 always; S2 included if USE_STAR=True) ----\n",
        "try:\n",
        "    USE_STAR\n",
        "except NameError:\n",
        "    USE_STAR = False\n",
        "\n",
        "# Vertices: S1 plus shared centroid C; extend with S2 in star mode\n",
        "V = ['0','1','2','3','C'] + (['4','5','6','7'] if USE_STAR else [])\n",
        "\n",
        "# Faces:\n",
        "# - S1 outer + centroid faces\n",
        "F_S1_outer = [('0','1','2'), ('0','1','3'), ('0','2','3'), ('1','2','3')]\n",
        "F_S1_cent  = [('0','1','C'), ('0','2','C'), ('0','3','C'), ('1','2','C'), ('1','3','C'), ('2','3','C')]\n",
        "\n",
        "# - Optional S2 outer + centroid faces (only if USE_STAR)\n",
        "F_S2_outer = [('4','5','6'), ('4','5','7'), ('4','6','7'), ('5','6','7')]\n",
        "F_S2_cent  = [('4','5','C'), ('4','6','C'), ('4','7','C'), ('5','6','C'), ('5','7','C'), ('6','7','C')]\n",
        "\n",
        "F = F_S1_outer + F_S1_cent + (F_S2_outer + F_S2_cent if USE_STAR else [])\n",
        "\n",
        "# ---- 2) Oriented edges derived from faces (backbone edges only) ----\n",
        "edges_backbone = sorted({(a,b) for (a,b,c) in F for (a,b) in ((a,b),(b,c),(c,a))})\n",
        "\n",
        "# Index maps\n",
        "node_id = {v:i for i,v in enumerate(V)}\n",
        "edge_id = {e:i for i,e in enumerate(edges_backbone)}\n",
        "face_id = {f:i for i,f in enumerate(F)}\n",
        "\n",
        "# ---- 3) Boundary maps ----\n",
        "# B1: nodes×edges (∂1)\n",
        "B1 = np.zeros((len(V), len(edges_backbone)), dtype=float)\n",
        "for (u,v), ei in edge_id.items():\n",
        "    B1[node_id[u], ei] = -1.0\n",
        "    B1[node_id[v], ei] = +1.0\n",
        "B1 = csr_matrix(B1)\n",
        "\n",
        "# B2: edges×faces (∂2) with oriented incidence\n",
        "B2 = np.zeros((len(edges_backbone), len(F)), dtype=float)\n",
        "for fj,(v0,v1,v2) in enumerate(F):\n",
        "    for (a,b) in ((v0,v1),(v1,v2),(v2,v0)):\n",
        "        sign = +1.0\n",
        "        e = (a,b)\n",
        "        if e not in edge_id:\n",
        "            e = (b,a); sign = -1.0\n",
        "        B2[edge_id[e], fj] += sign\n",
        "B2 = csr_matrix(B2)\n",
        "\n",
        "# ---- 4) Diagonal Hodge stars (regularised circumcentric stand-ins) ----\n",
        "# Use a unit geometric scale here; SI scaling lives in the optional calibration cell.\n",
        "L = 1.0  # assumed primal edge length scale for now\n",
        "nE, nF = len(edges_backbone), len(F)\n",
        "\n",
        "# primal measures\n",
        "len_e  = np.full(nE, L, dtype=float)                       # |e|\n",
        "area_f = np.full(nF, (np.sqrt(3)/4.0)*L*L, dtype=float)    # |f| (equilateral)\n",
        "\n",
        "# crude-but-coherent dual measures for a regular/star tetra\n",
        "dual_e = np.full(nE, (L*L)/4.0, dtype=float)               # |*e|\n",
        "dual_f = np.full(nF, (L/3.0), dtype=float)                 # |*f|\n",
        "\n",
        "star1_diag = dual_e / len_e          # edges→edges\n",
        "star2_diag = dual_f / area_f         # faces→faces\n",
        "\n",
        "Star1 = np.diag(star1_diag)          # SPD\n",
        "Star2 = np.diag(star2_diag)\n",
        "\n",
        "def star1(x): return Star1 @ x\n",
        "def star2(x): return Star2 @ x\n",
        "\n",
        "# ---- 5) Audits ----\n",
        "D1 = B1.toarray(); D2 = B2.toarray()\n",
        "B1B2 = D1 @ D2\n",
        "inf_norm = float(np.max(np.abs(B1B2))) if B1B2.size else 0.0\n",
        "rank_D1 = int(np.linalg.matrix_rank(D1))\n",
        "rank_D2 = int(np.linalg.matrix_rank(D2))\n",
        "is_spd_star1 = bool(np.min(star1_diag) > 0)\n",
        "is_spd_star2 = bool(np.min(star2_diag) > 0)\n",
        "\n",
        "print(f\"[dims] |V|={len(V)} |E|={nE} |F|={nF}\")\n",
        "print(f\"||B1·B2||_∞ = {inf_norm:.3e} (expect 0)\")\n",
        "print(f\"rank(B1)={rank_D1}, rank(B2)={rank_D2}\")\n",
        "print(f\"Star1 SPD? {is_spd_star1}   Star2 SPD? {is_spd_star2}\")\n",
        "print(f\"star1_diag min/max = {star1_diag.min():.3e} / {star1_diag.max():.3e}\")\n",
        "print(f\"star2_diag min/max = {star2_diag.min():.3e} / {star2_diag.max():.3e}\")\n",
        "\n",
        "# ---- 6) Energy helper ----\n",
        "def energy_field(E, B):\n",
        "    \"\"\"Discrete EM energy: 0.5*(E⋅(⋆1 E) + B⋅(⋆2 B)).\"\"\"\n",
        "    return 0.5*(E @ (Star1 @ E) + B @ (Star2 @ B))\n"
      ],
      "metadata": {
        "id": "b9aJlYAHbv8B",
        "outputId": "0c8a958e-7113-45f5-e63b-75b265237dad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dims] |V|=5 |E|=15 |F|=10\n",
            "||B1·B2||_∞ = 0.000e+00 (expect 0)\n",
            "rank(B1)=4, rank(B2)=10\n",
            "Star1 SPD? True   Star2 SPD? True\n",
            "star1_diag min/max = 2.500e-01 / 2.500e-01\n",
            "star2_diag min/max = 7.698e-01 / 7.698e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. **(Optional) SI Calibration — Scales, Materials & CFL Guard** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Sets dimensionful scales (edge length `L_m`), material guesses (ε_r, μ_r), and a conservative CFL-like `global_dt`.\n",
        "# @markdown - Leaves DEC stars (`Star1/Star2`) untouched; use this only for reporting or SI-coupled experiments.\n",
        "\n",
        "import numpy as np\n",
        "from mpmath import mpf\n",
        "\n",
        "# ---- 1) Geometry scale (metres) ----\n",
        "L_m = mpf('1e-9')  # 1 nm representative edge length (tune as needed)\n",
        "\n",
        "# ---- 2) Materials (metal-like defaults) ----\n",
        "eps0 = mpf('8.854187817e-12')     # F/m\n",
        "mu0  = mpf('1.25663706212e-6')    # H/m\n",
        "eps_r = mpf('20')                  # relative permittivity (order 10–100)\n",
        "mu_r  = mpf('1')                   # non-magnetic\n",
        "sigma = mpf('1e6')                 # S/m (ballpark for metals; tune/disable if not using ohmic loss)\n",
        "\n",
        "eps = eps_r * eps0\n",
        "mu  = mu_r  * mu0\n",
        "c_si = 1.0 / float(np.sqrt(eps * mu))   # wave speed in medium\n",
        "\n",
        "# ---- 3) CFL-like time step guard (from Markov rates if available) ----\n",
        "def cfl_dt_from_rates(graph, safety=0.1):\n",
        "    if graph is None:\n",
        "        return None\n",
        "    try:\n",
        "        mr = max((float(d.get('rate', 0.0)) for _,_,d in graph.edges(data=True)), default=0.0)\n",
        "    except Exception:\n",
        "        mr = 0.0\n",
        "    if mr <= 0.0:\n",
        "        return None\n",
        "    return safety / mr\n",
        "\n",
        "try:\n",
        "    G  # if your Markov graph exists, we can use it\n",
        "    dt_rate = cfl_dt_from_rates(G, safety=0.1)\n",
        "except NameError:\n",
        "    dt_rate = None\n",
        "\n",
        "# geometric CFL (Yee-like): dt ≤ 0.5 * L / c\n",
        "dt_geom = 0.5 * float(L_m) / float(c_si)\n",
        "\n",
        "# choose most conservative if both exist\n",
        "candidates = [x for x in (dt_rate, dt_geom) if x is not None]\n",
        "global_dt = min(candidates) if candidates else dt_geom\n",
        "\n",
        "# ---- 4) Export SI globals ----\n",
        "global_epsilon = float(eps)\n",
        "global_mu      = float(mu)\n",
        "global_sigma   = float(sigma)\n",
        "global_c       = float(c_si)\n",
        "\n",
        "print(f\"L = {float(L_m):.3e} m   eps_r={float(eps_r)}   mu_r={float(mu_r)}   sigma={float(sigma):.2e} S/m\")\n",
        "print(f\"c (medium) = {global_c:.3e} m/s\")\n",
        "print(f\"dt_geom = {dt_geom:.3e} s   dt_rate = {dt_rate if dt_rate is not None else 'n/a'}\")\n",
        "print(f\"=> global_dt = {global_dt:.3e} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1pqe2HQ_n5m",
        "outputId": "61aabfaf-dc2f-49a0-bc99-97e4e8f9a56d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L = 1.000e-09 m   eps_r=20.0   mu_r=1.0   sigma=1.00e+06 S/m\n",
            "c (medium) = 6.704e+07 m/s\n",
            "dt_geom = 7.459e-18 s   dt_rate = 0.1\n",
            "=> global_dt = 7.459e-18 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time evolution (Maxwell-like DEC loop + optional Markov flux layer)"
      ],
      "metadata": {
        "id": "-_sS3jpKPOO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. **DEC Backbone — ∂ Operators & Diagonal Hodge Stars (with Audits)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds the simplicial backbone (independent of the Markov graph): vertices, oriented edges, faces.\n",
        "# @markdown - Constructs boundary maps: **B₁** (nodes→edges) and **B₂** (edges→faces).\n",
        "# @markdown - Defines **diagonal SPD Hodge stars** `Star1` (edges×edges) and `Star2` (faces×faces).\n",
        "# @markdown - Runs audits: `||B₁·B₂||∞ ≈ 0`, ranks of B₁/B₂, SPD minima; exposes `energy_field(E,B)`.\n",
        "# @markdown **Notes**\n",
        "# @markdown - No rectangular/“incidence-averaged” Hodge stand-ins here. Those are deprecated.\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# ---- 1) Vertex & face set (S1 always; S2 included if USE_STAR=True) ----\n",
        "try:\n",
        "    USE_STAR\n",
        "except NameError:\n",
        "    USE_STAR = False\n",
        "\n",
        "# Vertices: S1 plus shared centroid C; extend with S2 in star mode\n",
        "V = ['0','1','2','3','C'] + (['4','5','6','7'] if USE_STAR else [])\n",
        "\n",
        "# Faces:\n",
        "# - S1 outer + centroid faces\n",
        "F_S1_outer = [('0','1','2'), ('0','1','3'), ('0','2','3'), ('1','2','3')]\n",
        "F_S1_cent  = [('0','1','C'), ('0','2','C'), ('0','3','C'), ('1','2','C'), ('1','3','C'), ('2','3','C')]\n",
        "\n",
        "# - Optional S2 outer + centroid faces (only if USE_STAR)\n",
        "F_S2_outer = [('4','5','6'), ('4','5','7'), ('4','6','7'), ('5','6','7')]\n",
        "F_S2_cent  = [('4','5','C'), ('4','6','C'), ('4','7','C'), ('5','6','C'), ('5','7','C'), ('6','7','C')]\n",
        "\n",
        "F = F_S1_outer + F_S1_cent + (F_S2_outer + F_S2_cent if USE_STAR else [])\n",
        "\n",
        "# ---- 2) Oriented edges derived from faces (backbone edges only) ----\n",
        "edges_backbone = sorted({(a,b) for (a,b,c) in F for (a,b) in ((a,b),(b,c),(c,a))})\n",
        "\n",
        "# Index maps\n",
        "node_id = {v:i for i,v in enumerate(V)}\n",
        "edge_id = {e:i for i,e in enumerate(edges_backbone)}\n",
        "face_id = {f:i for i,f in enumerate(F)}\n",
        "\n",
        "# ---- 3) Boundary maps ----\n",
        "# B1: nodes×edges (∂1)\n",
        "B1 = np.zeros((len(V), len(edges_backbone)), dtype=float)\n",
        "for (u,v), ei in edge_id.items():\n",
        "    B1[node_id[u], ei] = -1.0\n",
        "    B1[node_id[v], ei] = +1.0\n",
        "B1 = csr_matrix(B1)\n",
        "\n",
        "# B2: edges×faces (∂2) with oriented incidence\n",
        "B2 = np.zeros((len(edges_backbone), len(F)), dtype=float)\n",
        "for fj,(v0,v1,v2) in enumerate(F):\n",
        "    for (a,b) in ((v0,v1),(v1,v2),(v2,v0)):\n",
        "        sign = +1.0\n",
        "        e = (a,b)\n",
        "        if e not in edge_id:\n",
        "            e = (b,a); sign = -1.0\n",
        "        B2[edge_id[e], fj] += sign\n",
        "B2 = csr_matrix(B2)\n",
        "\n",
        "# ---- 4) Diagonal Hodge stars (regularised circumcentric stand-ins) ----\n",
        "# Use a unit geometric scale here; SI scaling lives in the optional calibration cell.\n",
        "L = 1.0  # assumed primal edge length scale for now\n",
        "nE, nF = len(edges_backbone), len(F)\n",
        "\n",
        "# primal measures\n",
        "len_e  = np.full(nE, L, dtype=float)                       # |e|\n",
        "area_f = np.full(nF, (np.sqrt(3)/4.0)*L*L, dtype=float)    # |f| (equilateral)\n",
        "\n",
        "# crude-but-coherent dual measures for a regular/star tetra\n",
        "dual_e = np.full(nE, (L*L)/4.0, dtype=float)               # |*e|\n",
        "dual_f = np.full(nF, (L/3.0), dtype=float)                 # |*f|\n",
        "\n",
        "star1_diag = dual_e / len_e          # edges→edges\n",
        "star2_diag = dual_f / area_f         # faces→faces\n",
        "\n",
        "Star1 = np.diag(star1_diag)          # SPD\n",
        "Star2 = np.diag(star2_diag)\n",
        "\n",
        "def star1(x): return Star1 @ x\n",
        "def star2(x): return Star2 @ x\n",
        "\n",
        "# ---- 5) Audits ----\n",
        "D1 = B1.toarray(); D2 = B2.toarray()\n",
        "B1B2 = D1 @ D2\n",
        "inf_norm = float(np.max(np.abs(B1B2))) if B1B2.size else 0.0\n",
        "rank_D1 = int(np.linalg.matrix_rank(D1))\n",
        "rank_D2 = int(np.linalg.matrix_rank(D2))\n",
        "is_spd_star1 = bool(np.min(star1_diag) > 0)\n",
        "is_spd_star2 = bool(np.min(star2_diag) > 0)\n",
        "\n",
        "print(f\"[dims] |V|={len(V)} |E|={nE} |F|={nF}\")\n",
        "print(f\"||B1·B2||_∞ = {inf_norm:.3e} (expect 0)\")\n",
        "print(f\"rank(B1)={rank_D1}, rank(B2)={rank_D2}\")\n",
        "print(f\"Star1 SPD? {is_spd_star1}   Star2 SPD? {is_spd_star2}\")\n",
        "print(f\"star1_diag min/max = {star1_diag.min():.3e} / {star1_diag.max():.3e}\")\n",
        "print(f\"star2_diag min/max = {star2_diag.min():.3e} / {star2_diag.max():.3e}\")\n",
        "\n",
        "# ---- 6) Energy helper ----\n",
        "def energy_field(E, B):\n",
        "    \"\"\"Discrete EM energy: 0.5*(E⋅(⋆1 E) + B⋅(⋆2 B)).\"\"\"\n",
        "    return 0.5*(E @ (Star1 @ E) + B @ (Star2 @ B))\n"
      ],
      "metadata": {
        "id": "3-57UGmhcWZz",
        "outputId": "bda70b5d-18ed-455c-f6f0-4c58dc5a4735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dims] |V|=5 |E|=15 |F|=10\n",
            "||B1·B2||_∞ = 0.000e+00 (expect 0)\n",
            "rank(B1)=4, rank(B2)=10\n",
            "Star1 SPD? True   Star2 SPD? True\n",
            "star1_diag min/max = 2.500e-01 / 2.500e-01\n",
            "star2_diag min/max = 7.698e-01 / 7.698e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "898ec073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56491249-54ab-467e-d4f5-962172482a3b"
      },
      "source": [
        "# @title 7. **Markov Diagnostics — Mediation, Entropy, Mixing** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds discrete transition chains from your graph **G** (uses `data['rate']` on edges).\n",
        "# @markdown - Reports: Centroid reliance **R_C**, discrete **ΔE** (early Electric rise), entropy production **Σ** (Schnakenberg), spectral gap, **Kemeny** constant, and mean hitting times to sinks **{0, C}** (auto-pruned if missing).\n",
        "#\n",
        "# @markdown **Counterfactual**\n",
        "# @markdown - Optionally adds forbidden **2→1** (or **6→5** if S2 present) to test loss of mediation and lowered dissipation (EPR).\n",
        "import numpy as np\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def build_P_from_graph(G, node_idx, rate_attr='rate'):\n",
        "    n = len(node_idx)\n",
        "    P = np.zeros((n, n))\n",
        "    # Use node_idx to map original node labels to matrix indices\n",
        "    for u_orig, v_orig, data in G.edges(data=True):\n",
        "        u_str, v_str = str(u_orig), str(v_orig)\n",
        "        if u_str in node_idx and v_str in node_idx:\n",
        "            i, j = node_idx[u_str], node_idx[v_str]\n",
        "            P[i, j] = float(data.get(rate_attr, 0.0))\n",
        "    # row-normalise\n",
        "    for i in range(n):\n",
        "        s = P[i].sum()\n",
        "        if s > 0:\n",
        "            P[i] /= s\n",
        "    return P\n",
        "\n",
        "def roll_states(P, start_idx, steps=20):\n",
        "    n = P.shape[0]\n",
        "    x = np.zeros(n); x[start_idx] = 1.0\n",
        "    traj = [x.copy()]\n",
        "    for _ in range(steps):\n",
        "        x = x @ P\n",
        "        traj.append(x.copy())\n",
        "    return np.stack(traj)\n",
        "\n",
        "def centroid_reliance(states, node_idx, horizon=10):\n",
        "    if 'C' not in node_idx: return np.nan\n",
        "    c = node_idx['C']\n",
        "    T = min(horizon, states.shape[0])\n",
        "    return float(states[:T, c].mean())\n",
        "\n",
        "def electric_acceleration(states, node_idx, t1=1, t2=2):\n",
        "    # Prefer '1' (S1 electric); fall back to '5' (S2 electric) if needed\n",
        "    e_key = '1' if '1' in node_idx else ('5' if '5' in node_idx else None)\n",
        "    if e_key is None: return np.nan\n",
        "    e = node_idx[e_key]\n",
        "    if max(t1, t2) >= states.shape[0]: return np.nan\n",
        "    return float(states[t2, e] - states[t1, e])\n",
        "\n",
        "def absorbing_hitting_time(P, targets, node_idx):\n",
        "    # Make copy with targets absorbing\n",
        "    tgt_idx = [node_idx[t] for t in targets if t in node_idx]\n",
        "    if not tgt_idx:\n",
        "        return np.full(P.shape[0], np.nan)\n",
        "    Q_idx = [i for i in range(P.shape[0]) if i not in tgt_idx]\n",
        "    if not Q_idx:\n",
        "        # If all nodes are targets, hitting time from any node is 0\n",
        "        return np.zeros(P.shape[0])\n",
        "    Q = P[np.ix_(Q_idx, Q_idx)]\n",
        "    I = np.eye(Q.shape[0])\n",
        "    try:\n",
        "        N = np.linalg.inv(I - Q)\n",
        "    except np.linalg.LinAlgError:\n",
        "        # Handle singular matrix (e.g., disconnected graph)\n",
        "        # Using pinv can give a result but interpret with caution\n",
        "        N = np.linalg.pinv(I - Q)\n",
        "    t_mean = N.sum(axis=1)  # expected steps to absorption from each transient\n",
        "    out = np.zeros(P.shape[0])\n",
        "    # Map results back to original full node indexing\n",
        "    # Ensure Q_idx length matches t_mean length\n",
        "    if len(Q_idx) == len(t_mean):\n",
        "        for k_q, i_orig in enumerate(Q_idx):\n",
        "            out[i_orig] = t_mean[k_q]\n",
        "    else:\n",
        "        # This case indicates a potential issue in Q/N calculation\n",
        "        print(\"Warning: Mismatch in transient node indices and hitting time results length.\")\n",
        "        # Fallback: fill with NaNs for safety\n",
        "        out.fill(np.nan)\n",
        "\n",
        "    return out\n",
        "\n",
        "def stationary_dist(P):\n",
        "    n = P.shape[0]\n",
        "    A = P.T - np.eye(n)\n",
        "    A[-1, :] = 1.0  # Add constraint that distribution sums to 1\n",
        "    b = np.zeros(n)\n",
        "    b[-1] = 1.0\n",
        "    try:\n",
        "        # Use pinv for potentially non-ergodic chains\n",
        "        pi = np.linalg.pinv(A) @ b\n",
        "        pi = np.real(pi)\n",
        "        pi = np.maximum(pi, 0)\n",
        "        s = pi.sum()\n",
        "        return (pi / s) if s > 0 else np.ones(n) / n\n",
        "    except np.linalg.LinAlgError:\n",
        "        print(\"Warning: Could not compute stationary distribution.\")\n",
        "        return np.ones(n) / n # Fallback to uniform distribution\n",
        "\n",
        "def entropy_production(P, eps=1e-12):\n",
        "    pi = stationary_dist(P)\n",
        "    n = P.shape[0]\n",
        "    Sigma = 0.0\n",
        "    for i in range(n):\n",
        "        for j in range(n): # Iterate over all pairs for detailed balance check\n",
        "            if i == j: continue\n",
        "            Jij = pi[i] * P[i, j]\n",
        "            Jji = pi[j] * P[j, i]\n",
        "            # Use absolute values for log argument to avoid issues with small negative numbers\n",
        "            # Add eps for numerical stability\n",
        "            if abs(Jij) > eps or abs(Jji) > eps:\n",
        "                Sigma += (Jij - Jji) * np.log((abs(Jij) + eps) / (abs(Jji) + eps))\n",
        "\n",
        "    # For Schnakenberg, sum over *distinct* pairs i != j only once, e.g., j > i.\n",
        "    # The formula is Sigma = 0.5 * Sum_{i!=j} (Jij - Jji) * log(Jij/Jji)\n",
        "    # The previous loop sums each pair twice (i,j) and (j,i), so divide by 2.\n",
        "    return float(Sigma * 0.5) # Divide by 2 for correct Schnakenberg formula\n",
        "\n",
        "def spectral_gap_and_kemeny(P):\n",
        "    n = P.shape[0]\n",
        "    vals = np.linalg.eigvals(P)\n",
        "    vals = np.real_if_close(vals)\n",
        "    # Sort eigenvalues by magnitude in descending order\n",
        "    sorted_indices = np.argsort(np.abs(vals))[::-1]\n",
        "    sorted_vals = vals[sorted_indices]\n",
        "\n",
        "    # Find the eigenvalue closest to 1 (should be 1 for ergodic chains)\n",
        "    idx_one = np.argmin(np.abs(sorted_vals - 1.0))\n",
        "    l1 = sorted_vals[idx_one]\n",
        "\n",
        "    # The second largest eigenvalue magnitude\n",
        "    if len(sorted_vals) > 1:\n",
        "       # Find the second largest eigenvalue by magnitude, excluding the one at 1\n",
        "       # Ensure there are eigenvalues other than 1 before accessing index 0 of the deleted array\n",
        "       non_one_vals = np.delete(sorted_vals, idx_one)\n",
        "       l2 = np.abs(non_one_vals)[0] if non_one_vals.size > 0 else 0.0\n",
        "    else:\n",
        "        l2 = 0.0\n",
        "\n",
        "    gap = float(1.0 - l2)\n",
        "\n",
        "    K = 0.0\n",
        "    # Kemeny constant formula sum_{k=2}^n 1/(1-lambda_k)\n",
        "    # Sum over all eigenvalues except the one at 1\n",
        "    for k in range(n):\n",
        "        # Use a tolerance when comparing to 1 to handle floating point inaccuracies\n",
        "        if abs(sorted_vals[k] - 1.0) < 1e-9:\n",
        "             continue\n",
        "        denom = 1.0 - sorted_vals[k]\n",
        "        if abs(denom) > 1e-9:\n",
        "            K += (1.0 / denom)\n",
        "        # else: if denominator is zero (another eigenvalue at 1), Kemeny is infinite. Handle with large number.\n",
        "        else:\n",
        "            K += 1e9 # Represent infinite Kemeny constant with a large number\n",
        "    return gap, float(K)\n",
        "\n",
        "def pick_start_index(node_idx):\n",
        "    # Prefer magnetic-like start: '2' in S1, else '6' in S2, else first node\n",
        "    for k in ('2', '6'):\n",
        "        if k in node_idx: return node_idx[k]\n",
        "    # Fallback to 'C' if available, otherwise first node\n",
        "    if 'C' in node_idx: return node_idx['C']\n",
        "    return 0 if node_idx else None # Return 0 if node_idx is not empty, otherwise None\n",
        "\n",
        "# ---------- build base chain ----------\n",
        "# Expect G in scope; if node_idx not present, build it.\n",
        "# Use the global G defined in cell 3, which includes all nodes\n",
        "if 'G' not in globals():\n",
        "    raise ValueError(\"Graph G not found. Run Cell 3 (Geometry — Star Tetra) first.\")\n",
        "\n",
        "# Re-build node_idx based on the current G to ensure consistency\n",
        "node_idx = {str(n): i for i, n in enumerate(G.nodes())}\n",
        "ALL_nodes_present = all(n in node_idx for n in ALL) # Check if all original nodes are in the current G\n",
        "\n",
        "if not node_idx:\n",
        "    print(\"Error: No nodes found in graph G.\")\n",
        "    P_norm = None\n",
        "else:\n",
        "    P_norm = build_P_from_graph(G, node_idx)\n",
        "    start_idx = pick_start_index(node_idx)\n",
        "    if start_idx is None:\n",
        "        print(\"Error: Could not determine a valid starting node.\")\n",
        "        traj_norm = None\n",
        "    else:\n",
        "        traj_norm = roll_states(P_norm, start_idx=start_idx, steps=20)\n",
        "\n",
        "    if traj_norm is not None:\n",
        "        Rc_norm   = centroid_reliance(traj_norm, node_idx, horizon=10)\n",
        "        dE_norm   = electric_acceleration(traj_norm, node_idx, t1=1, t2=2)\n",
        "    else:\n",
        "        Rc_norm, dE_norm = np.nan, np.nan\n",
        "\n",
        "    Sigma_norm = entropy_production(P_norm) if P_norm is not None else np.nan\n",
        "    gap_norm, K_norm = spectral_gap_and_kemeny(P_norm) if P_norm is not None else (np.nan, np.nan)\n",
        "    HT_norm = absorbing_hitting_time(P_norm, targets=['0', 'C'], node_idx=node_idx) if P_norm is not None else np.full(len(node_idx), np.nan)\n",
        "\n",
        "# ---------- counterfactual (optional 2→1 or 6→5) ----------\n",
        "add_counterfactual = True # This can be controlled by a form field later\n",
        "w_forbidden = 0.10 # This can be controlled by a form field later\n",
        "\n",
        "def add_forbidden_edge(Gin, node_idx, w):\n",
        "    Gx = Gin.copy()\n",
        "    tag = None\n",
        "    # Check if nodes exist before adding the edge\n",
        "    if '2' in node_idx and '1' in node_idx:\n",
        "        # Check if the edge already exists before adding to avoid errors in some graph types\n",
        "        if not Gx.has_edge('2', '1'):\n",
        "            Gx.add_edge('2', '1', rate=w)\n",
        "            tag = '2→1'\n",
        "        elif Gx['2']['1'].get('rate', 0.0) != w:\n",
        "            # Update rate if edge exists but rate is different\n",
        "            Gx['2']['1']['rate'] = w\n",
        "            tag = f'2→1 (rate updated to {w})'\n",
        "        else:\n",
        "            tag = '2→1 (edge already exists with same rate)'\n",
        "\n",
        "    elif '6' in node_idx and '5' in node_idx:\n",
        "        if not Gx.has_edge('6', '5'):\n",
        "            Gx.add_edge('6', '5', rate=w)\n",
        "            tag = '6→5'\n",
        "        elif Gx['6']['5'].get('rate', 0.0) != w:\n",
        "            Gx['6']['5']['rate'] = w\n",
        "            tag = f'6→5 (rate updated to {w})'\n",
        "        else:\n",
        "            tag = '6→5 (edge already exists with same rate)'\n",
        "\n",
        "    return Gx, tag\n",
        "\n",
        "if add_counterfactual:\n",
        "    # Use the original G to create the counterfactual graph\n",
        "    G_ctf, tag = add_forbidden_edge(G, node_idx, w_forbidden)\n",
        "    if tag is None or P_norm is None: # Also skip if normal P could not be built\n",
        "        print(\"Counterfactual skipped (no suitable nodes for forbidden edge or graph issues).\")\n",
        "        P_ctf = None\n",
        "    else:\n",
        "        # Re-build node_idx for the counterfactual graph to ensure consistency\n",
        "        node_idx_ctf = {str(n): i for i, n in enumerate(G_ctf.nodes())}\n",
        "        P_ctf = build_P_from_graph(G_ctf, node_idx_ctf)\n",
        "else:\n",
        "    P_ctf = None\n",
        "    tag = None\n",
        "\n",
        "# Ensure node_idx_ctf is defined if P_ctf is calculated\n",
        "if P_ctf is not None:\n",
        "    node_idx_ctf = {str(n): i for i, n in enumerate(G_ctf.nodes())}\n",
        "    # Use node_idx_ctf for counterfactual calculations\n",
        "    traj_ctf = roll_states(P_ctf, start_idx=pick_start_index(node_idx_ctf), steps=20)\n",
        "    if traj_ctf is not None:\n",
        "        Rc_ctf   = centroid_reliance(traj_ctf, node_idx_ctf, horizon=10)\n",
        "        dE_ctf   = electric_acceleration(traj_ctf, node_idx_ctf, t1=1, t2=2)\n",
        "    else:\n",
        "        Rc_ctf, dE_ctf = np.nan, np.nan\n",
        "\n",
        "    Sigma_ctf = entropy_production(P_ctf)\n",
        "    gap_ctf, K_ctf = spectral_gap_and_kemeny(P_ctf)\n",
        "    HT_ctf = absorbing_hitting_time(P_ctf, targets=['0', 'C'], node_idx=node_idx_ctf) # Use node_idx_ctf\n",
        "else:\n",
        "    Rc_ctf, dE_ctf, Sigma_ctf, gap_ctf, K_ctf = np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "    HT_ctf = np.full(len(node_idx), np.nan)\n",
        "\n",
        "\n",
        "# ---------- report ----------\n",
        "def fmt(v):\n",
        "    # Handle various NaN/None cases, format floats\n",
        "    if v is None or (isinstance(v, (float, np.float64)) and not np.isfinite(v)):\n",
        "        return \"nan\"\n",
        "    # Check if v is an array and format elements\n",
        "    if isinstance(v, np.ndarray):\n",
        "        return \"[\" + \", \".join(fmt(x) for x in v) + \"]\"\n",
        "    return f\"{v:.3f}\" # Default formatting for floats\n",
        "\n",
        "print(\"=== Markov Metrics ===\")\n",
        "print(f\"Centroid reliance R_C     : normal={fmt(Rc_norm)}\" + (f\" | counterfactual={fmt(Rc_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Electric acceleration ΔE   : normal={fmt(dE_norm)}\" + (f\" | counterfactual={fmt(dE_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Entropy production Σ       : normal={fmt(Sigma_norm)}\" + (f\" | counterfactual={fmt(Sigma_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Spectral gap (1-|λ2|)      : normal={fmt(gap_norm)}\" + (f\" | counterfactual={fmt(gap_ctf)}\" if P_ctf is not None else \"\"))\n",
        "print(f\"Kemeny constant            : normal={fmt(K_norm)}\" + (f\" | counterfactual={fmt(K_ctf)}\" if P_ctf is not None else \"\"))\n",
        "\n",
        "# Hitting times table\n",
        "def print_ht(label, HT, node_idx_for_ht, G_for_ht):\n",
        "    print(f\"Mean hitting time to {{0,C}} from each node ({label}):\")\n",
        "    # Iterate over the nodes actually present in the graph being reported on\n",
        "    # Sort nodes for consistent output order\n",
        "    sorted_nodes = sorted(G_for_ht.nodes(), key=str) # Simple string sort\n",
        "\n",
        "    # Check if node_idx_for_ht and HT have compatible sizes\n",
        "    if HT is not None and len(node_idx_for_ht) != len(HT):\n",
        "        print(f\"Warning: Node index size ({len(node_idx_for_ht)}) mismatch with HT array size ({len(HT)}) for {label} report.\")\n",
        "\n",
        "    for node_key_orig in sorted_nodes:\n",
        "        k = str(node_key_orig) # Ensure key is string for consistent lookup\n",
        "\n",
        "        # Safely get the node label, falling back to the key if node access fails\n",
        "        try:\n",
        "            node_label = G_for_ht.nodes[node_key_orig].get('label', k)\n",
        "        except KeyError:\n",
        "            # If direct access fails, use the string key as the label\n",
        "            node_label = k\n",
        "            print(f\"Warning: Could not access node attributes for key '{k}' in graph '{label}'. Using key as label.\")\n",
        "\n",
        "\n",
        "        # Get the hitting time value\n",
        "        v = np.nan # Default to NaN\n",
        "\n",
        "        if k in node_idx_for_ht:\n",
        "            idx = node_idx_for_ht[k]\n",
        "            if HT is not None and idx < len(HT): # Check index is within bounds of HT array\n",
        "                v = HT[idx]\n",
        "                 # Handle potential NaN/Inf from hitting time calculation\n",
        "                if not np.isfinite(v):\n",
        "                    v = 0.0 if k in ('0','C') else np.nan\n",
        "            elif k in ('0', 'C'):\n",
        "                 # If target node index is not valid for HT but is a target, report 0\n",
        "                v = 0.0\n",
        "            # else: If node is in node_idx but not a target and index is invalid/HT is None, v remains nan\n",
        "\n",
        "        elif k in ('0', 'C'):\n",
        "             # If target node is not in node_idx but is a target, report 0\n",
        "             v = 0.0\n",
        "        # else: If node exists in G_for_ht but not in node_idx_for_ht (unexpected), v remains nan\n",
        "\n",
        "\n",
        "        print(f\"  {node_label:>22s}: {fmt(v)}\")\n",
        "\n",
        "\n",
        "print_ht(\"normal\", HT_norm, node_idx, G) # Pass node_idx and G for normal report\n",
        "if P_ctf is not None and G_ctf is not None:\n",
        "    print_ht(f\"counterfactual ({tag})\", HT_ctf, node_idx_ctf, G_ctf) # Pass node_idx_ctf and G_ctf\n",
        "\n",
        "# Export for later cells\n",
        "markov_report = {\n",
        "    \"normal\": {\n",
        "        \"Rc\": Rc_norm, \"dE\": dE_norm, \"Sigma\": Sigma_norm,\n",
        "        \"gap\": gap_norm, \"Kemeny\": K_norm, \"HT\": HT_norm\n",
        "    }\n",
        "}\n",
        "if P_ctf is not None and G_ctf is not None:\n",
        "    markov_report[\"counterfactual\"] = {\n",
        "        \"tag\": tag, \"Rc\": Rc_ctf, \"dE\": dE_ctf, \"Sigma\": Sigma_ctf,\n",
        "        \"gap\": gap_ctf, \"Kemeny\": K_ctf, \"HT\": HT_ctf\n",
        "    }"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Markov Metrics ===\n",
            "Centroid reliance R_C     : normal=0.241 | counterfactual=0.230\n",
            "Electric acceleration ΔE   : normal=0.288 | counterfactual=0.241\n",
            "Entropy production Σ       : normal=17.347 | counterfactual=14.771\n",
            "Spectral gap (1-|λ2|)      : normal=0.389 | counterfactual=0.405\n",
            "Kemeny constant            : normal=4.649 | counterfactual=4.837\n",
            "Mean hitting time to {0,C} from each node (normal):\n",
            "                       0: 0.000\n",
            "                       1: 2.944\n",
            "                       2: 1.444\n",
            "                       3: 1.400\n",
            "                       C: 0.000\n",
            "Mean hitting time to {0,C} from each node (counterfactual (2→1)):\n",
            "                       0: 0.000\n",
            "                       1: 3.222\n",
            "                       2: 1.722\n",
            "                       3: 1.400\n",
            "                       C: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3529139570.py:154: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return gap, float(K)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ace3d1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "1c984153-4109-4718-c72d-768fde7e106c"
      },
      "source": [
        "# @title 8. **Energy Balance Audit — Stored Energy vs Power Flows** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines SPD energy forms; compares dU/dt with (input − dissipation); residual should hover near zero.\n",
        "\n",
        "import numpy as np\n",
        "from mpmath import mpf\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Setup (Assumes Cell 6: baseline_history with 'energy', 'E_field', 'B_field') ---\n",
        "# Ensure globals exist from DEC Stepper\n",
        "try:\n",
        "    history = baseline_history # Corrected from global_history\n",
        "    dt = global_dt\n",
        "    ε = global_epsilon\n",
        "    μ = global_mu\n",
        "    σ = global_sigma\n",
        "except NameError:\n",
        "    raise ValueError(\"Run Cell 6 (DEC Stepper) first to set baseline_history, dt, ε, μ, σ\")\n",
        "\n",
        "# Graph (reuse from Cell 6 if available; mock for audit)\n",
        "if 'G' not in globals():\n",
        "    nodes = ['C', '0', '1', '2', '3']\n",
        "    G = nx.DiGraph()\n",
        "    G.add_nodes_from(nodes)\n",
        "    G.add_edges_from([('C','1'), ('1','2'), ('2','C'), ('C','3'), ('3','0'), ('0','C')])\n",
        "\n",
        "# --- Power Flow Calculation ---\n",
        "def compute_power_flows(E, B, G, σ, ε):\n",
        "    \"\"\"Input power (proxy: pump at (C,1)) minus dissipation (Joule: σ |E|^2).\"\"\"\n",
        "    input_power = 0.0\n",
        "    if ('C', '1') in edge_idx:\n",
        "        input_power = abs(E[edge_idx[('C', '1')]]) * 1.0  # Source term (W/m)\n",
        "\n",
        "    # Dissipation: Integrated Joule heating σ |E|^2 over edges\n",
        "    dissipation = σ * np.sum(E**2)\n",
        "\n",
        "    return input_power - dissipation\n",
        "\n",
        "# --- Audit Loop (Over History) ---\n",
        "residuals = []\n",
        "dU_dt_vals = []\n",
        "power_net_vals = []\n",
        "n_steps = len(history['energy'])\n",
        "epsilon = 1e-18 # a small number to avoid division by zero\n",
        "\n",
        "if n_steps > 1:\n",
        "    for i in range(1, n_steps):\n",
        "        # Retrieve E/B from history\n",
        "        E = history['E_field'][i-1]  # Use previous for dU/dt consistency\n",
        "        B = history['B_field'][i-1]\n",
        "\n",
        "        # dU/dt (central finite difference approximation)\n",
        "        U_prev = history['energy'][i-1]\n",
        "        U_curr = history['energy'][i]\n",
        "        dU_dt = (U_curr - U_prev) / (dt + epsilon)\n",
        "\n",
        "        # Power net\n",
        "        power_net = compute_power_flows(E, B, G, σ, ε)\n",
        "\n",
        "        # Residual: |dU/dt - (input - dissipation)|\n",
        "        res = abs(float(dU_dt - power_net))\n",
        "        residuals.append(res)\n",
        "        dU_dt_vals.append(float(dU_dt))\n",
        "        power_net_vals.append(float(power_net))\n",
        "\n",
        "        # Early report\n",
        "        if i > 0 and i % 50 == 0:\n",
        "            print(f\"Step {i}: dU/dt={dU_dt:.2e}, Power Net={power_net:.2e}, Res={res:.2e}\")\n",
        "\n",
        "# --- Summary Stats ---\n",
        "if residuals:\n",
        "    mean_residual = np.mean(residuals)\n",
        "    max_residual = np.max(residuals)\n",
        "    std_residual = np.std(residuals)\n",
        "else:\n",
        "    mean_residual, max_residual, std_residual = np.nan, np.nan, np.nan\n",
        "\n",
        "U_final = history['energy'][-1] if history['energy'] else np.nan\n",
        "\n",
        "print(f\"\\n--- Energy Balance Audit Summary ---\")\n",
        "print(f\"Steps Audited: {len(residuals)}\")\n",
        "print(f\"Mean Residual: {mean_residual:.2e} (should hover ~0)\")\n",
        "print(f\"Max Residual: {max_residual:.2e}\")\n",
        "print(f\"Std Residual: {std_residual:.2e}\")\n",
        "print(f\"Final Stored Energy U: {float(U_final):.2e} J\")\n",
        "print(f\"Audit Status: {'PASS' if not np.isnan(mean_residual) and mean_residual < 1e-10 else 'FAIL'} (residual near zero)\")\n",
        "\n",
        "# --- Plot Residuals vs Time ---\n",
        "if residuals:\n",
        "    steps_plot = np.arange(1, len(residuals) + 1)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    ax1.plot(steps_plot, dU_dt_vals, label='dU/dt', alpha=0.7)\n",
        "    ax1.plot(steps_plot, power_net_vals, label='Input - Dissipation', alpha=0.7)\n",
        "    ax1.set_title('Energy Rate vs Power Flows')\n",
        "    ax1.set_ylabel('Rate (J/s)')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    ax2.plot(steps_plot, residuals)\n",
        "    ax2.set_title('Residual |dU/dt - (Input - Dissipation)|')\n",
        "    ax2.set_ylabel('Residual')\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- Store for Later (e.g., Cell 15 plots) ---\n",
        "global_residuals = residuals\n",
        "global_dU_dt = dU_dt_vals\n",
        "global_power_net = power_net_vals\n",
        "\n",
        "print(\"\\nAudit complete. Residuals stored in global_residuals for visualizations.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Run Cell 6 (DEC Stepper) first to set baseline_history, dt, ε, μ, σ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3961903179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_history\u001b[0m \u001b[0;31m# Corrected from global_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_dt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'baseline_history' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3961903179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mσ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_sigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run Cell 6 (DEC Stepper) first to set baseline_history, dt, ε, μ, σ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Graph (reuse from Cell 6 if available; mock for audit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Run Cell 6 (DEC Stepper) first to set baseline_history, dt, ε, μ, σ"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb2ece69"
      },
      "source": [
        "# @title 9. **Phase Linter — 90° E–M Lag & Anchor to C (S1 & Star)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Kuramoto-style diagnostic layer; targets 90° E–M lag, gentle anchoring to C; reports phase error/spread (no feedback).\n",
        "import numpy as np\n",
        "\n",
        "# Assumes S1, S2, and a node_idx map are in the global scope.\n",
        "# If not, this cell will fail. Ensure geometry cells (2, 3) and an operator cell (e.g., 4) have run.\n",
        "\n",
        "# Define node_list based on detected S1/S2 to be robust\n",
        "node_list = []\n",
        "if 'S1' in globals(): node_list.extend(list(S1)) # Convert set to list for node_list\n",
        "if 'S2' in globals(): node_list.extend(list(S2)) # Convert set to list for node_list\n",
        "if 'C' in globals() and 'C' not in node_list: node_list.append('C')\n",
        "\n",
        "# Re-create index map based on the actual node list\n",
        "idx = {k: i for i, k in enumerate(node_list)}\n",
        "n_nodes_phase = len(node_list)\n",
        "\n",
        "# Initialize phase array if not present\n",
        "if 'phi_star' not in globals() or len(phi_star) != n_nodes_phase:\n",
        "    phi_star = np.zeros(n_nodes_phase)\n",
        "\n",
        "def _wrap_pi(x):\n",
        "    return (x + np.pi) % (2 * np.pi) - np.pi\n",
        "\n",
        "# --- Define Couplings and Target Lags ---\n",
        "kap = np.zeros((n_nodes_phase, n_nodes_phase))\n",
        "theta = np.zeros_like(kap)\n",
        "\n",
        "def set_kap(a, b, val):\n",
        "    if a in idx and b in idx:\n",
        "        i, j = idx[a], idx[b]\n",
        "        kap[i, j] = val\n",
        "        kap[j, i] = val\n",
        "\n",
        "def set_theta(a, b, rad):\n",
        "    if a in idx and b in idx:\n",
        "        i, j = idx[a], idx[b]\n",
        "        theta[i, j] = rad\n",
        "        theta[j, i] = -rad # Anti-symmetric for phi_j - phi_i\n",
        "\n",
        "# Baseline weak coupling for all nodes within each shell\n",
        "if 'S1' in globals():\n",
        "    # Iterate over elements of the set S1\n",
        "    for u in S1:\n",
        "        for v in S1:\n",
        "            if u != v: # Avoid self-coupling here\n",
        "                set_kap(u, v, 0.02)\n",
        "\n",
        "if 'S2' in globals():\n",
        "    # Iterate over elements of the set S2\n",
        "    for u in S2:\n",
        "        for v in S2:\n",
        "            if u != v: # Avoid self-coupling here\n",
        "                set_kap(u, v, 0.02)\n",
        "\n",
        "\n",
        "# Stronger E-M couplings within each shell\n",
        "set_kap('1', '2', 0.12)\n",
        "set_kap('5', '6', 0.12)\n",
        "set_theta('1', '2', np.pi / 2)\n",
        "set_theta('5', '6', np.pi / 2)\n",
        "\n",
        "# Work and heat bridge couplings\n",
        "set_kap('3', '6', 0.08); set_theta('3', '6', np.pi / 2) # Work\n",
        "set_kap('7', '4', 0.05); set_theta('7', '4', np.pi)     # Heat\n",
        "set_kap('7', '2', 0.05); set_theta('7', '2', np.pi)     # Heat\n",
        "set_kap('5', '0', 0.05); set_theta('5', '0', np.pi)     # Heat\n",
        "\n",
        "# Anchor to Centroid\n",
        "γC = 0.05\n",
        "\n",
        "def phase_step(phi, dt):\n",
        "    d_phi = np.zeros_like(phi)\n",
        "    # Iterate over all nodes that have a defined index\n",
        "    for u, i in idx.items():\n",
        "        if u == 'C': continue # Centroid is the anchor, does not update\n",
        "\n",
        "        acc = 0.0\n",
        "        # Interaction with other nodes\n",
        "        for v, j in idx.items():\n",
        "            if i == j: continue\n",
        "            acc += kap[i, j] * np.sin(phi[j] - phi[i] - theta[i, j])\n",
        "\n",
        "        # Anchor to Centroid (phi[idx['C']] is assumed to be 0)\n",
        "        if 'C' in idx:\n",
        "            acc -= γC * np.sin(phi[i] - phi[idx['C']])\n",
        "\n",
        "        d_phi[i] = acc\n",
        "\n",
        "    # Update phases (excluding the Centroid)\n",
        "    # Ensure d_phi has the same length as phi before updating\n",
        "    if len(d_phi) == len(phi):\n",
        "        phi += dt * d_phi\n",
        "    else:\n",
        "        print(\"Warning: Mismatch in phi and d_phi lengths. Skipping phase update.\")\n",
        "\n",
        "\n",
        "    # Keep centroid phase at 0\n",
        "    if 'C' in idx:\n",
        "        phi[idx['C']] = 0\n",
        "\n",
        "    return _wrap_pi(phi)\n",
        "\n",
        "def phase_report(phi):\n",
        "    report_data = {}\n",
        "    def err(a, b, trg):\n",
        "        if a in idx and b in idx:\n",
        "            i, j = idx[a], idx[b]\n",
        "            return float(np.degrees(_wrap_pi((phi[i] - phi[j]) - trg)))\n",
        "        return np.nan\n",
        "\n",
        "    report_data['EM_S1_deg'] = err('1', '2', np.pi/2)\n",
        "    report_data['EM_S2_deg'] = err('5', '6', np.pi/2)\n",
        "    report_data['work_3_6_deg'] = err('3', '6', np.pi/2)\n",
        "    report_data['heat_7_4_deg'] = err('7', '4', np.pi)\n",
        "    report_data['heat_7_2_deg'] = err('7', '2', np.pi)\n",
        "    report_data['heat_5_0_deg'] = err('5', '0', np.pi)\n",
        "    if 'C' in idx:\n",
        "        report_data['C_phase_deg'] = float(np.degrees(phi[idx['C']]))\n",
        "\n",
        "    return report_data\n",
        "\n",
        "# Example of running the phase linter for a few steps to let it settle\n",
        "# This part is for demonstration; the main simulation will call phase_step repeatedly\n",
        "print(\"Phase linter loaded. Running a few settling steps...\")\n",
        "for _ in range(50):\n",
        "    # Ensure phi_star is correctly sized before calling phase_step\n",
        "    if 'phi_star' not in globals() or len(phi_star) != n_nodes_phase:\n",
        "         phi_star = np.zeros(n_nodes_phase)\n",
        "\n",
        "    phi_star = phase_step(phi_star, dt=0.1)\n",
        "\n",
        "print(\"Settling complete. Current phase errors:\")\n",
        "print(phase_report(phi_star))\n",
        "\n",
        "# The linter functions (phase_step, phase_report) are now available for other cells."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee8a0508"
      },
      "source": [
        "# @title 10. **Centroid Angle Probe — 109.471221° Mediation Test** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Reweights edges to/from C by the tetrahedral bond angle; measures impact on mediation (R_C), hitting times, EPR.\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from mpmath import mpf\n",
        "\n",
        "# --- Parameters ---\n",
        "# Tetrahedral angle in radians (cos(-1/3))\n",
        "TETRA_ANGLE_RAD = mpf('1.9106332362490186') # Approx 109.47 degrees\n",
        "\n",
        "# --- Helper to apply angle-based weighting ---\n",
        "def weight_graph_by_angle(G_in, angle_rad):\n",
        "    \"\"\"\n",
        "    Creates a deep copy of the graph and re-weights edges to/from the Centroid 'C'\n",
        "    by a factor related to the tetrahedral angle.\n",
        "    \"\"\"\n",
        "    G_weighted = G_in.copy() # Deep copy to avoid modifying the original graph\n",
        "\n",
        "    # Weighting factor (e.g., use the angle directly, or a function of it)\n",
        "    # Using a simple scaling factor for demonstration.\n",
        "    # A more physically-motivated model might use cos(angle) or other geometric factors.\n",
        "    weight_factor = float(angle_rad / np.pi) # Normalize by pi to get a reasonable factor\n",
        "\n",
        "    for u, v, data in G_weighted.edges(data=True):\n",
        "        rate = data.get('rate', mpf('1.0'))\n",
        "        # Apply weighting if the edge involves the Centroid\n",
        "        if u == 'C' or v == 'C':\n",
        "            data['rate'] = rate * weight_factor\n",
        "\n",
        "    return G_weighted\n",
        "\n",
        "# --- Create the weighted graph ---\n",
        "G_angled = weight_graph_by_angle(G, TETRA_ANGLE_RAD)\n",
        "\n",
        "# --- Re-run Markov Diagnostics on the weighted graph ---\n",
        "# We need the Markov analysis helper functions. If they are not in the global scope,\n",
        "# this cell will fail. This assumes Cell 7 has been run.\n",
        "try:\n",
        "    # We need a new node_idx for the potentially modified graph\n",
        "    node_idx_angled = {str(n): i for i, n in enumerate(G_angled.nodes())}\n",
        "\n",
        "    # Build the transition matrix\n",
        "    P_angled = build_P_from_graph(G_angled, node_idx_angled)\n",
        "\n",
        "    # Run diagnostics\n",
        "    start_idx_angled = pick_start_index(node_idx_angled)\n",
        "    if start_idx_angled is not None:\n",
        "        traj_angled = roll_states(P_angled, start_idx_angled, steps=20)\n",
        "        Rc_angled = centroid_reliance(traj_angled, node_idx_angled)\n",
        "        dE_angled = electric_acceleration(traj_angled, node_idx_angled)\n",
        "    else:\n",
        "        Rc_angled, dE_angled = np.nan, np.nan\n",
        "\n",
        "    Sigma_angled = entropy_production(P_angled)\n",
        "    gap_angled, K_angled = spectral_gap_and_kemeny(P_angled)\n",
        "    HT_angled = absorbing_hitting_time(P_angled, targets=['0', 'C'], node_idx=node_idx_angled)\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"Error: A required function from Markov Diagnostics (Cell 7) is missing: {e}\")\n",
        "    print(\"Please run Cell 7 before this one.\")\n",
        "    # Set dummy values to avoid breaking subsequent cells\n",
        "    Rc_angled, dE_angled, Sigma_angled, gap_angled, K_angled, HT_angled = [np.nan] * 6\n",
        "\n",
        "# --- Report Comparison ---\n",
        "print(\"--- Centroid Angle Probe Results ---\")\n",
        "print(f\"Weighting edges to/from 'C' by a factor derived from {float(TETRA_ANGLE_RAD):.3f} rad ({np.degrees(float(TETRA_ANGLE_RAD)):.2f}°).\")\n",
        "print(\"\\n--- Comparison of Markov Metrics (Normal vs. Angle-Weighted) ---\")\n",
        "\n",
        "# A helper to format for comparison\n",
        "def fmt_comp(val_norm, val_angled):\n",
        "    # Check if values are valid numbers before formatting\n",
        "    is_norm_valid = val_norm is not None and np.isfinite(val_norm)\n",
        "    is_angled_valid = val_angled is not None and np.isfinite(val_angled)\n",
        "\n",
        "    norm_str = f\"{val_norm:.3f}\" if is_norm_valid else \"nan\"\n",
        "    angled_str = f\"{val_angled:.3f}\" if is_angled_valid else \"nan\"\n",
        "\n",
        "    delta_str = \"\"\n",
        "    if is_norm_valid and is_angled_valid:\n",
        "        delta = val_angled - val_norm\n",
        "        delta_str = f\"  (Δ: {delta:+.3f})\"\n",
        "\n",
        "    return f\"{norm_str:>8}  ->  {angled_str:>8}{delta_str}\"\n",
        "\n",
        "# Fetch the normal metrics from the 'markov_report' global created in Cell 7\n",
        "try:\n",
        "    normal_metrics = markov_report['normal']\n",
        "    print(f\"Centroid Reliance (R_C): {fmt_comp(normal_metrics.get('Rc'), Rc_angled)}\")\n",
        "    print(f\"Electric Accel (ΔE):   {fmt_comp(normal_metrics.get('dE'), dE_angled)}\")\n",
        "    print(f\"Entropy Prod (Σ):      {fmt_comp(normal_metrics.get('Sigma'), Sigma_angled)}\")\n",
        "    print(f\"Spectral Gap:          {fmt_comp(normal_metrics.get('gap'), gap_angled)}\")\n",
        "    print(f\"Kemeny Constant:       {fmt_comp(normal_metrics.get('Kemeny'), K_angled)}\")\n",
        "\n",
        "    # Compare mean hitting times (excluding targets)\n",
        "    ht_norm = normal_metrics.get('HT', [])\n",
        "    # Filter out NaNs and Infs for a clean mean calculation\n",
        "    ht_norm_mean = np.nanmean([t for t in ht_norm if np.isfinite(t) and t > 0])\n",
        "    ht_angled_mean = np.nanmean([t for t in HT_angled if np.isfinite(t) and t > 0])\n",
        "    print(f\"Mean Hitting Time:     {fmt_comp(ht_norm_mean, ht_angled_mean)}\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"\\n'markov_report' not found. Cannot compare with baseline. Run Cell 7 first.\")\n",
        "except KeyError:\n",
        "    print(\"\\n'normal' key not in 'markov_report'. Cannot compare with baseline.\")\n",
        "\n",
        "# Store results for later use\n",
        "angle_probe_report = {\n",
        "    \"Rc\": Rc_angled,\n",
        "    \"dE\": dE_angled,\n",
        "    \"Sigma\": Sigma_angled,\n",
        "    \"gap\": gap_angled,\n",
        "    \"Kemeny\": K_angled,\n",
        "    \"HT_mean\": ht_angled_mean if 'ht_angled_mean' in locals() else np.nan\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diagnostics (energy, EPR, phase, visuals)"
      ],
      "metadata": {
        "id": "cwVkgWSFPaxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main — Select Pipeline and Geometry { display-mode: \"form\" }\n",
        "PIPELINE = \"fast\"   # \"fast\" (Cell 6 dec_step) or \"si\" (Cell 14 leapfrog_step)\n",
        "GEOMETRY = \"S1\"     # \"S1\" or \"STAR\"\n",
        "\n",
        "if PIPELINE == \"fast\":\n",
        "    print(\"Running baseline DEC stepper (dimensionless).\")\n",
        "    # This will run the simulation defined in Cell 6\n",
        "    # The `baseline_history` variable will be available for subsequent cells.\n",
        "elif PIPELINE == \"si\":\n",
        "    print(\"Running stable SI leapfrog stepper.\")\n",
        "    # This would run the simulation from Cell 14.\n",
        "    # Note: The `run_star_tetra_cycle` function is defined in Cell 19,\n",
        "    # so you would need to ensure that cell is run before this one if using the \"si\" pipeline.\n",
        "else:\n",
        "    raise ValueError(\"Unknown PIPELINE.\")"
      ],
      "metadata": {
        "id": "npVHj1YjZm8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cdd9aab"
      },
      "source": [
        "# @title 11. **Adelic Layer — ℚ_p Utilities & Prime Sweep** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Implements p-adic valuation/norm; builds composite “adelic balance”; sweeps primes (e.g., 2,3,5,7,11,…,137) for robustness.\n",
        "\n",
        "from sympy import prime, factorint\n",
        "from mpmath import mpf, power\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- p-adic helpers ---\n",
        "def padic_valuation(n, p):\n",
        "    \"\"\"Computes the p-adic valuation of an integer n.\"\"\"\n",
        "    if n == 0:\n",
        "        return float('inf')\n",
        "    valuation = 0\n",
        "    n = abs(int(n)) # Ensure we are working with positive integers\n",
        "    if n == 0: return float('inf')\n",
        "    while n > 0 and n % p == 0:\n",
        "        valuation += 1\n",
        "        n //= p\n",
        "    return valuation\n",
        "\n",
        "def padic_norm(n, p):\n",
        "    \"\"\"Computes the p-adic norm |n|_p = p^(-v_p(n)).\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    v = padic_valuation(n, p)\n",
        "    return power(p, -v)\n",
        "\n",
        "def padic_norm_from_energy(energy, scale=1e18):\n",
        "    \"\"\"\n",
        "    Converts a real-valued energy to a scaled integer to compute a p-adic norm.\n",
        "    This is a heuristic to bridge the continuous (real) and discrete (p-adic) domains.\n",
        "    \"\"\"\n",
        "    # Heuristically convert a float energy to a large integer\n",
        "    # The scale factor is crucial and problem-dependent\n",
        "    n = int(energy * scale)\n",
        "    if n == 0:\n",
        "        return 0\n",
        "\n",
        "    # For demonstration, we'll use a fixed prime p=2, but this could be varied.\n",
        "    p = 2\n",
        "\n",
        "    return padic_norm(n, p)\n",
        "\n",
        "# --- Adelic Balance ---\n",
        "# A conceptual model for combining real and p-adic measures.\n",
        "# alpha_pad is a mixing parameter.\n",
        "alpha_pad = mpf('0.1')\n",
        "\n",
        "def adelic_balance(e_real, e_padic):\n",
        "    \"\"\"\n",
        "    A simple model for the interplay between real and p-adic components.\n",
        "    This is a toy model for the \"adelic crystal\" concept where both measures matter.\n",
        "    \"\"\"\n",
        "    # Example: a weighted geometric mean, preserving a conceptual \"total\" value.\n",
        "    # This is highly speculative and for model-testing purposes.\n",
        "    e_real_new = power(e_real, 1 - alpha_pad)\n",
        "    e_padic_new = power(e_padic, alpha_pad)\n",
        "\n",
        "    return e_real_new, e_padic_new\n",
        "\n",
        "# --- Prime Sweep ---\n",
        "def get_primes_up_to(n):\n",
        "    \"\"\"Returns a list of prime numbers up to n.\"\"\"\n",
        "    primes = []\n",
        "    i = 1\n",
        "    while True:\n",
        "        p = prime(i)\n",
        "        if p <= n:\n",
        "            primes.append(p)\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "    return primes\n",
        "\n",
        "def analyze_number_with_primes(n, primes):\n",
        "    \"\"\"\n",
        "    Computes p-adic norms for a number n across a list of primes.\n",
        "    \"\"\"\n",
        "    norms = [padic_norm(n, p) for p in primes]\n",
        "    return norms\n",
        "\n",
        "# --- Demonstration of Prime Sweep ---\n",
        "# Example number to analyze. In the full model, this would be derived from a state variable.\n",
        "test_number = 120  # (2^3 * 3 * 5)\n",
        "\n",
        "# Primes to test against\n",
        "primes_to_sweep = get_primes_up_to(20) # e.g., [2, 3, 5, 7, 11, 13, 17, 19]\n",
        "\n",
        "# Calculate norms\n",
        "norms = analyze_number_with_primes(test_number, primes_to_sweep)\n",
        "\n",
        "# --- Report and Visualize ---\n",
        "print(f\"Analyzing integer: {test_number}\")\n",
        "print(f\"Factors: {factorint(test_number)}\")\n",
        "print(\"p-adic norms |n|_p for primes up to 20:\")\n",
        "for p, norm in zip(primes_to_sweep, norms):\n",
        "    print(f\"  p={p:<3}: |{test_number}|_{p} = {float(norm):.4f}\")\n",
        "\n",
        "# Plotting the norms\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar([str(p) for p in primes_to_sweep], [float(n) for n in norms], color='skyblue')\n",
        "plt.title(f'p-adic Norms of {test_number} for Various Primes')\n",
        "plt.xlabel('Prime (p)')\n",
        "plt.ylabel('p-adic Norm |n|_p')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Store adelic helpers and sweep results for later use\n",
        "adelic_utils = {\n",
        "    'padic_valuation': padic_valuation,\n",
        "    'padic_norm': padic_norm,\n",
        "    'padic_norm_from_energy': padic_norm_from_energy,\n",
        "    'adelic_balance': adelic_balance,\n",
        "    'alpha_pad': alpha_pad\n",
        "}\n",
        "prime_sweep_results = {\n",
        "    'test_number': test_number,\n",
        "    'primes': primes_to_sweep,\n",
        "    'norms': norms\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf480c0d"
      },
      "source": [
        "# @title 12. **Breath Operator — Inhale/Exhale Rhythm** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Alternates phases to favour in-breath (0→C, even→C) and out-breath (C→odd, 1→2 work, 3→0 heat); non-local C stays mediated."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24c6c773"
      },
      "source": [
        "# @title 13. **LENR Cycle Runner — Pump → Coherence → Squeeze → Fusion → Heat** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Executes the breath-driven cycle; integrates adelic scaling at node 3; detects “bursts” on phase-lock; logs heat/entropy.\n",
        "\n",
        "\n",
        "\n",
        "def run_cycle(G_base: nx.DiGraph, steps=400, dt=mpf('0.05'), report_every=80):\n",
        "    global phi_star\n",
        "    energy = {n: mpf('0.5') for n in ALL}\n",
        "    energy['1'] = mpf('1.0'); energy['5'] = mpf('1.0')   # start with E channels primed\n",
        "    bursts = 0; entropy = mpf('0.0'); history = {'heat': [], 'entropy': [], 'bursts': [], 'phase': []}\n",
        "\n",
        "    for k in range(steps):\n",
        "        # Breath modulation (non-destructive per step)\n",
        "        Gk, phase = apply_breath(G_base, k)\n",
        "\n",
        "        # Simple conservative flow pass (rate * energy at source)\n",
        "        for (u,v,data) in Gk.edges(data=True):\n",
        "            flow = energy[u] * data['rate'] * dt\n",
        "            if 'threshold' in data and flow < data['threshold']:\n",
        "                continue\n",
        "            energy[u] -= flow; energy[v] += flow\n",
        "\n",
        "        # p-adic scaling at matter nodes (3,7)\n",
        "        for m in ['3','7']:\n",
        "            e_r = energy[m]\n",
        "            e_p = padic_norm_from_energy(e_r)\n",
        "            e_r, e_p = adelic_balance(e_r, e_p)\n",
        "            energy[m] = e_r * power(e_p, alpha_pad)\n",
        "\n",
        "        # Fusion bursts when C↔matter near phase lock (diagnostic, not physical prediction)\n",
        "        # Use linter's phase (C fixed at 0) — here we proxy lock by small random jitter\n",
        "        jitter = abs(np.sin(phi_star[idx['C']] - phi_star[idx['3']])) + \\\n",
        "                 abs(np.sin(phi_star[idx['C']] - phi_star[idx['7']]))\n",
        "        if jitter < 0.2:\n",
        "            # split burst between shells if available\n",
        "            for m, sink in [('3','0'), ('7','4')]:\n",
        "                burst = energy[m] * mpf('0.3')\n",
        "                energy[m] -= burst\n",
        "                energy[sink] += burst * mpf('0.9')\n",
        "                entropy += burst * mpf('0.1')\n",
        "            bursts += 1\n",
        "\n",
        "        # Phase linter step (non-invasive)\n",
        "        phi_star = phase_step(phi_star, float(dt))\n",
        "\n",
        "        # Log\n",
        "        history['heat'].append(float(energy['0'] + energy['4']))\n",
        "        history['entropy'].append(float(entropy))\n",
        "        history['bursts'].append(int(bursts))\n",
        "        if k % report_every == 0:\n",
        "            print(f\"step {k:4d}  breath={phase:>4s}  bursts={bursts}  heat={history['heat'][-1]:.3f}  \",\n",
        "                  phase_report(phi_star))\n",
        "    return history\n",
        "\n",
        "hist = run_cycle(G, steps=360)\n",
        "print(\"\\nFinal:\", \"bursts=\", hist['bursts'][-1], \"entropy=\", hist['entropy'][-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d84557c"
      },
      "source": [
        "# @title 14. **Stable SI Stepper — Leapfrog + CFL + Joule Heating** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Uses leapfrog with CFL time step; computes SI energy, Joule power, entropy production; reports realistic field magnitudes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e99fb2f1"
      },
      "source": [
        "# @title 15. **Visualisations — Energy, EPR, Spectra, Phases** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Plots energy/frequency time-series, EPR bars (normal vs counterfactual vs low-T), residuals, phase diagnostics."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c51c160b"
      },
      "source": [
        "# @title 16. **Red-Team Nulls & Ablations — Try to Break It** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Degree-preserving rewires; geometry swap (octahedron); no-adelic baseline; breath disabled; 2→1 during exhale only."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e18fb48c"
      },
      "source": [
        "# @title 17. **Preregistered Sweep — Seeds × Parameters × Outcomes** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Freezes thresholds; runs multiple seeds; aggregates pass/fail for quantised heat + mediation/EPR signatures."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d12d1f2"
      },
      "source": [
        "# @title 18. **Centroid Work vs Heat Ledger — Path Classification** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Labels forward “work-like” shortcuts (e.g., 0→1, 2→3) and backward “heat-like” fallbacks (1→0, 3→2); tallies contributions."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42f20ef7"
      },
      "source": [
        "# @title 19. **Star-Tetra Runner — Cross-Tetra Breath with Cubic Bridges** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Executes your S1↔S2 pathing rules; measures mediation across C, cross-domain hitting times, and burst propagation."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31527ebe"
      },
      "source": [
        "# @title 20. **Centroid Locality Tests — Algorithmic Induction Around C** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Drives edge-based current scenarios near C; probes iterative/inductive dynamics; quantifies sensitivity to 109.47° bias."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c84fd14f"
      },
      "source": [
        "# @title 21. **Save & Export — Results, Seeds, Config** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this does**\n",
        "\n",
        "# @markdown - Stores metrics, plots, chosen primes, geometry flags, and RNG seeds for reproducibility; optional JSON/CSV export."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6e4b814"
      },
      "source": [
        "# @title 22. **Appendix — Utilities & Helpers** { display-mode: \"form\" }\n",
        "\n",
        "# @markdown **What this contains**\n",
        "\n",
        "# @markdown - Small helpers (index maps, safe mat-ops, plotting styles), validation checks, and pretty printers."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b851f6a"
      },
      "source": [
        "# Task\n",
        "Reorder the cells in the notebook \"https://github.com/manifoldai/manifoldflow/blob/main/papers/unified_language/unified_language.ipynb\" according to the following sequence, merging cells `7f7f6517` and `662659ce` into one cell, deleting cells `8eb7eb44` and `4fc07da8`, and noting that cell `vKkeHbZI-4fJ` should be parked for later: `qKR1ogm8760g`, `c3c07b46`, the merged cell (from `7f7f6517` and `662659ce`), `lVELWkflMr7b`, `-1pqe2HQ_n5m`, `bP96s6u7L2CW`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56b2bff1"
      },
      "source": [
        "## Merge cells\n",
        "\n",
        "### Subtask:\n",
        "Combine the content of cells `7f7f6517` and `662659ce` into a single code cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545cb1a9"
      },
      "source": [
        "**Reasoning**:\n",
        "Combine the code from the two specified cells into a single cell to merge the geometry definitions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6aa5459"
      },
      "source": [
        "# @title 2 & 3. **Geometry — Star Tetra (S1 + S2) with Cubic Bridges** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines S1 vertices {0,1,2,3,C}, allowed directed edges, self-loops, and “breath” semantics (work vs heat).\n",
        "# @markdown - Adds S2 vertices {4,5,6,7} and inter-tetra “cubic” bridges; encodes the cross-tetra flow sequence you specified.\n",
        "\n",
        "\n",
        "# Nodes: two tetrahedra share a single centroid C\n",
        "S1 = ['0','1','2','3']          # sinks even / branches odd\n",
        "S2 = ['4','5','6','7']\n",
        "ALL = S1 + S2 + ['C']\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(ALL)\n",
        "\n",
        "# Baseline rates (mpf for clean high-precision arithmetic)\n",
        "r = lambda x: mpf(str(x))\n",
        "\n",
        "# Core single-shell flows (work/heat + mediation)\n",
        "core_edges_S1 = [\n",
        "    ('C','1', {'rate': r(0.5)}),   # pump\n",
        "    ('1','2', {'rate': r(0.8)}),   # E→M (work)\n",
        "    ('2','C', {'rate': r(0.9)}),   # return to mediator\n",
        "    ('C','3', {'rate': r(0.7)}),   # squeeze/fusion path\n",
        "    ('3','0', {'rate': r(1.0)}),   # heat dump\n",
        "    ('0','C', {'rate': r(0.3)}),   # reset\n",
        "]\n",
        "\n",
        "core_edges_S2 = [\n",
        "    ('C','5', {'rate': r(0.5)}),\n",
        "    ('5','6', {'rate': r(0.8)}),\n",
        "    ('6','C', {'rate': r(0.9)}),\n",
        "    ('C','7', {'rate': r(0.7)}),\n",
        "    ('7','4', {'rate': r(1.0)}),\n",
        "    ('4','C', {'rate': r(0.3)}),\n",
        "]\n",
        "\n",
        "# Cubic cross-edges (work bridge + heat dumps)\n",
        "cross_edges = [\n",
        "    ('3','6', {'rate': r(0.35)}),  # work bridge (coherent transfer S1→S2)\n",
        "    ('7','2', {'rate': r(0.25)}),  # heat-biased back to S1 magnetic\n",
        "    ('5','0', {'rate': r(0.20)}),  # heat dump assist into S1 sink\n",
        "    ('1','6', {'rate': r(0.20)}),  # optional assist E→M across shells\n",
        "]\n",
        "\n",
        "# Self-loops (stability/linger)\n",
        "self_loops = [(n, n, {'rate': r(0.4)}) for n in S1+S2]\n",
        "\n",
        "G.add_edges_from(core_edges_S1 + core_edges_S2 + cross_edges + self_loops)\n",
        "print(\"Graph ready. |V|=\", len(G.nodes), \"|E|=\", len(G.edges))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21c20524"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `networkx` library was not imported. I need to add the necessary import statement at the beginning of the combined cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M99HHuENQg8T"
      },
      "source": [
        "# @title 2 & 3. **Geometry — Star Tetra (S1 + S2) with Cubic Bridges** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines S1 vertices {0,1,2,3,C}, allowed directed edges, self-loops, and “breath” semantics (work vs heat).\n",
        "# @markdown - Adds S2 vertices {4,5,6,7} and inter-tetra “cubic” bridges; encodes the cross-tetra flow sequence you specified.\n",
        "\n",
        "import networkx as nx # Import networkx\n",
        "\n",
        "# Nodes: two tetrahedra share a single centroid C\n",
        "S1 = ['0','1','2','3']          # sinks even / branches odd\n",
        "S2 = ['4','5','6','7']\n",
        "ALL = S1 + S2 + ['C']\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(ALL)\n",
        "\n",
        "# Baseline rates (mpf for clean high-precision arithmetic)\n",
        "r = lambda x: mpf(str(x))\n",
        "\n",
        "# Core single-shell flows (work/heat + mediation)\n",
        "core_edges_S1 = [\n",
        "    ('C','1', {'rate': r(0.5)}),   # pump\n",
        "    ('1','2', {'rate': r(0.8)}),   # E→M (work)\n",
        "    ('2','C', {'rate': r(0.9)}),   # return to mediator\n",
        "    ('C','3', {'rate': r(0.7)}),   # squeeze/fusion path\n",
        "    ('3','0', {'rate': r(1.0)}),   # heat dump\n",
        "    ('0','C', {'rate': r(0.3)}),   # reset\n",
        "]\n",
        "\n",
        "core_edges_S2 = [\n",
        "    ('C','5', {'rate': r(0.5)}),\n",
        "    ('5','6', {'rate': r(0.8)}),\n",
        "    ('6','C', {'rate': r(0.9)}),\n",
        "    ('C','7', {'rate': r(0.7)}),\n",
        "    ('7','4', {'rate': r(1.0)}),\n",
        "    ('4','C', {'rate': r(0.3)}),\n",
        "]\n",
        "\n",
        "# Cubic cross-edges (work bridge + heat dumps)\n",
        "cross_edges = [\n",
        "    ('3','6', {'rate': r(0.35)}),  # work bridge (coherent transfer S1→S2)\n",
        "    ('7','2', {'rate': r(0.25)}),  # heat-biased back to S1 magnetic\n",
        "    ('5','0', {'rate': r(0.20)}),  # heat dump assist into S1 sink\n",
        "    ('1','6', {'rate': r(0.20)}),  # optional assist E→M across shells\n",
        "]\n",
        "\n",
        "# Self-loops (stability/linger)\n",
        "self_loops = [(n, n, {'rate': r(0.4)}) for n in S1+S2]\n",
        "\n",
        "G.add_edges_from(core_edges_S1 + core_edges_S2 + cross_edges + self_loops)\n",
        "print(\"Graph ready. |V|=\", len(G.nodes), \"|E|=\", len(G.edges))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUQufNLtQkKH"
      },
      "source": [
        "# @title 2 & 3. **Geometry — Star Tetra (S1 + S2) with Cubic Bridges** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines S1 vertices {0,1,2,3,C}, allowed directed edges, self-loops, and “breath” semantics (work vs heat).\n",
        "# @markdown - Adds S2 vertices {4,5,6,7} and inter-tetra “cubic” bridges; encodes the cross-tetra flow sequence you specified.\n",
        "\n",
        "import networkx as nx # Import networkx\n",
        "from mpmath import mpf # Import mpf\n",
        "\n",
        "# Nodes: two tetrahedra share a single centroid C\n",
        "S1 = ['0','1','2','3']          # sinks even / branches odd\n",
        "S2 = ['4','5','6','7']\n",
        "ALL = S1 + S2 + ['C']\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(ALL)\n",
        "\n",
        "# Baseline rates (mpf for clean high-precision arithmetic)\n",
        "r = lambda x: mpf(str(x))\n",
        "\n",
        "# Core single-shell flows (work/heat + mediation)\n",
        "core_edges_S1 = [\n",
        "    ('C','1', {'rate': r(0.5)}),   # pump\n",
        "    ('1','2', {'rate': r(0.8)}),   # E→M (work)\n",
        "    ('2','C', {'rate': r(0.9)}),   # return to mediator\n",
        "    ('C','3', {'rate': r(0.7)}),   # squeeze/fusion path\n",
        "    ('3','0', {'rate': r(1.0)}),   # heat dump\n",
        "    ('0','C', {'rate': r(0.3)}),   # reset\n",
        "]\n",
        "\n",
        "core_edges_S2 = [\n",
        "    ('C','5', {'rate': r(0.5)}),\n",
        "    ('5','6', {'rate': r(0.8)}),\n",
        "    ('6','C', {'rate': r(0.9)}),\n",
        "    ('C','7', {'rate': r(0.7)}),\n",
        "    ('7','4', {'rate': r(1.0)}),\n",
        "    ('4','C', {'rate': r(0.3)}),\n",
        "]\n",
        "\n",
        "# Cubic cross-edges (work bridge + heat dumps)\n",
        "cross_edges = [\n",
        "    ('3','6', {'rate': r(0.35)}),  # work bridge (coherent transfer S1→S2)\n",
        "    ('7','2', {'rate': r(0.25)}),  # heat-biased back to S1 magnetic\n",
        "    ('5','0', {'rate': r(0.20)}),  # heat dump assist into S1 sink\n",
        "    ('1','6', {'rate': r(0.20)}),  # optional assist E→M across shells\n",
        "]\n",
        "\n",
        "# Self-loops (stability/linger)\n",
        "self_loops = [(n, n, {'rate': r(0.4)}) for n in S1+S2]\n",
        "\n",
        "G.add_edges_from(core_edges_S1 + core_edges_S2 + cross_edges + self_loops)\n",
        "print(\"Graph ready. |V|=\", len(G.nodes), \"|E|=\", len(G.edges))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}