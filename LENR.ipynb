{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmZ20nkBuOxVCUAwVDD1oz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berigny/AI-Entrainment-Protocol/blob/main/LENR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Low Energy Nuclear (LENR) Cycles Model\n",
        "This notebook tests whether a minimal, topology-first model can simulate and falsify a low-energy nuclear reaction (LENR) cycle driven by breath-like EM coherence. Using Discrete Exterior Calculus (DEC) on a star-tetrahedral complex with a shared centroid, we evolve fields, enforce first-law energy accounting, monitor entropy production and phase relations, and—optionally—add an adelic (ℝ × ℚ_p) layer to represent hierarchical memory at the fusion node. If quantised heat bursts do not emerge with lawful topology, pre-burst EM signatures, rising EPR, and correct energy balance, the hypothesis is weakened. If they do, we proceed to richer modelling and lab validation. The prize is significant: a path to low-cost, high-yield, sustainable energy in an energy-hungry world.\n",
        "\n",
        "## Falsification criteria\n",
        "\n",
        "We consider the LENR cycle unsupported if any lawful configuration fails to produce:\n",
        "(i) pre-burst EM coherence with ~90° E–M phase and centroid mediation,\n",
        "(ii) quantised heat steps at the sink,\n",
        "(iii) a non-negative EPR that rises prior to bursts, and\n",
        "(iv) first-law integrity (residual ≈ 0).\n",
        "Controls must behave as expected: illegal shortcuts reduce irreversibility or break energy accounting; removing C→3 or 1→2 kills bursts; random primes revert to baseline.\n",
        "\n",
        "## Notebook Overview & Research Aim\n",
        "### Goal\n",
        "- Simulate and *attempt to falsify* LENR-like cycles on a tetrahedral (and star-tetrahedral) topology.\n",
        "- If not falsified, motivate deeper modelling and lab tests for low-cost, high-yield, sustainable energy.\n",
        "### Key Ideas\n",
        "- DEC on simplicial complexes; mediation via centroid **C**; breath-driven, asymmetric flows; adelic (ℝ×ℚ_p) layer."
      ],
      "metadata": {
        "id": "qKR1ogm8760g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3c07b46"
      },
      "source": [
        "# @title 1. **Imports & Global Config** { display-mode: \"form\" }\n",
        "# @markdown **What this sets**\n",
        "# @markdown - Imports, numeric precision/warnings, plotting defaults, reproducibility seeds.\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from mpmath import mpf, power\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geometry (simplices, orientations, dual volumes)"
      ],
      "metadata": {
        "id": "rWI-4DAHO92i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb7ea8f2",
        "outputId": "dd8d0544-7801-47ec-a947-3b741fa028d2"
      },
      "source": [
        "# @title 2. **Geometry — S1 (Single Tetra) and Star (S1+S2) with Cubic Bridges** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds the base directed graph `G` for one tetrahedron (S1) or the full star (S1+S2) if `USE_STAR=True`.\n",
        "# @markdown - Defines vertices `{0,1,2,3,C}` for S1 and adds `{4,5,6,7}` for S2 in star mode.\n",
        "# @markdown - Encodes work-like edges, heat-dump edges, and mediation paths through centroid `C`.\n",
        "# @markdown - Adds optional cross-tetra “cubic” bridges for coherent work transfer and heat redistribution.\n",
        "# @markdown - Inserts self-loops for stability/linger dynamics.\n",
        "# @markdown - Labels canonical edge sets (`work_edges`, `heat_edges`) inside `G.graph` for later diagnostics.\n",
        "\n",
        "# === Geometry — S1 (tetra) and optional Star (S1+S2) with cubic bridges ===\n",
        "# Inputs: USE_STAR (bool) defined in C01_config; default to False if missing\n",
        "try:\n",
        "    USE_STAR\n",
        "except NameError:\n",
        "    USE_STAR = False\n",
        "\n",
        "import networkx as nx\n",
        "from mpmath import mpf\n",
        "\n",
        "# Nodes\n",
        "S1 = ['0','1','2','3']      # sinks even / branches odd\n",
        "S2 = ['4','5','6','7']\n",
        "ALL = (S1 + ['C']) if not USE_STAR else (S1 + S2 + ['C'])\n",
        "\n",
        "# Helper\n",
        "r = lambda x: mpf(str(x))\n",
        "\n",
        "# Core single-shell flows (work/heat + mediation) on S1\n",
        "core_edges_S1 = [\n",
        "    ('C','1', {'rate': r(0.5)}),     # pump\n",
        "    ('1','2', {'rate': r(0.8)}),     # E→M (work)\n",
        "    ('2','C', {'rate': r(0.9)}),     # return to mediator\n",
        "    ('C','3', {'rate': r(0.7)}),     # squeeze/fusion path\n",
        "    ('3','0', {'rate': r(1.0)}),     # heat dump\n",
        "    ('0','C', {'rate': r(0.3)}),     # reset\n",
        "]\n",
        "\n",
        "# Optional second shell (S2)\n",
        "core_edges_S2 = [\n",
        "    ('C','5', {'rate': r(0.5)}),\n",
        "    ('5','6', {'rate': r(0.8)}),\n",
        "    ('6','C', {'rate': r(0.9)}),\n",
        "    ('C','7', {'rate': r(0.7)}),\n",
        "    ('7','4', {'rate': r(1.0)}),\n",
        "    ('4','C', {'rate': r(0.3)}),\n",
        "]\n",
        "\n",
        "# Cross-shell bridges (only used if USE_STAR)\n",
        "cross_edges = [\n",
        "    ('3','6', {'rate': r(0.35)}),  # work bridge S1→S2\n",
        "    ('7','2', {'rate': r(0.25)}),  # heat-biased return to S1 magnetic\n",
        "    ('5','0', {'rate': r(0.20)}),  # heat assist into S1 sink\n",
        "    ('1','6', {'rate': r(0.20)}),  # optional E→M assist across shells\n",
        "]\n",
        "\n",
        "# Build graph once\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(ALL)\n",
        "G.add_edges_from(core_edges_S1)\n",
        "\n",
        "if USE_STAR:\n",
        "    G.add_edges_from(core_edges_S2 + cross_edges)\n",
        "    self_loop_nodes = S1 + S2\n",
        "else:\n",
        "    self_loop_nodes = S1\n",
        "\n",
        "# Self-loops (linger/stability)\n",
        "G.add_edges_from([(n, n, {'rate': r(0.4)}) for n in self_loop_nodes])\n",
        "\n",
        "# Label canonical edge sets (for later coupling/diagnostics)\n",
        "work_edges = {('1','2'), ('3','6')} if USE_STAR else {('1','2')}\n",
        "heat_edges = {('3','0')} | ({('7','2'), ('5','0')} if USE_STAR else set())\n",
        "\n",
        "G.graph['work_edges'] = work_edges\n",
        "G.graph['heat_edges'] = heat_edges\n",
        "\n",
        "print(f\"Graph ready. USE_STAR={USE_STAR} |V|={G.number_of_nodes()} |E|={G.number_of_edges()}\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph ready. USE_STAR=False |V|=5 |E|=10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. **Breath Operator — Inhale/Exhale Rhythm** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Defines a transformer `apply_breath(G_base, step)` that scales edge rates\n",
        "# @markdown   according to the breath cycle.\n",
        "# @markdown - Even steps = inhale: favour flows into sinks (`0,4`) and mediator `C`.\n",
        "# @markdown - Odd steps = exhale: favour flows out of `C` toward pump branches (`1,3,5,7`).\n",
        "# @markdown - Parameters `inhale_gain` and `exhale_gain` control modulation strength.\n",
        "# @markdown - Returns a fresh graph copy and the current phase label (`\"in\"` / `\"out\"`).\n",
        "\n",
        "\n",
        "def apply_breath(G_base, step, inhale_gain=1.15, exhale_gain=1.10,\n",
        "                 sinks=('0','4'), sources=('C',), pumps=('1','3','5','7')):\n",
        "    \"\"\"Scale edge rates by breath phase. Even steps = inhale (toward sinks/C), odd = exhale (from C→pumps).\"\"\"\n",
        "    phase = 'in' if (step % 2) == 0 else 'out'\n",
        "    G = G_base.copy()\n",
        "    for u, v, d in G.edges(data=True):\n",
        "        r = float(d.get('rate', 0.0))\n",
        "        if phase == 'in' and (v in sinks or v in sources):\n",
        "            d['rate'] = r * inhale_gain\n",
        "        elif phase == 'out' and (u in sources and v in pumps):\n",
        "            d['rate'] = r * exhale_gain\n",
        "    return G, phase\n"
      ],
      "metadata": {
        "id": "lVELWkflMr7b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEC operators (∂, Hodge stars, audits)"
      ],
      "metadata": {
        "id": "geaJ8kVwPFBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. **DEC Backbone — ∂ Operators & Diagonal Hodge Stars (with Audits)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Builds the simplicial backbone (independent of the Markov graph): vertices, oriented edges, faces.\n",
        "# @markdown - Constructs boundary maps: **B₁** (nodes→edges) and **B₂** (edges→faces).\n",
        "# @markdown - Defines **diagonal SPD Hodge stars** `Star1` (edges×edges) and `Star2` (faces×faces).\n",
        "# @markdown - Runs audits: `||B₁·B₂||∞ ≈ 0`, ranks of B₁/B₂, SPD minima; exposes `energy_field(E,B)`.\n",
        "# @markdown **Notes**\n",
        "# @markdown - No rectangular/“incidence-averaged” Hodge stand-ins here. Those are deprecated.\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# ---- 1) Vertex & face set (S1 always; S2 included if USE_STAR=True) ----\n",
        "try:\n",
        "    USE_STAR\n",
        "except NameError:\n",
        "    USE_STAR = False\n",
        "\n",
        "# Vertices: S1 plus shared centroid C; extend with S2 in star mode\n",
        "V = ['0','1','2','3','C'] + (['4','5','6','7'] if USE_STAR else [])\n",
        "\n",
        "# Faces:\n",
        "# - S1 outer + centroid faces\n",
        "F_S1_outer = [('0','1','2'), ('0','1','3'), ('0','2','3'), ('1','2','3')]\n",
        "F_S1_cent  = [('0','1','C'), ('0','2','C'), ('0','3','C'), ('1','2','C'), ('1','3','C'), ('2','3','C')]\n",
        "\n",
        "# - Optional S2 outer + centroid faces (only if USE_STAR)\n",
        "F_S2_outer = [('4','5','6'), ('4','5','7'), ('4','6','7'), ('5','6','7')]\n",
        "F_S2_cent  = [('4','5','C'), ('4','6','C'), ('4','7','C'), ('5','6','C'), ('5','7','C'), ('6','7','C')]\n",
        "\n",
        "F = F_S1_outer + F_S1_cent + (F_S2_outer + F_S2_cent if USE_STAR else [])\n",
        "\n",
        "# ---- 2) Oriented edges derived from faces (backbone edges only) ----\n",
        "edges_backbone = sorted({(a,b) for (a,b,c) in F for (a,b) in ((a,b),(b,c),(c,a))})\n",
        "\n",
        "# Index maps\n",
        "node_id = {v:i for i,v in enumerate(V)}\n",
        "edge_id = {e:i for i,e in enumerate(edges_backbone)}\n",
        "face_id = {f:i for i,f in enumerate(F)}\n",
        "\n",
        "# ---- 3) Boundary maps ----\n",
        "# B1: nodes×edges (∂1)\n",
        "B1 = np.zeros((len(V), len(edges_backbone)), dtype=float)\n",
        "for (u,v), ei in edge_id.items():\n",
        "    B1[node_id[u], ei] = -1.0\n",
        "    B1[node_id[v], ei] = +1.0\n",
        "B1 = csr_matrix(B1)\n",
        "\n",
        "# B2: edges×faces (∂2) with oriented incidence\n",
        "B2 = np.zeros((len(edges_backbone), len(F)), dtype=float)\n",
        "for fj,(v0,v1,v2) in enumerate(F):\n",
        "    for (a,b) in ((v0,v1),(v1,v2),(v2,v0)):\n",
        "        sign = +1.0\n",
        "        e = (a,b)\n",
        "        if e not in edge_id:\n",
        "            e = (b,a); sign = -1.0\n",
        "        B2[edge_id[e], fj] += sign\n",
        "B2 = csr_matrix(B2)\n",
        "\n",
        "# ---- 4) Diagonal Hodge stars (regularised circumcentric stand-ins) ----\n",
        "# Use a unit geometric scale here; SI scaling lives in the optional calibration cell.\n",
        "L = 1.0  # assumed primal edge length scale for now\n",
        "nE, nF = len(edges_backbone), len(F)\n",
        "\n",
        "\n",
        "# primal measures\n",
        "len_e  = np.full(nE, L, dtype=float)                       # |e|\n",
        "area_f = np.full(nF, (np.sqrt(3)/4.0)*L*L, dtype=float)    # |f| (equilateral)\n",
        "\n",
        "# crude-but-coherent dual measures for a regular/star tetra\n",
        "dual_e = np.full(nE, (L*L)/4.0, dtype=float)               # |*e|\n",
        "dual_f = np.full(nF, (L/3.0), dtype=float)                 # |*f|\n",
        "\n",
        "star1_diag = dual_e / len_e          # edges→edges\n",
        "star2_diag = dual_f / area_f         # faces→faces\n",
        "\n",
        "Star1 = np.diag(star1_diag)          # SPD\n",
        "Star2 = np.diag(star2_diag)\n",
        "\n",
        "def star1(x): return Star1 @ x\n",
        "def star2(x): return Star2 @ x\n",
        "\n",
        "# ---- 5) Audits ----\n",
        "D1 = B1.toarray(); D2 = B2.toarray()\n",
        "B1B2 = D1 @ D2\n",
        "inf_norm = float(np.max(np.abs(B1B2))) if B1B2.size else 0.0\n",
        "rank_D1 = int(np.linalg.matrix_rank(D1))\n",
        "rank_D2 = int(np.linalg.matrix_rank(D2))\n",
        "is_spd_star1 = bool(np.min(star1_diag) > 0)\n",
        "is_spd_star2 = bool(np.min(star2_diag) > 0)\n",
        "\n",
        "print(f\"[dims] |V|={len(V)} |E|={nE} |F|={nF}\")\n",
        "print(f\"||B1·B2||_∞ = {inf_norm:.3e} (expect 0)\")\n",
        "print(f\"rank(B1)={rank_D1}, rank(B2)={rank_D2}\")\n",
        "print(f\"Star1 SPD? {is_spd_star1}   Star2 SPD? {is_spd_star2}\")\n",
        "print(f\"star1_diag min/max = {star1_diag.min():.3e} / {star1_diag.max():.3e}\")\n",
        "print(f\"star2_diag min/max = {star2_diag.min():.3e} / {star2_diag.max():.3e}\")\n",
        "\n",
        "# ---- 6) Energy helper ----\n",
        "def energy_field(E, B):\n",
        "    \"\"\"Discrete EM energy: 0.5*(E⋅(⋆1 E) + B⋅(⋆2 B)).\"\"\"\n",
        "    return 0.5*(E @ (Star1 @ E) + B @ (Star2 @ B))\n",
        "\n",
        "# ---- 7) shape asserts ----\n",
        "\n",
        "assert D1.shape == (len(V), len(edge_id))          # nodes × edges\n",
        "assert D2.shape == (len(edge_id), len(F))          # edges × faces\n",
        "assert (D2.T @ np.zeros(D1.shape[1])).shape[0] == len(F)\n",
        "assert (D2 @ np.zeros(len(F))).shape[0] == len(edge_id)\n"
      ],
      "metadata": {
        "id": "b9aJlYAHbv8B",
        "outputId": "ef2efb1a-9301-456b-bdaf-0a64c03c6bca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dims] |V|=5 |E|=15 |F|=10\n",
            "||B1·B2||_∞ = 0.000e+00 (expect 0)\n",
            "rank(B1)=4, rank(B2)=10\n",
            "Star1 SPD? True   Star2 SPD? True\n",
            "star1_diag min/max = 2.500e-01 / 2.500e-01\n",
            "star2_diag min/max = 7.698e-01 / 7.698e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. **(Optional) SI Calibration — Scales, Materials & CFL Guard** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Sets dimensionful scales (edge length `L_m`), material guesses (ε_r, μ_r), and a conservative CFL-like `global_dt`.\n",
        "# @markdown - Leaves DEC stars (`Star1/Star2`) untouched; use this only for reporting or SI-coupled experiments.\n",
        "\n",
        "import numpy as np\n",
        "from mpmath import mpf\n",
        "\n",
        "# ---- 1) Geometry scale (metres) ----\n",
        "L_m = mpf('1e-9')  # 1 nm representative edge length (tune as needed)\n",
        "\n",
        "# ---- 2) Materials (metal-like defaults) ----\n",
        "eps0 = mpf('8.854187817e-12')     # F/m\n",
        "mu0  = mpf('1.25663706212e-6')    # H/m\n",
        "eps_r = mpf('20')                  # relative permittivity (order 10–100)\n",
        "mu_r  = mpf('1')                   # non-magnetic\n",
        "sigma = mpf('1e6')                 # S/m (ballpark for metals; tune/disable if not using ohmic loss)\n",
        "\n",
        "eps = eps_r * eps0\n",
        "mu  = mu_r  * mu0\n",
        "c_si = 1.0 / float(np.sqrt(eps * mu))   # wave speed in medium\n",
        "\n",
        "# ---- 3) CFL-like time step guard (from Markov rates if available) ----\n",
        "def cfl_dt_from_rates(graph, safety=0.1):\n",
        "    if graph is None:\n",
        "        return None\n",
        "    try:\n",
        "        mr = max((float(d.get('rate', 0.0)) for _,_,d in graph.edges(data=True)), default=0.0)\n",
        "    except Exception:\n",
        "        mr = 0.0\n",
        "    if mr <= 0.0:\n",
        "        return None\n",
        "    return safety / mr\n",
        "\n",
        "try:\n",
        "    G  # if your Markov graph exists, we can use it\n",
        "    dt_rate = cfl_dt_from_rates(G, safety=0.1)\n",
        "except NameError:\n",
        "    dt_rate = None\n",
        "\n",
        "# geometric CFL (Yee-like): dt ≤ 0.5 * L / c\n",
        "dt_geom = 0.5 * float(L_m) / float(c_si)\n",
        "\n",
        "# choose most conservative if both exist\n",
        "candidates = [x for x in (dt_rate, dt_geom) if x is not None]\n",
        "global_dt = min(candidates) if candidates else dt_geom\n",
        "\n",
        "# ---- 4) Export SI globals ----\n",
        "global_epsilon = float(eps)\n",
        "global_mu      = float(mu)\n",
        "global_sigma   = float(sigma)\n",
        "global_c       = float(c_si)\n",
        "\n",
        "print(f\"L = {float(L_m):.3e} m   eps_r={float(eps_r)}   mu_r={float(mu_r)}   sigma={float(sigma):.2e} S/m\")\n",
        "print(f\"c (medium) = {global_c:.3e} m/s\")\n",
        "print(f\"dt_geom = {dt_geom:.3e} s   dt_rate = {dt_rate if dt_rate is not None else 'n/a'}\")\n",
        "print(f\"=> global_dt = {global_dt:.3e} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1pqe2HQ_n5m",
        "outputId": "16bf686f-4cdf-4c5a-9c4e-cd3bc807afd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L = 1.000e-09 m   eps_r=20.0   mu_r=1.0   sigma=1.00e+06 S/m\n",
            "c (medium) = 6.704e+07 m/s\n",
            "dt_geom = 7.459e-18 s   dt_rate = 0.1\n",
            "=> global_dt = 7.459e-18 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time evolution (Maxwell-like DEC loop + optional Markov flux layer)"
      ],
      "metadata": {
        "id": "-_sS3jpKPOO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. **Coupling — Markov → DEC (edge currents & heat sink)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Provides pure functions to couple the Markov layer to the DEC solver:\n",
        "# @markdown   • `markov_to_currents(Gk, edge_id, ...) → J` injects **coherent edge currents** on the DEC backbone.\n",
        "# @markdown   • `accumulate_heat(Gk, dt, ...) → ΔQ` integrates **dissipative heat** from designated heat edges.\n",
        "# @markdown - Orientation-aware: if a directed Markov edge aligns with a DEC edge, +J; if reversed, −J; if not on the backbone, ignore.\n",
        "# @markdown - By default reads canonical `work_edges` / `heat_edges` from `G.graph` (set in Geometry). You can also pass explicit sets.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _edge_sign_index(u, v, edge_id):\n",
        "    \"\"\"Return (sign, idx) for directed pair (u,v) against DEC backbone edge_id map.\"\"\"\n",
        "    uv = (u, v)\n",
        "    vu = (v, u)\n",
        "    if uv in edge_id:\n",
        "        return +1.0, edge_id[uv]\n",
        "    if vu in edge_id:\n",
        "        return -1.0, edge_id[vu]\n",
        "    return 0.0, None  # not on backbone\n",
        "\n",
        "def markov_to_currents(\n",
        "    Gk,\n",
        "    edge_id: dict,\n",
        "    coherence_gain: float = 0.1,\n",
        "    work_edges: set | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Map Markov rates to a coherent current vector J on DEC edges.\n",
        "    Only edges tagged as 'work' contribute (coherent); 'heat' edges are handled in heat accounting.\n",
        "    \"\"\"\n",
        "    J = np.zeros(len(edge_id), dtype=float)\n",
        "    # pick work set (prefer graph annotation)\n",
        "    if work_edges is None:\n",
        "        work_edges = Gk.graph.get('work_edges', set())\n",
        "    for (u, v, data) in Gk.edges(data=True):\n",
        "        if (u, v) not in work_edges:\n",
        "            continue\n",
        "        rate = float(data.get('rate', 0.0))\n",
        "        sgn, ei = _edge_sign_index(str(u), str(v), edge_id)\n",
        "        if ei is None or sgn == 0.0:\n",
        "            continue\n",
        "        J[ei] += sgn * coherence_gain * rate\n",
        "    return J\n",
        "\n",
        "def accumulate_heat(\n",
        "    Gk,\n",
        "    dt: float,\n",
        "    heat_edges: set | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Integrate dissipative power from 'heat' edges into a scalar heat sink Q.\n",
        "    \"\"\"\n",
        "    if heat_edges is None:\n",
        "        heat_edges = Gk.graph.get('heat_edges', set())\n",
        "    dQ = 0.0\n",
        "    for (u, v, data) in Gk.edges(data=True):\n",
        "        if (u, v) in heat_edges:\n",
        "            dQ += float(data.get('rate', 0.0)) * float(dt)\n",
        "    return dQ\n"
      ],
      "metadata": {
        "id": "3-57UGmhcWZz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "898ec073"
      },
      "source": [
        "# @title 7. **Core Engine — Leapfrog DEC Loop (Energy & Heat Audit)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Integrates Maxwell-like fields on the DEC backbone with a **staggered (leapfrog/Yee)** scheme:\n",
        "# @markdown   • Faraday:   `B^{n+1/2} = B^{n-1/2} - dt * (∂₂ᵀ E^n)`\n",
        "# @markdown   • Ampère:    `⋆₁ E^{n+1} = ⋆₁ E^n + dt * (∂₁ᵀ ⋆₂ B^{n+1/2} - J^{n+1/2})`\n",
        "# @markdown - Couples to Markov layer via `apply_breath` (modulates rates) and `markov_to_currents` (injects **J** on edges).\n",
        "# @markdown - Audits **first-law closure**: logs field energy `U_field(t)`, cumulative heat `Q(t)`, and residual `Δ(U_field+Q)`.\n",
        "# @markdown\n",
        "# @markdown **Inputs expected from earlier cells**\n",
        "# @markdown - DEC: `B1, B2, Star1, Star2, energy_field`, and `edge_id` (from the DEC backbone cell).\n",
        "# @markdown - Markov: `G` (geometry) and `apply_breath` (breath operator).\n",
        "# @markdown - Optional SI: `global_dt` (else a safe dt is inferred from rates).\n",
        "# @markdown\n",
        "# @markdown **Outputs**\n",
        "# @markdown - `hist` dict with keys: `heat`, `energy`, `residual`, `phase`, `dt`, `samples`\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _safe_dt_from_rates(G, default_dt=1e-2, safety=0.1):\n",
        "    try:\n",
        "        mr = max((float(d.get('rate', 0.0)) for _, _, d in G.edges(data=True)), default=0.0)\n",
        "    except Exception:\n",
        "        mr = 0.0\n",
        "    if mr > 0.0:\n",
        "        return safety / mr\n",
        "    return default_dt\n",
        "\n",
        "def run_lenr_core(\n",
        "    G_base,\n",
        "    steps: int = 400,\n",
        "    dt: float | None = None,\n",
        "    coherence_gain: float = 0.1,\n",
        "    report_every: int = 20,\n",
        "):\n",
        "    # ---- Guards (ensure DEC objects exist) ----\n",
        "    needed = ['B1','B2','Star1','Star2','energy_field','edge_id']\n",
        "    missing = [k for k in needed if k not in globals()]\n",
        "    if missing:\n",
        "        raise RuntimeError(f\"Missing DEC objects: {missing}. Run the DEC backbone cell first.\")\n",
        "\n",
        "    # Dense views (small problems → faster)\n",
        "    D1 = B1.toarray()\n",
        "    D2 = B2.toarray()\n",
        "    DT1 = D1.T\n",
        "    DT2 = D2.T\n",
        "\n",
        "    # Star1 is diagonal SPD; grab its diagonal for cheap solves\n",
        "    star1_diag = np.diag(Star1).astype(float)\n",
        "    star2_mat  = Star2  # diagonal as well\n",
        "    inv_star1_diag = 1.0 / star1_diag\n",
        "\n",
        "    # Time step\n",
        "    if dt is None:\n",
        "        dt = globals().get('global_dt', None)\n",
        "    if dt is None:\n",
        "        dt = _safe_dt_from_rates(G_base, default_dt=1e-2, safety=0.1)\n",
        "    dt = float(dt)\n",
        "\n",
        "    # Fields: E on edges (integer time); B on faces (half-step)\n",
        "    nE = D1.shape[1]\n",
        "    nF = D2.shape[1]\n",
        "    E = np.zeros(nE, dtype=float)\n",
        "    Bf = np.zeros(nF, dtype=float)\n",
        "\n",
        "    # Heat sink & energy tracker\n",
        "    Q_sink = 0.0\n",
        "    U_prev = energy_field(E, Bf)\n",
        "\n",
        "    hist = {\"heat\": [], \"energy\": [], \"residual\": [], \"phase\": [], \"dt\": dt, \"samples\": []}\n",
        "\n",
        "    for n in range(steps):\n",
        "        # Breath-modulated graph & phase tag\n",
        "        Gk, phase = apply_breath(G_base, n)\n",
        "\n",
        "        # Coherent current from Markov layer\n",
        "        J = markov_to_currents(Gk, edge_id=edge_id, coherence_gain=coherence_gain)\n",
        "\n",
        "        # --- Faraday (half-step for B)\n",
        "        # B^{n+1/2} = B^{n-1/2} - dt * (∂₂ᵀ E^n)\n",
        "        Bf = Bf - dt * (DT2 @ E)\n",
        "\n",
        "        # --- Ampère (integer-step for E) with diagonal ⋆₁ solve\n",
        "        # ⋆₁ E^{n+1} = ⋆₁ E^n + dt * (∂₁ᵀ ⋆₂ B^{n+1/2} - J)\n",
        "        # drive = DT1 @ (star2_mat @ Bf) - J  # WRONG\n",
        "        drive = D2 @ (star2_mat @ Bf) - J  # RIGHT\n",
        "        E = E + dt * (drive * inv_star1_diag)\n",
        "\n",
        "        # Heat accounting\n",
        "        Q_sink += accumulate_heat(Gk, dt)\n",
        "\n",
        "        # Energy audit\n",
        "        U_now = energy_field(E, Bf)\n",
        "        residual = (U_now + Q_sink) - U_prev\n",
        "        U_prev = U_now + Q_sink\n",
        "\n",
        "        # Minimal logging (downsampled)\n",
        "        if (n % report_every) == 0 or n == steps - 1:\n",
        "            hist[\"heat\"].append(float(Q_sink))\n",
        "            hist[\"energy\"].append(float(U_now))\n",
        "            hist[\"residual\"].append(float(residual))\n",
        "            hist[\"phase\"].append(phase)\n",
        "            hist[\"samples\"].append(n)\n",
        "\n",
        "    return hist\n",
        "\n",
        "# --- Quick smoke test (comment out if you prefer) ---\n",
        "# hist = run_lenr_core(G, steps=120, report_every=10)\n",
        "# print(f\"samples={len(hist['samples'])}, heat_last={hist['heat'][-1]:.3e}, residual_last={hist['residual'][-1]:+.3e}\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diagnostics (energy, EPR, phase, visuals)"
      ],
      "metadata": {
        "id": "cwVkgWSFPaxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 8. **Diagnostics — Energy, EPR & Phase Metrics (pure functions)** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Computes compact diagnostics from your core engine and Markov layer:\n",
        "# @markdown   • Energy & heat summaries from `hist`\n",
        "# @markdown   • Steady-state **EPR** (Schnakenberg) per sampled step using `apply_breath(G, n)`\n",
        "# @markdown   • Optional phase metrics if your `hist` includes them (else skipped)\n",
        "# @markdown - Returns a `diag` dict you can print or plot.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _energy_summary(hist):\n",
        "    e = np.asarray(hist.get(\"energy\", []), dtype=float)\n",
        "    q = np.asarray(hist.get(\"heat\", []), dtype=float)\n",
        "    r = np.asarray(hist.get(\"residual\", []), dtype=float)\n",
        "    out = {\n",
        "        \"E_min\": float(np.nanmin(e)) if e.size else np.nan,\n",
        "        \"E_max\": float(np.nanmax(e)) if e.size else np.nan,\n",
        "        \"Q_final\": float(q[-1]) if q.size else np.nan,\n",
        "        \"resid_max_abs\": float(np.nanmax(np.abs(r))) if r.size else np.nan,\n",
        "    }\n",
        "    return out\n",
        "\n",
        "def _build_generator(Gk, node_list=None):\n",
        "    \"\"\"Continuous-time generator Q from rates; nodes ordered by node_list or sorted labels.\"\"\"\n",
        "    if node_list is None:\n",
        "        node_list = sorted([str(n) for n in Gk.nodes()])\n",
        "    idx = {u:i for i,u in enumerate(node_list)}\n",
        "    n = len(node_list)\n",
        "    Q = np.zeros((n,n), dtype=float)\n",
        "    for u,v,d in Gk.edges(data=True):\n",
        "        u,v = str(u), str(v)\n",
        "        if u not in idx or v not in idx:\n",
        "            continue\n",
        "        rate = float(d.get('rate', 0.0))\n",
        "        if rate <= 0:\n",
        "            continue\n",
        "        i,j = idx[u], idx[v]\n",
        "        Q[i,j] += rate\n",
        "    # diagonals\n",
        "    for i in range(n):\n",
        "        Q[i,i] = -np.sum(Q[i,:])\n",
        "    return Q, node_list\n",
        "\n",
        "def _stationary_dist(Q):\n",
        "    \"\"\"Solve Q^T π = 0 with Σπ=1 (least-squares + constraint).\"\"\"\n",
        "    n = Q.shape[0]\n",
        "    A = np.vstack([Q.T, np.ones((1,n))])\n",
        "    b = np.zeros(n+1); b[-1] = 1.0\n",
        "    # Least squares (robust if Q is nearly singular)\n",
        "    pi, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
        "    pi = np.clip(pi, 0.0, None)\n",
        "    s = pi.sum()\n",
        "    return (pi/s) if s > 0 else np.full(n, 1.0/n)\n",
        "\n",
        "def _epr_schnakenberg(Gk, node_order=None):\n",
        "    \"\"\"Schnakenberg EPR at steady state: σ = Σ_{u<v} J_uv * ln( (π_u k_uv)/(π_v k_vu) ).\"\"\"\n",
        "    Q, nodes = _build_generator(Gk, node_order)\n",
        "    pi = _stationary_dist(Q)\n",
        "    idx = {u:i for i,u in enumerate(nodes)}\n",
        "    sigma = 0.0\n",
        "    seen = set()\n",
        "    for u,v,d in Gk.edges(data=True):\n",
        "        u,v = str(u), str(v)\n",
        "        if (v,u) in seen or u==v:\n",
        "            continue\n",
        "        seen.add((u,v))\n",
        "        k_uv = float(Gk[u][v].get('rate', 0.0))\n",
        "        k_vu = float(Gk[v][u].get('rate', 0.0)) if Gk.has_edge(v,u) else 0.0\n",
        "        i,j = idx[u], idx[v]\n",
        "        j_uv = pi[i]*k_uv - pi[j]*k_vu\n",
        "        num = (pi[i]*k_uv) if (pi[i]>0 and k_uv>0) else 0.0\n",
        "        den = (pi[j]*k_vu) if (pi[j]>0 and k_vu>0) else 0.0\n",
        "        if num>0 and den>0:\n",
        "            sigma += j_uv * np.log(num/den)\n",
        "        else:\n",
        "            # one-way link → contributes via j_uv*ln(num/den) with den→(tiny); ignore log if both zero\n",
        "            if num>0 and j_uv>0:\n",
        "                sigma += j_uv * np.log(num/1e-12)\n",
        "            elif den>0 and j_uv<0:\n",
        "                sigma += j_uv * np.log(1e-12/den)\n",
        "    return float(max(sigma, 0.0))  # EPR ≥ 0\n",
        "\n",
        "def compute_epr_series(G, hist):\n",
        "    \"\"\"EPR at each reported sample using breath-modulated G_k at sample step n.\"\"\"\n",
        "    samples = hist.get(\"samples\", [])\n",
        "    epr = []\n",
        "    for n in samples:\n",
        "        Gk, _phase = apply_breath(G, int(n))\n",
        "        epr.append(_epr_schnakenberg(Gk))\n",
        "    return {\"samples\": samples, \"epr\": epr}\n",
        "\n",
        "def compute_phase_metrics(hist):\n",
        "    \"\"\"If you log phase errors, summarise; else return empty.\"\"\"\n",
        "    if \"phase_error\" in hist:\n",
        "        pe = np.asarray(hist[\"phase_error\"], dtype=float)\n",
        "        return {\"phase_err_mean\": float(np.nanmean(pe)), \"phase_err_max\": float(np.nanmax(np.abs(pe)))}\n",
        "    return {}\n",
        "\n",
        "def diagnostics(G, hist):\n",
        "    diag = {}\n",
        "    diag.update(_energy_summary(hist))\n",
        "    try:\n",
        "        diag.update({\"EPR_series\": compute_epr_series(G, hist)})\n",
        "    except Exception:\n",
        "        diag.update({\"EPR_series\": {\"samples\": hist.get(\"samples\", []), \"epr\": []}})\n",
        "    diag.update(compute_phase_metrics(hist))\n",
        "    return diag\n"
      ],
      "metadata": {
        "id": "npVHj1YjZm8-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cdd9aab"
      },
      "source": [
        "# @title 9. **Visualisations — Energy, Heat, Residuals, EPR, Phase** { display-mode: \"form\" }\n",
        "# @markdown **What this does**\n",
        "# @markdown - Plots the main diagnostics:\n",
        "# @markdown   • Cumulative heat `Q(t)` and field energy `U_field(t)`\n",
        "# @markdown   • Energy-closure residual `Δ(U+Q)` (should hover near 0)\n",
        "# @markdown   • EPR over sampled steps (if computable)\n",
        "# @markdown   • Phase error (if provided in `hist`)\n",
        "# @markdown - Prints a simple PASS/FLAG summary based on tolerances.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_diagnostics(hist, diag, tol_resid=1e-6):\n",
        "    # Pull streams\n",
        "    s   = np.asarray(hist.get(\"samples\", []), dtype=int)\n",
        "    Q   = np.asarray(hist.get(\"heat\", []), dtype=float)\n",
        "    U   = np.asarray(hist.get(\"energy\", []), dtype=float)\n",
        "    R   = np.asarray(hist.get(\"residual\", []), dtype=float)\n",
        "\n",
        "    # 1) Energy & heat\n",
        "    plt.figure(figsize=(6.0,3.8))\n",
        "    if U.size: plt.plot(s, U, label=\"Field energy U\")\n",
        "    if Q.size: plt.plot(s, Q, label=\"Cumulative heat Q\")\n",
        "    plt.xlabel(\"step\"); plt.ylabel(\"energy (arb.)\"); plt.title(\"Energy / Heat\"); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    # 2) Residual\n",
        "    if R.size:\n",
        "        plt.figure(figsize=(6.0,3.2))\n",
        "        plt.plot(s, R)\n",
        "        plt.xlabel(\"step\"); plt.ylabel(\"Δ(U+Q)\"); plt.title(\"Energy-closure residual\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "    # 3) EPR\n",
        "    epr_s = diag.get(\"EPR_series\", {})\n",
        "    epr_vals = np.asarray(epr_s.get(\"epr\", []), dtype=float)\n",
        "    epr_samps = np.asarray(epr_s.get(\"samples\", []), dtype=int)\n",
        "    if epr_vals.size:\n",
        "        plt.figure(figsize=(6.0,3.2))\n",
        "        plt.plot(epr_samps, epr_vals)\n",
        "        plt.xlabel(\"step\"); plt.ylabel(\"EPR (nats/step)\"); plt.title(\"Entropy Production Rate\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "    # 4) Phase error (optional)\n",
        "    if \"phase_error\" in hist:\n",
        "        pe = np.asarray(hist[\"phase_error\"], dtype=float)\n",
        "        ps = np.arange(len(pe))\n",
        "        plt.figure(figsize=(6.0,3.2))\n",
        "        plt.plot(ps, pe)\n",
        "        plt.xlabel(\"index\"); plt.ylabel(\"phase error (deg)\"); plt.title(\"Phase error\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "    # PASS/FLAG summary\n",
        "    resid_max = float(np.nanmax(np.abs(R))) if R.size else np.nan\n",
        "    epr_nonneg =_\n"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}